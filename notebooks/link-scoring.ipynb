{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link text based scoring methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys \n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "\n",
    "from phdconf import config \n",
    "from phdconf.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(config.AUS_TOPIC_PATH)\n",
    "broad, specific = load_query_types(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_dir = os.path.join(BASE_DIR, 'anchor-text', 'dirichlet_prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['case-topics']\n",
    "qrel_paths = [config.AUS_QREL_PATH] * len(index_names)\n",
    "rel_levels = [config.AUS_REL_LEVEL] * len(index_names)\n",
    "display_names = ['base', 'indegree', 'sum-indegree', 'outdegree', 'sum-outdegree', 'comb', 'comb-sum']\n",
    "\n",
    "topics = 'case-topics'\n",
    "\n",
    "to = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1050\n",
    "base_df = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, mu, mu, 1)[0][0]\n",
    "base_qry = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, mu, mu, 1, per_query=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "dfs = []\n",
    "for d in display_names[1:]: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(link_dir, 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00-linktext-{0}.run'.format(d)), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'])[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_text_fig = plot_tune_1d_comp(['base', 'inlink', 'weight-inlink', 'outlink', 'weight-outlink', 'comb', 'weight-comb'], RERANK_METRICS, \n",
    "                    [[base_df for x in range(to+1)]] + [x[:to+1] for x in dfs], 0.00, (to)/100, 0.01, legend_x=0.995, ylims=RERANK_YLIMS, styles=['--'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link_text_fig.savefig('figures/ausnl-linktext-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_max = select_1d_max_with_interp(display_names[1:], dfs, 0.0, 0.01, '$\\lambda$', inter, base_qry, base_df, 1050, os.path.join(link_dir, 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00-linktext-{0}.run'), config.AUS_QREL_PATH, config.AUS_REL_LEVEL, metrics=RERANK_METRICS).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_max.drop(['Unjudged@20'], axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "names = ['iprob', 'oprob']\n",
    "dfs = []\n",
    "for d in names: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'links', d+'-res.txt'), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], False)[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_max = select_1d_max_with_interp(names, dfs, 0.0, 0.01, '$\\lambda$', inter, base_qry, base_df, 1050, os.path.join(BASE_DIR, 'links', '{0}-res.txt'), config.AUS_QREL_PATH, config.AUS_REL_LEVEL, metrics=RERANK_METRICS).T\n",
    "cit_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to citation effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max for err@20\n",
    "om = copy.copy(config.METRIC_NAMES)\n",
    "del om['recall_100']\n",
    "del om['unjudged@20']\n",
    "\n",
    "text_comps =['sum-indegree', 'sum-outdegree']\n",
    "link_comps = ['iprob', 'oprob']\n",
    "runs = ['in', 'out']\n",
    "\n",
    "cols = om.keys()\n",
    "\n",
    "a = pd.DataFrame()\n",
    "b = pd.DataFrame()\n",
    "\n",
    "for i in range(len(link_comps)):\n",
    "    interps = [float(x) for x in link_max.loc[text_comps[i], '$\\lambda$'].values]\n",
    "    for j, c in zip(interps, cols):\n",
    "        inter.interpolate(os.path.join(link_dir, 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00-linktext-{0}.run'.format(text_comps[i])), j, 'tmp.run')\n",
    "        a[c] = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0][c]\n",
    "    \n",
    "    b_interps = [float(x) for x in cit_max.loc[link_comps[i], '$\\lambda$'].values]\n",
    "    for j, c in zip(b_interps, cols):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'links', link_comps[i]+'-res.txt'), j, 'tmp.run')\n",
    "        b[c] = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0][c]\n",
    "    \n",
    "    qry_comp_df = a-b\n",
    "    qry_comp_fig = qry_comp_df[om.keys()].rename(RERANK_METRICS, axis='columns').plot.box(fontsize=15, boxprops=dict(linestyle='-', linewidth=2), medianprops=dict(linestyle='-', linewidth=2), color=dict(boxes='black', whiskers='black', medians='b', caps='r'), figsize=(16, 4)).axhline(y=0, xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='grey')\n",
    "    # qry_comp_fig.get_figure().savefig('figures/ausnl-link-{0}-qry-comp.pdf'.format(runs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "dfs = []\n",
    "for d in display_names[1:]: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(link_dir, 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00-linktext-{0}.run'.format(d)), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_folds = read_folds(AUS_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlm_df = pd.DataFrame(columns=RERANK_METRICS)\n",
    "\n",
    "for ab, runs in zip(['indegree', 'sum-indegree', 'outdegree', 'sum-outdegree', 'comb', 'comb-sum'], dfs):\n",
    "    cross = cross_validation(runs, tt_folds, RERANK_METRICS, base_qry)\n",
    "    ntlm_df.loc[ab] = cross[0]\n",
    "    \n",
    "ntlm_df.loc['$R$'] = base_df.round(4)\n",
    "ntlm_df = ntlm_df.rename(index={'indegree':'inlink', 'outdegree': 'outlink', 'sum-indegree': 'weighted-inlink', 'sum-outdegree': 'weighted-outlink', 'comb-sum': 'weighted-comb'})\n",
    "ntlm_df = ntlm_df.reindex(['$R$', 'inlink', 'weighted-inlink', 'outlink', 'weighted-outlink', 'comb', 'weighted-comb'])\n",
    "# write_table('tables/ausnl-linktext', bold_max(ntlm_df).rename(columns=RERANK_METRICS).drop('Unjudged@20',axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_count_file(path: str): \n",
    "    out = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            vals = list(map(int, line.split()))\n",
    "            q = vals[0]\n",
    "            out[q] = vals[1:]\n",
    "            vals = vals[1:]\n",
    "            split = [vals[i:i+2] for i in range(0, len(vals), 2)]\n",
    "            _in = []\n",
    "            _out = []\n",
    "            for i, s in enumerate(split):\n",
    "                if i % 2 == 0:\n",
    "                    _in.append(s)\n",
    "                else:\n",
    "                    _out.append(s)\n",
    "\n",
    "            out[q] = [[x[0] for x in _in], [x[1] for x in _in], [x[0] for x in _out], [x[1] for x in _out]]\n",
    "    \n",
    "    return out\n",
    "\n",
    "counts = read_count_file(os.path.join(BASE_DIR, 'anchor-text', 'counts.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame.from_dict(counts, orient='index', columns=['inlinks', 'pin', 'outlinks', 'pout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df.mean()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "size = 2\n",
    "xs = [xs[i:i+size] for i in range(0, len(xs), size)]\n",
    "xs[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({k: [sum(x) for x in v] for k, v in counts.items()}, orient='index', columns=['inlinks', 'pin', 'outlinks', 'pout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_relevant(qrel_path: str, res_path: str, counts): \n",
    "    qrels = {}\n",
    "    with open(qrel_path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            q = int(parts[0])\n",
    "            rel = qrels.get(q, [set(), set()])\n",
    "            if parts[3] != '0':\n",
    "                rel[0].add(parts[2])\n",
    "            else:\n",
    "                rel[1].add(parts[2])\n",
    "            qrels[q] = rel\n",
    "    \n",
    "    \n",
    "    rel = []\n",
    "    nonrel = []\n",
    "    for i in range(4):\n",
    "        rel.append([])\n",
    "        nonrel.append([])\n",
    "    numrel = [0]*2\n",
    "    with open(res_path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            q = int(parts[0])\n",
    "            r = int(parts[3])\n",
    "            if parts[2] in qrels[q][0]:\n",
    "                numrel[0] += 1\n",
    "                for i, x in enumerate(counts[q]):\n",
    "                    rel[i].append(x[r])\n",
    "            elif parts[2] in qrels[q][1]:\n",
    "                numrel[1] += 1\n",
    "                for i, x in enumerate(counts[q]):\n",
    "                    nonrel[i].append(x[r])\n",
    "                \n",
    "                \n",
    "    return np.array(rel), np.array(nonrel), numrel\n",
    "                \n",
    "            \n",
    "    \n",
    "rel_stats, non_rel_stats, proportion = sum_relevant(config.AUS_QREL_PATH, os.path.join(link_dir, 'case-topics-filtered-phrasestop-unigram_dir_mu_3000.00-linktext-indegree.run'), counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_stats/proportion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rel_stats/proportion[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
