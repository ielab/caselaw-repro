{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotlib.loaders import *\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import annoy\n",
    "import nltk\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phrase_scores(path: str, feature: str) -> Dict[str, Tuple[str, int]]: \n",
    "    ind = {\n",
    "        'recip_rank': 2,\n",
    "        'recall_20': 3,\n",
    "        'recall_100': 4,\n",
    "        'ndcg': 5,\n",
    "        'rbp@0.10': 6,\n",
    "        'rbp@0.50': 7,\n",
    "        'rbp@0.80': 8,\n",
    "    }[feature]\n",
    "    \n",
    "    out = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            if parts[0] not in out: \n",
    "                out[parts[0]] = []\n",
    "            v = float(parts[ind])\n",
    "            inc = 1 \n",
    "            if v < 0.0:\n",
    "                inc = 0 \n",
    "#             elif v == 0.0:\n",
    "#                 inc = 0 \n",
    "            out[parts[0]].append((parts[1], inc))\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_increases(path: str):\n",
    "    increases = [0]*7\n",
    "    decreases = [0]*7\n",
    "    num = 0\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            num+=1\n",
    "            parts = line.split()\n",
    "            for i, p in enumerate(parts[2:]):\n",
    "                v = float(p)\n",
    "                if v > 0.0: \n",
    "                    increases[i-2] += 1\n",
    "                elif v < 0.0:\n",
    "                    decreases[i-2] += 1\n",
    "    return increases, decreases, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc, dec, num = cnt_increases('expansion-changes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(340, 160),\n",
       " (605, 3032),\n",
       " (285, 2494),\n",
       " (469, 2850),\n",
       " (585, 2961),\n",
       " (407, 2688),\n",
       " (393, 2019)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(inc, dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &      + &      - \\\\\n",
      "\\midrule\n",
      "RR      & 0.0853 & 0.0402 \\\\\n",
      "R@20    & 0.1519 & 0.7610 \\\\\n",
      "R@100   & 0.0715 & 0.6260 \\\\\n",
      "NDCG    & 0.1177 & 0.7154 \\\\\n",
      "RBP@0.1 & 0.1468 & 0.7432 \\\\\n",
      "RBP@0.5 & 0.1022 & 0.6747 \\\\\n",
      "RBP@0.8 & 0.0986 & 0.5068 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if int(x) == x else '{:,.4f}'.format(x)\n",
    "print((pd.DataFrame(list(zip(inc, dec)), columns=['+', '-'], index=['RR', 'R@20', 'R@100', 'NDCG', 'RBP@0.1', 'RBP@0.5', 'RBP@0.8'])/num).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = load_queries('/home/danlocke/go/src/github.com/dan-locke/phd-data/case-topics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(path: str):\n",
    "    embeddings = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            values = line.rstrip().rsplit(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "class EmbMethod:\n",
    "    SUM = 0\n",
    "    MEAN = 1 \n",
    "    CF_SUM = 2 \n",
    "    CF_MEAN = 3\n",
    "\n",
    "def embed(tokens: List[str], embeddings, dim: int=100, method: EmbMethod = EmbMethod.SUM, coll_stats = None) -> np.array:\n",
    "    e = []\n",
    "    if method > EmbMethod.MEAN: \n",
    "        for x in tokens: \n",
    "            if x in embeddings:\n",
    "                mul = coll_stats[x] if x in coll_stats else 1.0\n",
    "                e.append(mul * embeddings[x])\n",
    "    else: \n",
    "        e = [embeddings[x] for x in tokens if x in embeddings]\n",
    "    if len(e) == 0:\n",
    "        return np.zeros((dim,), dtype='float32')\n",
    "    \n",
    "    e = np.sum(e, axis=0)\n",
    "    if method == EmbMethod.MEAN or method == EmbMethod.CF_MEAN:\n",
    "        e /= len(tokens)\n",
    "            \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = {\n",
    "    'first', \n",
    "    'second', \n",
    "    'third',\n",
    "    'fourth',\n",
    "    'fifth',\n",
    "    'sixth',\n",
    "    'seventh',\n",
    "    'eighth',\n",
    "    'ninth',\n",
    "    'tenth',\n",
    "    'eleventh',\n",
    "    'twelfth',\n",
    "    'thirteenth',\n",
    "    'fourteenth',\n",
    "    'fifteenth',\n",
    "    'sixteenth',\n",
    "    'seventeenth',\n",
    "    'eighteenth',\n",
    "    'nineteenth',\n",
    "    'twenty',\n",
    "    'thirty',\n",
    "    'fourty',\n",
    "}\n",
    "\n",
    "num_exclusion = {\n",
    "    'amendment',\n",
    "    'degree',\n",
    "    'refusal'\n",
    "}\n",
    "\n",
    "find2 = {\n",
    "    'north',\n",
    "    'south',\n",
    "    'east',\n",
    "    'west'\n",
    "}\n",
    "\n",
    "find3 = {\n",
    "    'set',\n",
    "    'hold',\n",
    "    'exemplary',\n",
    "    'intending',\n",
    "    'include',\n",
    "    'including',\n",
    "    'relies',\n",
    "    'relied',\n",
    "    'pursuant',\n",
    "    'thereto',\n",
    "    'behalf',\n",
    "    'giving',\n",
    "    'give',\n",
    "    'apparently',\n",
    "    'subsequently',\n",
    "    'jurisdictional',\n",
    "    'included',\n",
    "    'includes',\n",
    "    'appellant',\n",
    "    'respondent',\n",
    "    'resulting',\n",
    "    'such',\n",
    "    's',\n",
    "    'x',\n",
    "    't',\n",
    "    'th',\n",
    "    'thing',\n",
    "    're',\n",
    "    'subject'\n",
    "}\n",
    "\n",
    "find4 = {\n",
    "    'nonetheless',\n",
    "    'follows',\n",
    "    'referred',\n",
    "    'thereto',\n",
    "    'behalf',\n",
    "    'hastily',\n",
    "    'instance',\n",
    "    'instances',\n",
    "    'such',\n",
    "    's',\n",
    "    'applicant',\n",
    "    'applicants',\n",
    "    'respondent',\n",
    "    'respondents',\n",
    "    'th',\n",
    "    'x',\n",
    "    'such',\n",
    "    'll',\n",
    "    'only',\n",
    "    'way',\n",
    "    're',\n",
    "    'much',\n",
    "}\n",
    "\n",
    "#     consider 'made' and 'make' as exclusions\n",
    "\n",
    "def filter_phrases(phrases, splitter=' '):\n",
    "    d = isinstance(phrases, dict)\n",
    "    if d:\n",
    "        ret = {}\n",
    "    else:\n",
    "        ret = []\n",
    "    for phrase in phrases:\n",
    "        toks = phrase.split(splitter)\n",
    "        if len(toks) < 2:\n",
    "            continue \n",
    "        \n",
    "        cont = False \n",
    "        cnt = 0\n",
    "\n",
    "        if toks[-1] in find3 or len(toks[-1]) == 1:\n",
    "            continue\n",
    "        \n",
    "        if len(toks) == 2 and toks[0].startswith('claim'):\n",
    "            continue\n",
    "            \n",
    "        if len(toks) == 3 and toks[0] == 'intention' and toks[1] != 'to':\n",
    "            continue\n",
    "            \n",
    "        if toks[0] == 'intention' and len(toks) == 2:\n",
    "            continue\n",
    "            \n",
    "        if toks[0] in find4 or len(toks[0]) == 1:\n",
    "            continue\n",
    "            \n",
    "        unique = set()\n",
    "            \n",
    "        num = False \n",
    "        num_ex = False\n",
    "        for t, tok in enumerate(toks):\n",
    "            unique.add(tok)\n",
    "            \n",
    "            if tok in find: \n",
    "                num = True \n",
    "            if tok in num_exclusion:\n",
    "                num_ex = True\n",
    "            if tok in find2:\n",
    "                cnt += 1 \n",
    "            if tok == 'nunc' and t != 0:\n",
    "                cont = True \n",
    "                break\n",
    "                \n",
    "        if num and not num_ex: \n",
    "            continue\n",
    "        \n",
    "        if len(toks) > len(unique): \n",
    "            continue\n",
    "    \n",
    "        if cont or cnt > 1:\n",
    "            continue \n",
    "            \n",
    "        if d: \n",
    "            ret[phrase] = phrases[phrase]\n",
    "        else:\n",
    "            ret.append(phrase)\n",
    "        \n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = {\n",
    "    'the',\n",
    "    'of',\n",
    "    'to',\n",
    "    'in', \n",
    "    'for',\n",
    "    'that',\n",
    "    'and',\n",
    "    'on',\n",
    "    'is',\n",
    "    'be',\n",
    "    'by',\n",
    "    'a',\n",
    "    'an',\n",
    "    'was',\n",
    "    'it',\n",
    "    'as',\n",
    "    'this',\n",
    "    'which',\n",
    "    'with',\n",
    "    'have',\n",
    "    'at',\n",
    "    'been',\n",
    "    'there',\n",
    "    'no',\n",
    "    'or',\n",
    "    'from',\n",
    "    'has',\n",
    "    'any',\n",
    "    'i',\n",
    "    'would',\n",
    "    'were',\n",
    "    'had',\n",
    "    'are',\n",
    "    'if',\n",
    "    'also',\n",
    "    'before',\n",
    "    'but',\n",
    "    'his',\n",
    "    'other',\n",
    "    'those',\n",
    "    'so',\n",
    "    'he',\n",
    "    'did',\n",
    "    'its',\n",
    "    'she',\n",
    "    'hers',\n",
    "    'their',\n",
    "    'theirs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_vectors('/home/danlocke/fastText/filtered-100d.vec')\n",
    "embeddings = {k: v for k, v in embeddings.items() if k.islower() and k.isalpha()}\n",
    "term_embeddings = [x for x in embeddings.values()]\n",
    "term_lookup = [x for x in embeddings.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_embeddings = load_vectors('/home/danlocke/fastText/para-phrase-100d.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_embeddings = filter_phrases(phrase_embeddings, '_')\n",
    "phrase_embeddings_vecs = [x for x in phrase_embeddings.values()]\n",
    "phrase_lookup = [x for x in phrase_embeddings.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = load_phrase_scores('expansion-changes.txt', 'ndcg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(tokens: List[str], n: int): \n",
    "    ret = []\n",
    "    for i in range(0, len(tokens)-(n-1)):\n",
    "           ret.append('_'.join(tokens[i:i+n]))\n",
    "           \n",
    "    return ret \n",
    "\n",
    "def get_phrases(text: str, phrase_lookup: Dict[str, np.array]): \n",
    "    found = {}\n",
    "    tokens = [x for x in text.lower().replace(',', '').replace('?', '').replace('\\'', '').replace('/', '').replace('’', '').split() if x not in stop]\n",
    "    for grams in [n_gram(tokens, 2), n_gram(tokens, 3)]:\n",
    "        for gram in grams:\n",
    "            if gram in phrase_lookup:\n",
    "                found[gram] = 1\n",
    "                \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = annoy.AnnoyIndex(100, 'angular')\n",
    "for i, x in enumerate(phrase_embeddings_vecs):\n",
    "    ind.add_item(i, x) \n",
    "ind.build(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_phrases = {}\n",
    "for topic in topics:\n",
    "    phrases = get_phrases(topics[topic]['topic'], phrase_embeddings)\n",
    "    phrases = [(x, phrase_embeddings[x], [phrase_lookup[y] for y in ind.get_nns_by_vector(phrase_embeddings[x], 25)]) for x in phrases]\n",
    "    qry_phrases[topic] = phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coll_stats(path: str, total=None) -> Dict[str, float]:\n",
    "    stats = {}\n",
    "    \n",
    "    idf = total is None\n",
    "    if idf:\n",
    "        total = 0.0\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            if idf: \n",
    "                v = float(parts[-1])\n",
    "                total += v\n",
    "                stats[' '.join(parts[:-1])] = v\n",
    "            else:\n",
    "                stats[' '.join(parts[:-1])] = math.log(total / float(parts[-1])+1.0) + 1.0\n",
    "    \n",
    "    if idf: \n",
    "        for k, v in stats.items():\n",
    "            stats[k] = math.log(total / v+1.0) + 1.0\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_stats = load_coll_stats('/home/danlocke/phd-generated/filtered-stop-top-tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82154965 0.78118753 0.6857758 0.8264465 0.78699005 0.5 14 2 1 1 expiration_date variation_date False\n",
      "0.9468368 1.0000001 0.8685207 0.0 0.0 0.5 10 2 0 1 settlement_date date_settlement True\n",
      "0.8192368 0.8353799 0.7669248 0.8459365 0.72736233 0.5 9 3 1 1 months_after_settlement date_settlement True\n",
      "0.8968439 0.9050517 0.7910331 0.8459365 0.72736233 0.5 11 2 1 1 settlement_dates date_settlement True\n",
      "0.81259847 0.737557 0.6482811 0.8459365 0.72736233 0.5 3 2 1 1 net_settlement date_settlement False\n",
      "0.74921834 0.80630344 0.7013704 0.8264465 0.78699005 0.5 12 2 1 1 cessation_date variation_date False\n",
      "0.7610389 0.80080897 0.69828653 0.8264465 0.78699005 0.5 13 2 1 1 calculation_date variation_date False\n",
      "0.88468426 1.0 0.8952483 0.0 0.0 0.5 9 2 0 0 date_variation variation_date True\n",
      "0.8156795 0.7689801 0.73492855 0.8459365 0.72736233 0.5 4 2 1 0 buyer_settlement date_settlement False\n",
      "0.7290616 0.8775606 0.80433923 0.8264465 0.78699005 0.5 11 2 1 0 vary_date variation_date False\n",
      "0.8589423 0.8085611 0.7966112 0.8459365 0.72736233 0.5 6 2 1 0 complete_settlement date_settlement True\n",
      "0.77672917 0.77763754 0.7914509 0.8264465 0.78699005 0.5 13 2 1 0 mediation_date variation_date True\n",
      "0.81513333 0.8594637 0.8207713 0.8459365 0.72736233 0.5 2 2 1 0 later_settlement date_settlement True\n",
      "0.8165161 0.83712375 0.78051466 0.8459365 0.72736233 0.5 8 3 1 0 weeks_after_settlement date_settlement True\n",
      "0.7562356 0.7782855 0.7582743 0.8601467 0.72736233 0.5 16 2 1 0 variation_addition variation_date True\n",
      "0.7402749 0.8022246 0.7080597 0.8264465 0.78699005 0.5 13 2 1 0 creation_date variation_date False\n",
      "0.8370156 0.83858407 0.80965406 0.8459365 0.72736233 0.5 6 3 1 0 days_after_settlement date_settlement True\n",
      "0.77881944 0.74361485 0.6494371 1.0 0.8952483 0.5 15 2 2 0 expiration_dates variation_date False\n",
      "0.757015 0.85764176 0.8183008 0.8601467 0.72736233 0.5 11 2 1 0 day_variation variation_date True\n",
      "0.939157 0.9391409 0.83280015 0.0 0.0 0.5 4 3 0 0 due_date_settlement date_settlement True\n",
      "0.820419 0.8103311 0.7889594 0.8459365 0.72736233 0.5 2 2 1 0 made_settlement date_settlement True\n",
      "0.8596914 0.85764176 0.8183008 0.8601467 0.72736233 0.5 13 2 1 0 variation_day variation_date True\n",
      "0.7743577 0.7947114 0.7069943 0.8264465 0.78699005 0.5 13 2 1 0 indexation_date variation_date False\n",
      "0.81308836 0.81457126 0.7481394 0.8459365 0.72736233 0.5 4 2 1 0 week_settlement date_settlement False\n",
      "0.77417195 0.80009544 0.7432676 0.8264465 0.78699005 0.5 14 2 1 0 resignation_date variation_date False\n",
      "0.8174814 0.71627223 0.69968426 0.8459365 0.72736233 0.5 6 2 1 0 negotiate_settlement date_settlement False\n",
      "0.7722085 0.7731452 0.7098552 0.8264465 0.78699005 0.5 14 2 1 0 installation_date variation_date False\n",
      "1.0000001 1.0000001 0.8685207 0.0 0.0 0.5 0 2 0 0 date_settlement date_settlement True\n",
      "0.7617602 0.8085593 0.737666 0.8601467 0.72736233 0.5 15 2 1 0 vacation_variation variation_date False\n",
      "0.8430655 0.8717542 0.8074556 0.8459365 0.72736233 0.5 2 2 1 0 day_settlement date_settlement True\n",
      "0.8403518 0.86098146 0.7791865 0.8459365 0.72736233 0.5 5 2 1 0 months_settlement date_settlement True\n",
      "0.7485279 0.89978504 0.8079 0.8264465 0.78699005 0.5 12 2 1 0 varied_date variation_date False\n",
      "0.7544667 0.77349263 0.78684497 0.8601467 0.72736233 0.5 13 2 1 0 variation_deed variation_date True\n",
      "0.7469001 0.878695 0.8458911 0.8601467 0.72736233 0.5 13 2 1 0 variation_time variation_date False\n",
      "0.8638558 0.8512515 0.82624525 0.8459365 0.72736233 0.5 2 2 1 0 days_settlement date_settlement True\n",
      "1.0 1.0 0.8952483 0.0 0.0 0.5 13 2 0 0 variation_date variation_date True\n",
      "0.7376585 0.7982234 0.7003277 0.8264465 0.78699005 0.5 14 2 1 0 separation_date variation_date False\n",
      "0.9284075 0.92850935 0.8217616 0.0 0.0 0.5 8 3 0 0 st_settlement_date date_settlement True\n",
      "0.8280648 0.85110813 0.7835982 0.8459365 0.72736233 0.5 4 2 1 0 month_settlement date_settlement True\n",
      "0.81100893 0.8442524 0.7595212 0.8459365 0.72736233 0.5 3 2 1 0 st_settlement date_settlement True\n",
      "0.88109326 0.6791669 0.6768704 0.8880645 0.6604107 0.25 21 2 1 1 town_maintenance maintenance_champerty False\n",
      "0.88497967 0.8785398 0.6840126 0.88639325 0.6955093 0.25 12 2 1 1 required_degree requisite_degree False\n",
      "0.8588803 0.8350745 0.67929745 0.88639325 0.6955093 0.25 15 2 1 1 some_degree requisite_degree False\n",
      "0.8717175 0.67150754 0.6327153 0.8880645 0.6604107 0.25 18 2 1 1 maintenance_gang maintenance_champerty False\n",
      "0.8585112 0.80366457 0.7043797 0.9256778 0.76187056 0.5 11 2 2 1 degrees_control requisite_degree_control False\n",
      "0.8680096 0.8445742 0.7191668 0.88639325 0.6955093 0.25 15 2 1 0 necessary_degree requisite_degree False\n",
      "0.86739004 0.8069093 0.7296556 0.8880645 0.6604107 0.25 20 2 1 0 tort_maintenance maintenance_champerty False\n",
      "0.7536984 0.8865636 0.7793919 0.73563117 0.699619 0.5 5 3 1 0 requisite_degree_care requisite_degree_control True\n",
      "1.0 0.99999994 0.8623894 0.0 0.0 0.5 0 3 0 0 requisite_degree_control requisite_degree_control True\n",
      "0.8948238 0.81697583 0.65976566 0.88639325 0.6955093 0.25 11 2 1 0 require_degree requisite_degree False\n",
      "0.8673734 0.67926157 0.62481135 0.8880645 0.6604107 0.25 21 2 1 0 pool_maintenance maintenance_champerty False\n",
      "0.8728822 0.6453319 0.5981073 0.8880645 0.6604107 0.25 18 2 1 0 maintenance_log maintenance_champerty False\n",
      "0.8729937 0.7594019 0.74903417 0.8880645 0.6604107 0.25 20 2 1 0 view_maintenance maintenance_champerty False\n",
      "0.866228 0.743271 0.63953 0.88639325 0.6955093 0.25 15 2 1 0 like_degree requisite_degree False\n",
      "0.8863314 0.67334336 0.5842589 0.8880645 0.6604107 0.25 21 2 1 0 lawn_maintenance maintenance_champerty False\n",
      "0.91857696 0.9417053 0.82250446 0.8266383 0.6955093 0.5 10 2 1 0 degree_control requisite_degree_control True\n",
      "0.86829436 0.74578345 0.69939035 0.8880645 0.6604107 0.25 21 2 1 0 proper_maintenance maintenance_champerty False\n",
      "0.8865148 0.72041416 0.64739674 0.8880645 0.6604107 0.25 19 2 1 0 maintenance_upkeep maintenance_champerty False\n",
      "0.8649429 0.7685159 0.6422103 0.88639325 0.6955093 0.25 16 2 1 0 attain_degree requisite_degree False\n",
      "0.86296415 0.7672204 0.6584309 0.88639325 0.6955093 0.25 17 2 1 0 allow_degree requisite_degree False\n",
      "0.7416072 0.8513921 0.7197583 0.73563117 0.699619 0.5 8 3 1 0 requisite_degree_precision requisite_degree_control False\n",
      "0.89538354 0.71475554 0.6727865 0.8880645 0.6604107 0.25 18 2 1 0 maintenance_etc maintenance_champerty False\n",
      "0.9538591 0.99999994 0.8016899 0.0 0.0 0.25 20 2 0 0 champerty_maintenance maintenance_champerty True\n",
      "0.8833686 0.8457396 0.700439 0.88639325 0.6955093 0.25 14 3 1 0 required_some_degree requisite_degree False\n",
      "0.8822194 0.8003149 0.6831561 0.88639325 0.6955093 0.25 13 3 1 0 require_some_degree requisite_degree False\n",
      "0.855423 0.7618266 0.6305512 0.88639325 0.6955093 0.25 14 2 1 0 emphasise_degree requisite_degree False\n",
      "0.80741376 0.9256778 0.76187056 0.73563117 0.699619 0.5 8 2 1 0 requisite_degree requisite_degree_control True\n",
      "0.93417555 0.917027 0.84226805 0.8266383 0.6955093 0.5 7 3 1 0 necessary_degree_control requisite_degree_control True\n",
      "0.754376 0.8907072 0.7691868 0.73563117 0.699619 0.25 5 3 1 0 requisite_degree_connection requisite_degree_control True\n",
      "0.8781612 0.8294421 0.7017838 0.8880645 0.6604107 0.25 20 2 1 0 torts_maintenance maintenance_champerty False\n",
      "0.75984704 0.7273856 0.6135753 0.8224842 0.699619 0.25 18 2 1 0 degree_animosity degree_control False\n",
      "0.7471972 0.7427274 0.626691 0.93651664 0.8364149 0.5 15 2 2 0 degree_cogency requisite_degree_control False\n",
      "0.8882724 0.9407842 0.8322231 0.8266383 0.6955093 0.5 8 3 1 0 sufficient_degree_control requisite_degree_control True\n",
      "1.0 0.99999994 0.8016899 0.0 0.0 0.25 19 2 0 0 maintenance_champerty maintenance_champerty True\n",
      "0.7629416 0.89571005 0.8098834 0.73563117 0.699619 0.25 7 3 1 0 requisite_degree_confidence requisite_degree_control True\n",
      "0.86668736 0.7015295 0.6556276 0.8880645 0.6604107 0.25 20 2 1 0 boat_maintenance maintenance_champerty False\n",
      "0.8301551 0.89324796 0.79678893 0.8266383 0.6955093 0.5 10 3 1 0 substantial_degree_control requisite_degree_control True\n",
      "0.86401725 0.6817975 0.69454056 0.8880645 0.6604107 0.25 21 2 1 0 own_maintenance maintenance_champerty False\n",
      "0.76139987 0.85366935 0.7214053 0.73563117 0.699619 0.5 9 3 1 0 requisite_degree_persuasion requisite_degree_control False\n",
      "0.7761576 0.85875326 0.72539544 0.73563117 0.699619 0.5 6 3 1 0 requisite_degree_clarity requisite_degree_control False\n",
      "0.87543106 0.69494677 0.7036311 0.8880645 0.6604107 0.25 19 2 1 0 maintenance_sea maintenance_champerty False\n",
      "0.78129643 0.72538304 0.61833507 0.8224842 0.699619 0.25 13 2 1 0 degree_contact degree_control False\n",
      "0.8712286 0.6902864 0.64028406 0.8880645 0.6604107 0.25 21 2 1 0 yard_maintenance maintenance_champerty False\n",
      "0.8094184 0.88449323 0.7790393 0.8266383 0.6955093 0.5 9 3 1 0 significant_degree_control requisite_degree_control True\n",
      "0.89889914 0.9019557 0.79824203 0.8266383 0.6955093 0.5 8 3 1 0 high_degree_control requisite_degree_control True\n",
      "0.8655573 0.8758474 0.71667516 0.0 0.0 0.25 7 3 0 0 requisite_degree_pain requisite_degree True\n",
      "0.77622604 0.6992561 0.6411319 0.93651664 0.8364149 0.5 16 2 2 0 degree_contributory requisite_degree_control False\n",
      "0.7606544 0.79583085 0.67828405 0.8224842 0.699619 0.25 14 2 1 0 degree_concern degree_control False\n",
      "0.8721186 0.68449104 0.6355295 0.8880645 0.6604107 0.25 18 2 1 0 maintenance_shutdown maintenance_champerty False\n",
      "0.87633234 0.66099447 0.60923886 0.8880645 0.6604107 0.25 18 2 1 0 maintenance_logs maintenance_champerty False\n",
      "0.7878374 0.7329325 0.6546691 0.8224842 0.699619 0.25 15 2 1 0 degree_co degree_control False\n",
      "0.7740914 0.73986995 0.6122868 0.8224842 0.699619 0.25 15 2 1 0 degree_cooler degree_control False\n",
      "0.7553846 0.707209 0.6135331 0.8224842 0.699619 0.25 17 2 1 0 degree_anonymity degree_control False\n",
      "0.77333075 0.6931936 0.6352356 0.93651664 0.8364149 0.5 15 2 2 0 degree_controversy requisite_degree_control False\n",
      "0.8810638 0.61784464 0.5777727 0.8880645 0.6604107 0.25 19 2 1 0 rituximab_maintenance maintenance_champerty False\n",
      "0.76957774 0.8035027 0.7487083 0.93651664 0.8364149 0.5 16 2 2 0 degree_continuity requisite_degree_control False\n",
      "0.7614579 0.6612339 0.57796603 0.93651664 0.8364149 0.5 14 2 2 0 degree_contrition requisite_degree_control False\n",
      "0.7682269 0.81834847 0.70399284 0.8224842 0.699619 0.25 17 2 1 0 degree_autonomy degree_control False\n",
      "0.7698492 0.93651664 0.8364149 0.81917566 0.65938234 0.25 7 2 1 0 requisite_control requisite_degree_control True\n",
      "0.857081 0.8395499 0.6382988 0.88639325 0.6955093 0.25 16 2 1 0 show_degree requisite_degree False\n",
      "0.86148345 0.8748112 0.7242102 0.88639325 0.6955093 0.25 16 2 1 0 establish_degree requisite_degree False\n",
      "0.75761414 0.8936244 0.7739078 0.73563117 0.699619 0.5 7 3 1 0 requisite_degree_certainty requisite_degree_control True\n",
      "0.86767894 0.7707638 0.6659046 0.88639325 0.6955093 0.25 15 2 1 0 provide_degree requisite_degree False\n",
      "0.673101 0.58426356 0.5736498 0.73781043 0.49422655 0.25 15 2 1 1 globo_sale cause_sale False\n",
      "0.6693003 0.65303034 0.57372165 0.73781043 0.49422655 0.25 14 2 1 1 annul_sale cause_sale False\n",
      "0.72035193 0.7928241 0.63338286 0.8091807 0.6741427 0.25 16 2 1 1 memo_fees agency_fees False\n",
      "0.6929927 0.615252 0.5450567 0.9058914 0.79367757 0.25 9 2 2 1 effective_macadamia effective_cause_sale False\n",
      "0.72240484 0.7623436 0.6550595 0.9058914 0.79367757 0.5 7 2 2 1 effective_use effective_cause_sale False\n",
      "0.66697925 0.6285463 0.5755372 0.73781043 0.49422655 0.25 13 2 1 1 toys_sale cause_sale False\n",
      "0.7502231 0.69063264 0.70801574 0.73781043 0.49422655 0.25 11 2 1 1 warehouse_sale cause_sale False\n",
      "0.7615774 0.7283609 0.523057 0.79455537 0.5852676 0.25 12 2 1 1 substantive_cause effective_cause False\n",
      "0.69969004 0.63643444 0.6399634 0.9999999 0.778053 0.25 15 2 2 1 fix_fee agency_fees False\n",
      "0.7031063 0.7992153 0.7443758 0.8091807 0.6741427 0.25 15 2 1 1 hire_fees agency_fees False\n",
      "0.6851977 0.6408143 0.51981634 0.9058914 0.79367757 0.25 8 2 2 1 effective_vaccine effective_cause_sale False\n",
      "0.8468814 0.894652 0.7584028 0.8091807 0.6741427 0.25 15 2 1 1 agent_fees agency_fees True\n",
      "0.69108254 0.6373061 0.5499155 0.9058914 0.79367757 0.25 8 2 2 1 effective_chains effective_cause_sale False\n",
      "0.67797846 0.6483818 0.6152586 0.9058914 0.79367757 0.25 9 2 2 1 effective_bar effective_cause_sale False\n",
      "0.6880082 0.7710227 0.7414717 0.9058914 0.79367757 0.25 7 2 2 1 effective_sales effective_cause_sale False\n",
      "0.7596345 0.7650056 0.65001684 0.7079131 0.7037167 0.5 14 3 1 1 dominant_effective_cause effective_cause_sale False\n",
      "0.7747395 0.8937865 0.8033316 0.66688263 0.49422655 0.25 6 2 1 1 effective_sale effective_cause_sale True\n",
      "0.722923 0.7081903 0.67097664 0.9999999 0.778053 0.25 15 2 2 0 contingency_fee agency_fees False\n",
      "0.80687726 0.84953976 0.70883864 0.7079131 0.7037167 0.5 12 3 1 0 direct_effective_cause effective_cause_sale False\n",
      "0.70215803 0.7705652 0.61029553 0.8091807 0.6741427 0.25 15 2 1 0 fields_fees agency_fees False\n",
      "0.8105132 0.7194626 0.54444224 0.79455537 0.5852676 0.25 10 2 1 0 putative_cause effective_cause False\n",
      "0.77933276 0.73603064 0.51491314 1.0000001 0.67564666 0.25 9 2 2 0 operative_causes effective_cause False\n",
      "0.73656577 0.8722439 0.6725264 0.8091807 0.6741427 0.25 17 2 1 0 advisor_fees agency_fees False\n",
      "0.68149555 0.7039842 0.6965929 0.73781043 0.49422655 0.25 13 2 1 0 fit_sale cause_sale False\n",
      "0.7295442 0.6652111 0.61772454 0.8091807 0.6741427 0.25 15 2 1 0 tip_fees agency_fees False\n",
      "0.69954926 0.7624665 0.6631992 0.8091807 0.6741427 0.25 16 2 1 0 accrued_fees agency_fees False\n",
      "0.8020059 0.72218615 0.5069448 0.79455537 0.5852676 0.25 9 2 1 0 affect_cause effective_cause False\n",
      "0.69143754 0.6391162 0.54296213 0.9058914 0.79367757 0.25 9 2 2 0 effective_veto effective_cause_sale False\n",
      "0.68554705 0.7233742 0.66903865 0.9058914 0.79367757 0.25 12 3 2 0 safe_effective_use effective_cause_sale False\n",
      "0.6774261 0.6829935 0.5741352 0.8937865 0.8033316 0.5 10 2 2 0 prospective_cause effective_cause_sale False\n",
      "0.7569974 0.74627024 0.53671443 0.79455537 0.5852676 0.25 9 2 1 0 definitive_cause effective_cause False\n",
      "0.6747805 0.6836856 0.6788075 0.73781043 0.49422655 0.25 13 2 1 0 wash_sale cause_sale False\n",
      "0.85103774 0.79714155 0.60988635 0.9058914 0.79367757 0.5 4 2 2 0 effective_causes effective_cause_sale False\n",
      "0.7239405 0.84258896 0.6684671 0.8091807 0.6741427 0.25 15 2 1 0 client_fees agency_fees False\n",
      "0.8015727 0.7115377 0.49390143 0.79455537 0.5852676 0.25 11 2 1 0 give_cause effective_cause False\n",
      "0.68745494 0.5982598 0.6458083 1.0 0.79367757 0.25 13 2 2 0 use_sales cause_sale False\n",
      "0.7076536 0.81166685 0.68630064 0.9999999 0.778053 0.25 15 2 2 0 brokerage_fee agency_fees False\n",
      "0.7318485 0.83794194 0.6411936 0.8091807 0.6741427 0.25 17 2 1 0 advisory_fees agency_fees False\n",
      "0.8375396 0.8522009 0.70531625 0.7079131 0.7037167 0.5 10 3 1 0 real_effective_cause effective_cause_sale False\n",
      "0.7041772 0.6289464 0.58757097 0.9999999 0.778053 0.25 16 2 2 0 rata_fee agency_fees False\n",
      "0.86679006 0.87671435 0.67564666 0.7079131 0.7037167 0.5 5 2 1 0 effective_cause effective_cause_sale False\n",
      "0.74622315 0.8404091 0.66297144 0.7079131 0.7037167 0.5 10 3 1 0 effective_operative_cause effective_cause_sale False\n",
      "0.7090448 0.7148258 0.5522284 0.8937865 0.8033316 0.5 8 2 2 0 effect_cause effective_cause_sale False\n",
      "0.6876009 0.6445253 0.64802927 0.73781043 0.49422655 0.25 13 2 1 0 quick_sale cause_sale False\n",
      "0.6822058 0.6394347 0.5894711 0.73781043 0.49422655 0.25 13 2 1 0 wine_sale cause_sale False\n",
      "0.7101082 0.6890654 0.66938204 0.73781043 0.49422655 0.25 12 2 1 0 maximise_sale cause_sale False\n",
      "0.72020715 0.720167 0.71844715 0.73781043 0.49422655 0.25 12 2 1 0 house_sale cause_sale False\n",
      "0.7965241 0.8256913 0.5790584 0.79455537 0.5852676 0.25 10 2 1 0 operative_cause effective_cause False\n",
      "0.68973464 0.6704098 0.6448605 0.73781043 0.49422655 0.25 11 2 1 0 ease_sale cause_sale False\n",
      "0.9338429 0.9252742 0.76586515 0.8624189 0.63262063 0.25 16 2 1 0 agency_fee agency_fees True\n",
      "0.75597805 0.74739975 0.6554593 0.8091807 0.6741427 0.25 16 2 1 0 signage_fees agency_fees False\n",
      "0.684722 0.6427472 0.5785364 0.73781043 0.49422655 0.25 15 2 1 0 wool_sale cause_sale False\n",
      "0.69496185 0.6873298 0.6251056 0.9058914 0.79367757 0.5 7 2 2 0 effective_close effective_cause_sale False\n",
      "0.74677527 0.7805261 0.6821156 0.8091807 0.6741427 0.25 15 2 1 0 contingency_fees agency_fees False\n",
      "0.71543217 0.76506734 0.71176356 0.8091807 0.6741427 0.25 15 2 1 0 exit_fees agency_fees False\n",
      "0.7654428 0.6616934 0.5014584 1.0000001 0.67564666 0.25 10 2 2 0 alternative_causes effective_cause False\n",
      "0.7624859 0.86160535 0.6874798 0.8091807 0.6741427 0.25 16 2 1 0 brokerage_fees agency_fees False\n",
      "0.6753839 0.6243465 0.69496274 0.73781043 0.49422655 0.25 14 2 1 0 abalone_sale cause_sale False\n",
      "0.66857237 0.7287594 0.7100151 0.73781043 0.49422655 0.25 12 2 1 0 close_sale cause_sale False\n",
      "0.7978069 0.74876136 0.55659944 0.79455537 0.5852676 0.25 10 2 1 0 derivative_cause effective_cause False\n",
      "0.74601746 0.9058914 0.79367757 0.73343873 0.5852676 0.5 10 2 1 0 cause_sale effective_cause_sale True\n",
      "0.7569313 0.60740036 0.462377 1.0000001 0.67564666 0.25 9 2 2 0 putative_causes effective_cause False\n",
      "0.7539512 0.8017748 0.7034742 0.8091807 0.6741427 0.25 17 2 1 0 own_fees agency_fees False\n",
      "0.79540825 0.76712173 0.7260586 0.73781043 0.49422655 0.25 12 2 1 0 use_sale cause_sale False\n",
      "0.87691814 0.85871154 0.7411703 0.73781043 0.49422655 0.25 11 2 1 0 caused_sale cause_sale False\n",
      "0.6972414 0.76712173 0.7260586 0.73781043 0.49422655 0.25 15 2 1 0 sale_use cause_sale False\n",
      "0.6802618 0.73636305 0.6094398 0.9058914 0.79367757 0.5 10 2 2 0 effective_abandonment effective_cause_sale False\n",
      "1.0000001 0.9999999 0.778053 0.0 0.0 0.25 16 2 0 0 agency_fees agency_fees True\n",
      "0.7918793 0.7882885 0.5943739 0.79455537 0.5852676 0.25 11 2 1 0 alternative_cause effective_cause False\n",
      "1.0 1.0000001 0.84992516 0.0 0.0 0.75 0 3 0 0 effective_cause_sale effective_cause_sale True\n",
      "0.99999994 0.9999998 0.7712045 0.0 0.0 0.25 0 2 0 0 diligence_date diligence_date True\n",
      "0.7953167 0.6749956 0.6180354 0.84361833 0.6078902 0.25 14 2 1 0 consideration_none consideration_clause False\n",
      "0.80431527 0.7487767 0.6136583 0.84361833 0.6078902 0.25 16 2 1 0 consideration_context consideration_clause False\n",
      "0.8406288 0.8161977 0.7316004 0.82876134 0.5622331 0.25 13 2 1 0 full_discretion absolute_discretion False\n",
      "0.76430434 0.82700604 0.7447735 0.73521936 0.61348575 0.5 14 3 1 0 claim_due_diligence diligence_date False\n",
      "0.7773751 0.79423803 0.6747365 0.73521936 0.61348575 0.5 14 3 1 0 want_due_diligence diligence_date False\n",
      "0.75651014 0.8199003 0.7184206 0.73521936 0.61348575 0.5 14 3 1 0 duty_due_diligence diligence_date False\n",
      "0.84492445 0.7973781 0.6125183 0.82876134 0.5622331 0.25 15 2 1 0 invoke_discretion absolute_discretion False\n",
      "0.8602794 0.7844738 0.6244886 0.82876134 0.5622331 0.25 15 2 1 0 remove_discretion absolute_discretion False\n",
      "0.81047493 0.8033158 0.7466524 0.84361833 0.6078902 0.25 15 2 1 0 consideration_terms consideration_clause False\n",
      "0.7923592 0.73920316 0.7050438 0.84361833 0.6078902 0.25 18 2 1 0 consideration_therefore consideration_clause False\n",
      "0.7869476 0.676667 0.63192976 0.84361833 0.6078902 0.25 14 2 1 0 consideration_draft consideration_clause False\n",
      "0.848318 0.84184563 0.61410034 0.8309271 0.62471694 0.25 10 2 1 0 care_diligence due_diligence False\n",
      "0.7422995 0.8889846 0.7683454 0.73521936 0.61348575 0.25 15 3 1 0 period_due_diligence diligence_date False\n",
      "0.7523632 0.79954094 0.62511665 0.73521936 0.61348575 0.25 3 2 1 0 diligence_file diligence_date False\n",
      "0.8527521 0.9038664 0.7812852 0.84361833 0.6078902 0.25 20 3 1 0 clauses_under_consideration consideration_clause True\n",
      "0.87780774 0.78334403 0.6199943 0.82876134 0.5622331 0.25 13 2 1 0 like_discretion absolute_discretion False\n",
      "0.8367601 0.75624186 0.5506644 0.82876134 0.5622331 0.25 14 2 1 0 guide_discretion absolute_discretion False\n",
      "0.85493237 0.78784776 0.67790496 0.82876134 0.5622331 0.25 13 2 1 0 give_discretion absolute_discretion False\n",
      "0.8390901 0.7447079 0.6048915 0.82876134 0.5622331 0.25 14 2 1 0 ample_discretion absolute_discretion False\n",
      "0.81683815 0.7459276 0.66348827 0.84361833 0.6078902 0.25 15 2 1 0 consideration_scope consideration_clause False\n",
      "0.87744516 0.8458118 0.6509365 0.8309271 0.62471694 0.25 10 2 1 0 duty_diligence due_diligence False\n",
      "0.80909246 0.74011624 0.65561175 0.7631731 0.61441404 0.25 15 2 1 0 acceleration_clause consideration_clause False\n",
      "0.79698604 0.67044187 0.622191 0.84361833 0.6078902 0.25 14 2 1 0 consideration_fall consideration_clause False\n",
      "0.84426486 0.82401353 0.6771968 0.82876134 0.5622331 0.25 14 2 1 0 free_discretion absolute_discretion False\n",
      "0.788675 0.6697346 0.6372375 0.84361833 0.6078902 0.25 15 2 1 0 consideration_claim consideration_clause False\n",
      "0.7842314 0.63684857 0.6020052 0.84361833 0.6078902 0.25 16 2 1 0 consideration_reward consideration_clause False\n",
      "1.0000001 1.0 0.7568373 0.0 0.0 0.25 15 2 0 0 consideration_clause consideration_clause True\n",
      "0.7847797 0.84339076 0.74247384 0.73521936 0.61348575 0.5 9 3 1 0 due_diligence_regard diligence_date False\n",
      "0.84158725 0.7273588 0.5838026 0.82876134 0.5622331 0.25 13 2 1 0 discrete_discretion absolute_discretion False\n",
      "0.8486679 0.8252254 0.61638457 0.8309271 0.62471694 0.25 12 2 1 0 duties_diligence due_diligence False\n",
      "0.86290276 0.9347731 0.67372525 0.0 0.0 0.25 14 3 0 0 lack_due_diligence due_diligence True\n",
      "0.74924505 0.7442416 0.5895288 0.73521936 0.61348575 0.25 6 2 1 0 diligence_checks diligence_date False\n",
      "0.85733545 0.6875489 0.5708197 0.82876134 0.5622331 0.25 14 2 1 0 zone_discretion absolute_discretion False\n",
      "0.8432957 0.93642503 0.71050817 0.0 0.0 0.25 22 3 0 0 absolute_discretion_determines absolute_discretion True\n",
      "0.7558463 0.82401574 0.72659105 0.73521936 0.61348575 0.5 11 3 1 0 due_diligence_concerns diligence_date False\n",
      "0.7621544 0.8197124 0.68358254 0.73521936 0.61348575 0.25 10 3 1 0 due_diligence_reports diligence_date False\n",
      "0.76258063 0.804017 0.71829504 0.8574225 0.6259593 0.25 7 2 1 0 due_date diligence_date False\n",
      "0.816011 0.62660176 0.5758069 0.84361833 0.6078902 0.25 14 2 1 0 consideration_two consideration_clause False\n",
      "0.850223 0.9178974 0.6991623 0.0 0.0 0.25 23 3 0 0 absolute_discretion_considers absolute_discretion True\n",
      "0.8709147 0.94132376 0.8262018 0.0 0.0 0.25 19 3 0 0 clause_under_consideration consideration_clause True\n",
      "0.87426716 0.80982816 0.5879206 0.8309271 0.62471694 0.25 10 2 1 0 want_diligence due_diligence False\n",
      "0.8511737 0.75178057 0.6663405 0.82876134 0.5622331 0.25 14 2 1 0 gave_discretion absolute_discretion False\n",
      "1.0000001 0.99999994 0.67319804 0.0 0.0 0.25 16 2 0 0 absolute_discretion absolute_discretion True\n",
      "0.81383723 0.7497052 0.6882491 0.84361833 0.6078902 0.25 18 2 1 0 consideration_likewise consideration_clause False\n",
      "0.8388731 0.7350413 0.58367753 0.82876134 0.5622331 0.25 14 2 1 0 open_discretion absolute_discretion False\n",
      "0.8471651 0.82406896 0.7037242 0.82876134 0.5622331 0.25 14 2 1 0 true_discretion absolute_discretion False\n",
      "0.7854468 0.7055192 0.6741475 0.84361833 0.6078902 0.25 14 2 1 0 consideration_one consideration_clause False\n",
      "0.7511831 0.7592921 0.62368524 0.73521936 0.61348575 0.5 5 2 1 0 diligence_folder diligence_date False\n",
      "0.8385208 0.79350424 0.57272345 0.82876134 0.5622331 0.25 13 2 1 0 wide_discretion absolute_discretion False\n",
      "0.7617756 0.82644176 0.76036227 0.73521936 0.61348575 0.5 16 3 1 0 exercise_due_diligence diligence_date True\n",
      "0.76741797 0.82504785 0.65487474 0.73521936 0.61348575 0.5 5 2 1 0 diligence_dispatch diligence_date False\n",
      "0.779204 0.837769 0.6903872 0.73521936 0.61348575 0.5 12 3 1 0 due_diligence_enquiries diligence_date False\n",
      "0.853432 0.86837626 0.6854659 0.8309271 0.62471694 0.25 12 2 1 0 proper_diligence due_diligence False\n",
      "0.7876661 0.8987122 0.77421105 0.73521936 0.61348575 0.5 18 3 1 0 completion_due_diligence diligence_date True\n",
      "0.81597733 0.8719336 0.7076996 0.73521936 0.61348575 0.5 9 2 1 0 due_diligence diligence_date False\n",
      "0.8084025 0.7977956 0.66999304 0.73521936 0.61348575 0.5 10 3 1 0 due_diligence_checks diligence_date False\n",
      "0.8169954 0.68728167 0.7011466 0.84361833 0.6078902 0.25 18 2 1 0 consideration_therefor consideration_clause False\n",
      "0.8554336 0.8070767 0.6289938 0.82876134 0.5622331 0.25 14 2 1 0 mere_discretion absolute_discretion False\n",
      "0.84240925 0.8890851 0.57368976 0.82876134 0.5622331 0.25 17 2 1 0 unfettered_discretion absolute_discretion False\n",
      "0.73038524 0.73355305 0.5819752 0.73521936 0.61348575 0.5 6 2 1 0 diligence_prudence diligence_date False\n",
      "0.78696233 0.5902879 0.60875624 0.84361833 0.6078902 0.25 14 2 1 0 consideration_bore consideration_clause False\n",
      "0.75597394 0.85478854 0.748341 0.73521936 0.61348575 0.5 10 3 1 0 due_diligence_relation diligence_date False\n",
      "0.8413204 0.84747416 0.7167146 0.82876134 0.5622331 0.25 15 2 1 0 either_discretion absolute_discretion False\n",
      "0.7944505 0.65526134 0.54640126 0.84361833 0.6078902 0.25 17 2 1 0 consideration_contexts consideration_clause False\n",
      "0.8799031 0.9078747 0.7456336 0.0 0.0 0.25 16 3 0 0 appeal_due_diligence due_diligence True\n",
      "0.8523956 0.78048116 0.55700576 0.8309271 0.62471694 0.25 13 2 1 0 honesty_diligence due_diligence False\n",
      "0.78990424 0.8680086 0.71355695 0.7631731 0.61441404 0.25 12 2 1 0 consider_clause consideration_clause False\n",
      "0.7427927 0.890828 0.73768634 0.73521936 0.61348575 0.25 6 2 1 0 diligence_period diligence_date False\n",
      "0.8863314 0.67334336 0.67334336 0.8880645 0.8880645 1.0 15 2 1 1 lawn_maintenance maintenance_champerty False\n",
      "0.88109326 0.6791669 0.6791669 0.8880645 0.8880645 1.0 15 2 1 1 town_maintenance maintenance_champerty False\n",
      "0.86829436 0.74578345 0.74578345 0.8880645 0.8880645 1.0 17 2 1 1 proper_maintenance maintenance_champerty False\n",
      "0.8865148 0.72041416 0.72041416 0.8880645 0.8880645 1.0 8 2 1 1 maintenance_upkeep maintenance_champerty False\n",
      "1.0 0.99999994 0.99999994 0.0 0.0 1.0 0 2 0 1 maintenance_champerty maintenance_champerty True\n",
      "0.86668736 0.7015295 0.7015295 0.8880645 0.8880645 1.0 15 2 1 1 boat_maintenance maintenance_champerty False\n",
      "0.8717175 0.67150754 0.67150754 0.8880645 0.8880645 1.0 8 2 1 1 maintenance_gang maintenance_champerty False\n",
      "0.86401725 0.6817975 0.6817975 0.8880645 0.8880645 1.0 14 2 1 1 own_maintenance maintenance_champerty False\n",
      "0.8781612 0.8294421 0.8294421 0.8880645 0.8880645 1.0 16 2 1 1 torts_maintenance maintenance_champerty True\n",
      "0.87543106 0.69494677 0.69494677 0.8880645 0.8880645 1.0 8 2 1 1 maintenance_sea maintenance_champerty False\n",
      "0.8810638 0.61784464 0.61784464 0.8880645 0.8880645 1.0 19 2 1 1 rituximab_maintenance maintenance_champerty False\n",
      "0.86739004 0.8069093 0.8069093 0.8880645 0.8880645 1.0 15 2 1 1 tort_maintenance maintenance_champerty True\n",
      "0.8712286 0.6902864 0.6902864 0.8880645 0.8880645 1.0 15 2 1 1 yard_maintenance maintenance_champerty False\n",
      "0.89538354 0.71475554 0.71475554 0.8880645 0.8880645 1.0 7 2 1 0 maintenance_etc maintenance_champerty False\n",
      "0.9538591 0.99999994 0.99999994 0.0 0.0 1.0 19 2 0 0 champerty_maintenance maintenance_champerty True\n",
      "0.8721186 0.68449104 0.68449104 0.8880645 0.8880645 1.0 8 2 1 0 maintenance_shutdown maintenance_champerty False\n",
      "0.87633234 0.66099447 0.66099447 0.8880645 0.8880645 1.0 9 2 1 0 maintenance_logs maintenance_champerty False\n",
      "0.8673734 0.67926157 0.67926157 0.8880645 0.8880645 1.0 15 2 1 0 pool_maintenance maintenance_champerty False\n",
      "0.8728822 0.6453319 0.6453319 0.8880645 0.8880645 1.0 9 2 1 0 maintenance_log maintenance_champerty False\n",
      "0.8729937 0.7594019 0.7594019 0.8880645 0.8880645 1.0 15 2 1 0 view_maintenance maintenance_champerty True\n",
      "0.70821184 0.8316207 0.7356135 0.84647787 0.62900215 0.5 15 2 1 0 striking_example striking_out False\n",
      "0.67136705 0.78561115 0.7678085 0.84647787 0.62900215 0.5 15 2 1 0 striking_aspect striking_out False\n",
      "0.99999994 0.99999994 0.7722524 0.0 0.0 0.5 14 2 0 0 striking_out striking_out True\n",
      "0.7288064 0.8650386 0.7288482 0.8538769 0.7355147 0.5 5 2 1 0 defamation_relation defamation_claim False\n",
      "0.6803933 0.81364095 0.73924464 0.8991308 0.71465445 0.5 15 3 1 0 strike_out_motion striking_out False\n",
      "0.7624478 0.86589676 0.73045903 0.8538769 0.7355147 0.5 13 2 1 0 allegation_defamation defamation_claim False\n",
      "0.7112089 0.63874054 0.6798971 0.99999994 0.7722524 0.5 14 2 2 0 bring_strike striking_out False\n",
      "0.73747885 0.77240545 0.62574506 0.8538769 0.7355147 0.5 7 2 1 0 defamation_misleading defamation_claim False\n",
      "0.7376936 0.6132387 0.53840935 1.0 0.8102311 0.5 14 2 2 0 imputation_defamatory defamation_claim False\n",
      "0.67021716 0.8259252 0.6508316 0.8991308 0.71465445 0.5 14 2 1 0 stringing_out striking_out False\n",
      "0.726073 0.7258403 0.62312067 0.8538769 0.7355147 0.5 3 2 1 0 defamation_laws defamation_claim False\n",
      "0.75275487 0.6809689 0.71444964 0.99999994 0.7722524 0.5 13 2 2 0 seeking_strike striking_out False\n",
      "0.85878444 0.9416283 0.7974319 0.0 0.0 0.5 11 3 0 0 claim_defamation_cannot defamation_claim True\n",
      "0.6996664 0.85086566 0.7748961 0.8991308 0.71465445 0.5 15 3 1 0 strike_out_order striking_out False\n",
      "0.69507915 0.7475884 0.69020087 0.99999994 0.7722524 0.5 15 2 2 0 july_strike striking_out False\n",
      "0.7326984 0.7941023 0.66452926 0.8538769 0.7355147 0.5 6 2 1 0 defamation_lawyers defamation_claim False\n",
      "0.73830956 0.7810267 0.6807632 0.8538769 0.7355147 0.5 5 2 1 0 defamation_trial defamation_claim False\n",
      "0.73245883 0.85539454 0.7304436 0.8538769 0.7355147 0.5 6 2 1 0 defamation_plaintiff defamation_claim False\n",
      "0.68430346 0.6621026 0.6650871 0.99999994 0.7722524 0.5 13 2 2 0 resist_strike striking_out False\n",
      "0.82716525 0.83478606 0.6673465 0.84647787 0.62900215 0.5 14 2 1 0 striking_down striking_out False\n",
      "0.7520978 0.8074434 0.7130224 0.8538769 0.7355147 0.5 6 2 1 0 defamation_context defamation_claim False\n",
      "0.7466733 0.82658535 0.69215924 0.8538769 0.7355147 0.5 5 2 1 0 defamation_cannot defamation_claim False\n",
      "0.718701 0.71212244 0.6405605 0.99999994 0.7722524 0.5 14 2 2 0 strike_outs striking_out False\n",
      "0.8054169 0.86709255 0.76747024 0.8538769 0.7355147 0.5 5 2 1 0 defamation_pleading defamation_claim True\n",
      "0.82010627 0.8664571 0.73802704 0.84647787 0.62900215 0.5 14 2 1 0 striking_off striking_out False\n",
      "0.75398356 0.87267524 0.7734163 0.8538769 0.7355147 0.5 3 2 1 0 defamation_case defamation_claim True\n",
      "0.6777753 0.6684597 0.73216885 0.99999994 0.7722524 0.5 14 2 2 0 bringing_strike striking_out False\n",
      "0.75796247 0.85473585 0.7063455 0.8538769 0.7355147 0.5 6 2 1 1 defamation_damages defamation_claim False\n",
      "0.78371894 0.77113247 0.64611673 0.84647787 0.62900215 0.5 13 2 1 1 striking_blow striking_out False\n",
      "0.7542339 0.91444635 0.731288 0.8991308 0.71465445 0.5 15 2 1 0 struck_out striking_out True\n",
      "0.93867254 0.9439676 0.7677853 0.8538769 0.7355147 0.5 1 2 1 0 defamation_claims defamation_claim True\n",
      "0.8266317 0.84242284 0.6927826 0.84647787 0.62900215 0.5 13 2 1 0 striking_back striking_out False\n",
      "0.7296411 0.80034685 0.7224006 0.8538769 0.7355147 0.5 12 2 1 0 focus_defamation defamation_claim False\n",
      "0.7452336 0.752808 0.6491107 0.8538769 0.7355147 0.5 6 2 1 0 defamation_serves defamation_claim False\n",
      "1.0000001 1.0 0.8102311 0.0 0.0 0.5 0 2 0 0 defamation_claim defamation_claim True\n",
      "0.74352705 0.8493307 0.7127932 0.8538769 0.7355147 0.5 6 2 1 0 defamation_matter defamation_claim False\n",
      "0.69423074 0.7907465 0.6877069 0.84647787 0.62900215 0.5 16 2 1 0 striking_examples striking_out False\n",
      "0.6761461 0.8050307 0.7369849 0.8991308 0.71465445 0.5 16 3 1 0 strike_out_motions striking_out False\n",
      "0.8536258 0.85389316 0.7129851 0.8538769 0.7355147 0.5 4 2 1 0 defamation_suit defamation_claim False\n",
      "0.70572484 0.77305937 0.7212572 0.84647787 0.62900215 0.5 13 2 1 0 striking_victim striking_out False\n",
      "0.72902185 0.7853341 0.7853341 0.91851616 0.91851616 1.0 5 2 1 0 flow_commerce trade_commerce False\n",
      "0.8144102 0.86336887 0.86336887 0.91851616 0.91851616 1.0 4 2 1 0 world_commerce trade_commerce True\n",
      "0.7448544 0.85925895 0.85925895 0.94189405 0.94189405 1.0 6 2 1 0 trade_connexion trade_commerce False\n",
      "0.7184397 0.81559014 0.81559014 0.94189405 0.94189405 1.0 6 2 1 0 trade_etc trade_commerce False\n",
      "0.70779675 0.88111454 0.88111454 0.91851616 0.91851616 1.0 6 2 1 0 conduct_commerce trade_commerce False\n",
      "0.7193288 0.7986536 0.7986536 0.94189405 0.94189405 1.0 12 2 1 0 worldwide_trade trade_commerce False\n",
      "0.70186794 0.81840706 0.81840706 0.91851616 0.91851616 1.0 5 2 1 0 modern_commerce trade_commerce False\n",
      "0.735523 0.7757015 0.7757015 0.91851616 0.91851616 1.0 4 2 1 0 life_commerce trade_commerce False\n",
      "0.73489743 0.8537643 0.8537643 0.94189405 0.94189405 1.0 5 2 1 0 trade_context trade_commerce False\n",
      "0.7189939 0.8440246 0.8440246 0.94189405 0.94189405 1.0 12 2 1 0 commercial_trade trade_commerce False\n",
      "0.8908955 0.99999994 0.99999994 0.0 0.0 1.0 11 2 0 0 commerce_trade trade_commerce True\n",
      "0.74146 0.8069692 0.8069692 0.91851616 0.91851616 1.0 4 2 1 0 day_commerce trade_commerce False\n",
      "0.8287742 0.73601866 0.73601866 0.91851616 0.91851616 1.0 5 2 1 0 stuff_commerce trade_commerce False\n",
      "0.7364666 0.8166744 0.8166744 0.91851616 0.91851616 1.0 5 2 1 0 mobile_commerce trade_commerce False\n",
      "0.8201568 0.7439314 0.7439314 0.94189405 0.94189405 1.0 1 2 1 0 trade_commence trade_commerce False\n",
      "0.7194258 0.77414316 0.77414316 0.94189405 0.94189405 1.0 5 2 1 0 trade_conscience trade_commerce False\n",
      "0.74975187 0.7900013 0.7900013 0.91851616 0.91851616 1.0 7 2 1 0 decency_commerce trade_commerce False\n",
      "0.75069684 0.8412416 0.8412416 0.91851616 0.91851616 1.0 5 2 1 0 field_commerce trade_commerce True\n",
      "0.72602856 0.69067186 0.69067186 0.94189405 0.94189405 1.0 6 3 1 0 trade_common_law trade_commerce False\n",
      "0.99999994 0.99999994 0.99999994 0.0 0.0 1.0 0 2 0 1 trade_commerce trade_commerce True\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "def features(topic, phrases, qry_phrases):\n",
    "    out = []\n",
    "    topic = int(topic)\n",
    "    qry_toks = [x for x in topics[topic]['topic'].lower().replace(',', '').replace('?', '').replace('\\'', '').replace('/', '').replace('’', '').split() if x not in stop]\n",
    "    qry_vec = embed(qry_toks, embeddings).reshape(1, -1)\n",
    "    for phrase_tuple in phrases:\n",
    "        phrase_vec = phrase_embeddings[phrase_tuple[0]].reshape(1, -1)\n",
    "        \n",
    "        phrase_toks = set(phrase_tuple[0].split('_'))\n",
    "        \n",
    "        phrase_tok_vec = embed(phrase_toks, embeddings).reshape(1, -1)\n",
    "        matched_vec = None \n",
    "        matched_tok_vec = None \n",
    "        diff_toks_vec = None \n",
    "        num_diff_toks = 0\n",
    "        num_phrase_toks = len(phrase_toks)\n",
    "        orig_phrase = None \n",
    "        \n",
    "        min_qry_phrase_sim = None\n",
    "        max_qry_phrase_sim = None \n",
    "        \n",
    "        num_top_match = 0 \n",
    "        \n",
    "        for x in qry_phrases[topic]:\n",
    "            if phrase_tuple[0] in x[2]:\n",
    "                num_top_match += 1 \n",
    "                    \n",
    "                # the phrase is a potential expansion of this original query phrase\n",
    "\n",
    "                orig_phrase = x[0]\n",
    "                matched_vec = phrase_embeddings[x[0]].reshape(1, -1)\n",
    "                matched_toks = set(x[0].split('_'))\n",
    "                matched_tok_vec = embed(matched_toks, embeddings).reshape(1, -1)\n",
    "                \n",
    "                if min_qry_phrase_sim is None: \n",
    "                    min_qry_phrase_sim = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                else:\n",
    "                    s = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                    if s > min_qry_phrase_sim:\n",
    "                        min_qry_phrase_sim = s \n",
    "                        \n",
    "                if max_qry_phrase_sim is None: \n",
    "                    max_qry_phrase_sim = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                else:\n",
    "                    s = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                    if s > max_qry_phrase_sim:\n",
    "                        max_qry_phrase_sim = s \n",
    "\n",
    "                diff_toks = matched_toks - phrase_toks\n",
    "                num_diff_toks = len(diff_toks)\n",
    "                diff_toks_vec = embed(diff_toks, embeddings).reshape(1, -1)\n",
    "             \n",
    "        num_top_match = float(num_top_match) / float(len(qry_phrases[topic]))\n",
    "                \n",
    "        phrase_exp_sim = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "        phrase_exp_token_sim = cosine_similarity(phrase_tok_vec, matched_tok_vec)[0][0]\n",
    "        qry_exp_sim = cosine_similarity(qry_vec, phrase_tok_vec)[0][0]\n",
    "        diff_toks_sim = cosine_similarity(diff_toks_vec, matched_tok_vec)[0][0]\n",
    "        dist = nltk.edit_distance(phrase_tuple[0], x[0])\n",
    "        \n",
    "#         print(phrase_exp_sim, phrase_exp_token_sim, qry_exp_sim, dist, num_phrase_toks, num_diff_toks, num_top_match, phrase_tuple[1], phrase_tuple[0], orig_phrase)\n",
    "        out.append((qry_exp_sim, dist, num_phrase_toks, num_diff_toks, num_top_match, min_qry_phrase_sim, max_qry_phrase_sim,))\n",
    "    \n",
    "    return out\n",
    "    \n",
    "method=EmbMethod.SUM\n",
    "\n",
    "for topic, phrases in scores.items():\n",
    "    topic = int(topic)\n",
    "    if topic == 1:\n",
    "        continue\n",
    "    qry_toks = [x for x in topics[topic]['topic'].lower().replace(',', '').replace('?', '').replace('\\'', '').replace('/', '').replace('’', '').split() if x not in stop]\n",
    "    qry_vec = embed(qry_toks, embeddings, method=method, coll_stats=coll_stats).reshape(1, -1)\n",
    "    for phrase_tuple in phrases:\n",
    "        phrase_vec = phrase_embeddings[phrase_tuple[0]].reshape(1, -1)\n",
    "        \n",
    "        phrase_toks = set(phrase_tuple[0].split('_'))\n",
    "        \n",
    "        phrase_tok_vec = embed(phrase_toks, embeddings, method=method, coll_stats=coll_stats).reshape(1, -1)\n",
    "        matched_vec = None \n",
    "        matched_tok_vec = None \n",
    "        diff_toks_vec = None \n",
    "        num_diff_toks = 0\n",
    "        num_phrase_toks = len(phrase_toks)\n",
    "        orig_phrase = None \n",
    "        \n",
    "        min_qry_phrase_sim = None\n",
    "        max_qry_phrase_sim = None \n",
    "        \n",
    "        num_top_match = 0 \n",
    "        \n",
    "        for x in qry_phrases[topic]:\n",
    "            if phrase_tuple[0] in x[2]:\n",
    "                num_top_match += 1 \n",
    "                    \n",
    "                # the phrase is a potential expansion of this original query phrase\n",
    "\n",
    "                orig_phrase = x[0]\n",
    "                matched_vec = phrase_embeddings[x[0]].reshape(1, -1)\n",
    "                matched_toks = set(x[0].split('_'))\n",
    "                matched_tok_vec = embed(matched_toks, embeddings, method=method, coll_stats=coll_stats).reshape(1, -1)\n",
    "                \n",
    "                if min_qry_phrase_sim is None: \n",
    "                    min_qry_phrase_sim = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                else:\n",
    "                    s = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                    if s > min_qry_phrase_sim:\n",
    "                        min_qry_phrase_sim = s \n",
    "                        \n",
    "                if max_qry_phrase_sim is None: \n",
    "                    max_qry_phrase_sim = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                else:\n",
    "                    s = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "                    if s > max_qry_phrase_sim:\n",
    "                        max_qry_phrase_sim = s \n",
    "\n",
    "                diff_toks = matched_toks - phrase_toks\n",
    "                num_diff_toks = len(diff_toks)\n",
    "                diff_toks_vec = embed(diff_toks, embeddings, method=method, coll_stats=coll_stats).reshape(1, -1)\n",
    "             \n",
    "        num_top_match = float(num_top_match) / float(len(qry_phrases[topic]))\n",
    "                \n",
    "        phrase_exp_sim = cosine_similarity(phrase_vec, matched_vec)[0][0]\n",
    "        phrase_exp_token_sim = cosine_similarity(phrase_tok_vec, matched_tok_vec)[0][0]\n",
    "        qry_exp_sim = cosine_similarity(qry_vec, phrase_tok_vec)[0][0]\n",
    "        diff_toks_sim = cosine_similarity(diff_toks_vec, matched_tok_vec)[0][0]\n",
    "        diff_toks_qry_sim = cosine_similarity(diff_toks_vec, qry_vec)[0][0]\n",
    "        dist = nltk.edit_distance(phrase_tuple[0], x[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        keep = True    \n",
    "        if phrase_exp_sim < 0.75 and dist > 2:\n",
    "            keep = False\n",
    "#                 continue \n",
    "\n",
    "        if phrase_exp_sim < 0.7:\n",
    "            keep = False \n",
    "#                 continue\n",
    "\n",
    "        if diff_toks_sim == 0.0:\n",
    "            keep = True\n",
    "        elif diff_toks_sim < 0.5:\n",
    "            keep = False\n",
    "            \n",
    "        if qry_exp_sim < 0.75:\n",
    "            keep = False\n",
    "            \n",
    "        if num_diff_toks == 0:\n",
    "            keep = True\n",
    "        if phrase_exp_token_sim > 0.9:\n",
    "            keep = True\n",
    "        \n",
    "#         if keep and phrase_tuple[1] == 0:\n",
    "#             print('False positive -', phrase_exp_sim, phrase_exp_token_sim, qry_exp_sim, diff_toks_sim, diff_toks_qry_sim, num_top_match, dist, num_phrase_toks, num_diff_toks, phrase_tuple[1], phrase_tuple[0], orig_phrase, keep)\n",
    "#         elif not keep and phrase_tuple[1] == 1:\n",
    "        print(phrase_exp_sim, phrase_exp_token_sim, qry_exp_sim, diff_toks_sim, diff_toks_qry_sim, num_top_match, dist, num_phrase_toks, num_diff_toks, phrase_tuple[1], phrase_tuple[0], orig_phrase, keep)\n",
    "#         X.append((qry_exp_sim, dist, num_phrase_toks, num_diff_toks, num_top_match, min_qry_phrase_sim, max_qry_phrase_sim,))\n",
    "#         y.append(phrase_tuple[1])\n",
    "            \n",
    "    if topic > 8: \n",
    "        break \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   14.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('clf', SVC())]),\n",
       "             n_jobs=8,\n",
       "             param_grid={'clf__C': [1, 10],\n",
       "                         'clf__gamma': [0.001, 0.01, 1, 10, 100],\n",
       "                         'clf__kernel': ('linear', 'rbf')},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "parameters = {'clf__kernel':('linear', 'rbf'), 'clf__C':[1, 10, ], 'clf__gamma': [0.001, 0.01, 1, 10, 100]}\n",
    "# parameters =  {'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#         'clf__C': np.logspace(-3, 1, 5),} # for log_reg\n",
    "# parameters = {'clf__splitter': ('best', 'random'), 'clf__criterion': ('gini', 'entropy')} # for decision tree\n",
    "# parameters = {'clf__var_smoothing': [1e-9, 1e-2]}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "clf = GridSearchCV(pipe, parameters, n_jobs=8, verbose=2)\n",
    "# clf = make_pipeline(StandardScaler(), SVC())\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.07072458, 0.10285225, 0.06879096, 0.12561274, 0.0706389 ,\n",
       "        0.13745017, 0.07015314, 0.19507322, 0.07034044, 0.39453416,\n",
       "        0.19936719, 0.13692632, 0.1998868 , 0.16001153, 0.20335956,\n",
       "        0.18846006, 0.20252929, 0.23289852, 0.20129795, 0.43163505]),\n",
       " 'std_fit_time': array([0.00772153, 0.00508726, 0.00674348, 0.00795802, 0.00648207,\n",
       "        0.00713088, 0.00728654, 0.00910932, 0.00752077, 0.00730784,\n",
       "        0.02212769, 0.00603143, 0.02332529, 0.03861135, 0.02109922,\n",
       "        0.00688194, 0.02067971, 0.01447189, 0.01882749, 0.00653491]),\n",
       " 'mean_score_time': array([0.01131749, 0.01497307, 0.01005878, 0.01447854, 0.00788898,\n",
       "        0.0158433 , 0.00818162, 0.02413769, 0.00913258, 0.06827927,\n",
       "        0.00797586, 0.01496611, 0.0081707 , 0.01438241, 0.00799994,\n",
       "        0.01487956, 0.00789981, 0.02201042, 0.00790391, 0.06782985]),\n",
       " 'std_score_time': array([3.08560881e-03, 5.47546642e-04, 2.96519083e-03, 3.47163768e-04,\n",
       "        2.17059941e-04, 3.65958356e-04, 8.04237563e-04, 4.63417557e-04,\n",
       "        1.83021915e-03, 1.14038322e-03, 1.40545227e-04, 5.62960149e-04,\n",
       "        3.93407607e-04, 3.86137726e-04, 2.50031300e-04, 4.54994823e-04,\n",
       "        8.43850084e-05, 6.32613976e-04, 1.00899757e-04, 1.30985331e-03]),\n",
       " 'param_clf__C': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__gamma': masked_array(data=[0.001, 0.001, 0.01, 0.01, 1, 1, 10, 10, 100, 100,\n",
       "                    0.001, 0.001, 0.01, 0.01, 1, 1, 10, 10, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__C': 1, 'clf__gamma': 0.001, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 1, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 1, 'clf__gamma': 10, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 1, 'clf__gamma': 10, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 1, 'clf__gamma': 100, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 1, 'clf__gamma': 100, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 10, 'clf__gamma': 1, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 10, 'clf__gamma': 1, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 10, 'clf__gamma': 10, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 10, 'clf__gamma': 10, 'clf__kernel': 'rbf'},\n",
       "  {'clf__C': 10, 'clf__gamma': 100, 'clf__kernel': 'linear'},\n",
       "  {'clf__C': 10, 'clf__gamma': 100, 'clf__kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.75918885, 0.75918885, 0.75918885, 0.75918885, 0.75918885,\n",
       "        0.73003802, 0.75918885, 0.69835234, 0.75918885, 0.75918885,\n",
       "        0.75918885, 0.75918885, 0.75918885, 0.76045627, 0.75918885,\n",
       "        0.63498099, 0.75918885, 0.65019011, 0.75918885, 0.75285171]),\n",
       " 'split1_test_score': array([0.75918885, 0.75918885, 0.75918885, 0.75918885, 0.75918885,\n",
       "        0.77059569, 0.75918885, 0.74904943, 0.75918885, 0.75665399,\n",
       "        0.75918885, 0.75918885, 0.75918885, 0.74651458, 0.75918885,\n",
       "        0.69328264, 0.75918885, 0.7148289 , 0.75918885, 0.75411914]),\n",
       " 'split2_test_score': array([0.75918885, 0.75918885, 0.75918885, 0.75918885, 0.75918885,\n",
       "        0.72496831, 0.75918885, 0.72750317, 0.75918885, 0.75158428,\n",
       "        0.75918885, 0.75918885, 0.75918885, 0.73510773, 0.75918885,\n",
       "        0.67807351, 0.75918885, 0.67934094, 0.75918885, 0.75031686]),\n",
       " 'split3_test_score': array([0.75918885, 0.75918885, 0.75918885, 0.75918885, 0.75918885,\n",
       "        0.68187579, 0.75918885, 0.70975919, 0.75918885, 0.75411914,\n",
       "        0.75918885, 0.75918885, 0.75918885, 0.74397972, 0.75918885,\n",
       "        0.58301648, 0.75918885, 0.67553866, 0.75918885, 0.747782  ]),\n",
       " 'split4_test_score': array([0.76015228, 0.76015228, 0.76015228, 0.76015228, 0.76015228,\n",
       "        0.73857868, 0.76015228, 0.72335025, 0.76015228, 0.75888325,\n",
       "        0.76015228, 0.76015228, 0.76015228, 0.75888325, 0.76015228,\n",
       "        0.69670051, 0.76015228, 0.70558376, 0.76015228, 0.74873096]),\n",
       " 'mean_test_score': array([0.75938153, 0.75938153, 0.75938153, 0.75938153, 0.75938153,\n",
       "        0.7292113 , 0.75938153, 0.72160288, 0.75938153, 0.7560859 ,\n",
       "        0.75938153, 0.75938153, 0.75938153, 0.74898831, 0.75938153,\n",
       "        0.65721082, 0.75938153, 0.68509647, 0.75938153, 0.75076013]),\n",
       " 'std_test_score': array([0.00038538, 0.00038538, 0.00038538, 0.00038538, 0.00038538,\n",
       "        0.02849474, 0.00038538, 0.01715832, 0.00038538, 0.00289513,\n",
       "        0.00038538, 0.00038538, 0.00038538, 0.00952155, 0.00038538,\n",
       "        0.04311573, 0.00038538, 0.02300729, 0.00038538, 0.0024017 ]),\n",
       " 'rank_test_score': array([ 1,  1,  1,  1,  1, 17,  1, 18,  1, 14,  1,  1,  1, 16,  1, 20,  1,\n",
       "        19,  1, 15], dtype=int32)}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593813387423936"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features = features('1', scores['1'], qry_phrases)\n",
    "predicted = clf.predict(topic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7650007, 16, 2, 1, 0.5, 0.8511563, 0.8511563), (0.698878, 18, 2, 2, 0.5, 0.83666945, 0.83666945), (0.66542274, 16, 2, 1, 0.5, 0.82565606, 0.82565606), (0.7586659, 18, 2, 1, 0.5, 0.8432792, 0.8432792), (0.7763271, 10, 3, 0, 0.5, 0.94302297, 0.94302297), (0.78233033, 10, 3, 0, 0.5, 0.95130545, 0.95130545), (0.7615414, 16, 2, 1, 0.5, 0.8150523, 0.8150523), (0.7853027, 17, 2, 1, 0.5, 0.81310725, 0.81310725), (0.7103939, 6, 2, 1, 0.5, 0.8461931, 0.8461931), (0.7971319, 16, 2, 1, 0.5, 0.8230698, 0.8230698), (0.7248093, 15, 2, 1, 0.5, 0.8413123, 0.8413123), (0.80394316, 16, 2, 0, 0.5, 0.87822735, 0.87822735), (0.8068176, 15, 2, 1, 0.5, 0.83948386, 0.83948386), (0.710752, 15, 2, 1, 0.5, 0.83719003, 0.83719003), (0.7657465, 3, 2, 1, 0.5, 0.94904065, 0.94904065), (0.81424856, 18, 2, 0, 0.5, 1.0, 1.0), (0.7367139, 17, 2, 1, 0.5, 0.86503106, 0.86503106), (0.7697695, 17, 2, 1, 0.5, 0.8303156, 0.8303156), (0.7674389, 16, 2, 1, 0.5, 0.83646023, 0.83646023), (0.7721431, 17, 2, 1, 0.5, 0.8238973, 0.8238973), (0.84377104, 4, 3, 0, 0.5, 0.89712536, 0.89712536), (0.80285233, 1, 2, 1, 0.5, 0.9304306, 0.9304306), (0.7345257, 15, 2, 1, 0.5, 0.8306037, 0.8306037), (0.79617596, 16, 2, 1, 0.5, 0.83283514, 0.83283514), (0.79976046, 16, 2, 1, 0.5, 0.86705124, 0.86705124), (0.773281, 2, 2, 1, 0.5, 0.93478996, 0.93478996), (0.77558655, 8, 3, 1, 0.5, 0.9289369, 0.9289369), (0.76772887, 3, 2, 1, 0.5, 0.92068434, 0.92068434), (0.7367139, 10, 2, 1, 0.5, 0.8394888, 0.8394888), (0.7768868, 16, 2, 1, 0.5, 0.85205954, 0.85205954), (0.773281, 16, 2, 1, 0.5, 0.90599906, 0.90599906), (0.6148736, 17, 2, 1, 0.5, 0.8345215, 0.8345215), (0.80394316, 0, 2, 0, 0.5, 0.99999994, 0.99999994), (0.8034744, 5, 3, 0, 0.5, 0.9680804, 0.9680804), (0.81877816, 15, 2, 1, 0.5, 0.8202145, 0.8202145), (0.8125763, 16, 2, 1, 0.5, 0.8459116, 0.8459116), (0.7606451, 16, 2, 1, 0.5, 0.81857455, 0.81857455), (0.7989232, 16, 2, 1, 0.5, 0.8319579, 0.8319579), (0.7406298, 16, 2, 1, 0.5, 0.8262902, 0.8262902), (0.8125457, 16, 2, 1, 0.5, 0.81631356, 0.81631356)]\n"
     ]
    }
   ],
   "source": [
    "print(topic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bring_company', 0), ('liquidators_companies', 0), ('brewing_company', 0), ('reinstate_company', 1), ('insolvent_company_liquidation', 1), ('company_voluntary_liquidation', 1), ('putting_company', 0), ('bringing_company', 0), ('voluntary_liquidation', 0), ('taking_company', 0), ('keeping_company', 0), ('liquidation_company', 0), ('liquidate_company', 0), ('solvent_company', 0), ('companies_liquidation', 0), ('reinstating_company', 0), ('insolvent_company', 0), ('reducing_company', 0), ('giving_company', 0), ('allowing_company', 0), ('company_liquidation_pay', 0), ('company_liquidations', 0), ('choosing_company', 0), ('leaving_company', 0), ('liquidating_company', 0), ('company_liquidator', 0), ('companies_into_liquidation', 0), ('company_liquidators', 0), ('company_insolvent', 0), ('suing_company', 0), ('liquidator_company', 0), ('abetting_company', 0), ('company_liquidation', 0), ('company_into_liquidation', 0), ('paying_company', 0), ('liquidated_company', 0), ('running_company', 0), ('having_company', 0), ('placing_company', 0), ('being_company', 0)]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(scores['1'])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bring_company', 0) 0\n",
      "('liquidators_companies', 0) 0\n",
      "('brewing_company', 0) 0\n",
      "('reinstate_company', 1) 0\n",
      "('insolvent_company_liquidation', 1) 0\n",
      "('company_voluntary_liquidation', 1) 0\n",
      "('putting_company', 0) 0\n",
      "('bringing_company', 0) 0\n",
      "('voluntary_liquidation', 0) 0\n",
      "('taking_company', 0) 0\n",
      "('keeping_company', 0) 0\n",
      "('liquidation_company', 0) 0\n",
      "('liquidate_company', 0) 0\n",
      "('solvent_company', 0) 0\n",
      "('companies_liquidation', 0) 0\n",
      "('reinstating_company', 0) 0\n",
      "('insolvent_company', 0) 0\n",
      "('reducing_company', 0) 0\n",
      "('giving_company', 0) 0\n",
      "('allowing_company', 0) 0\n",
      "('company_liquidation_pay', 0) 0\n",
      "('company_liquidations', 0) 0\n",
      "('choosing_company', 0) 0\n",
      "('leaving_company', 0) 0\n",
      "('liquidating_company', 0) 0\n",
      "('company_liquidator', 0) 0\n",
      "('companies_into_liquidation', 0) 0\n",
      "('company_liquidators', 0) 0\n",
      "('company_insolvent', 0) 0\n",
      "('suing_company', 0) 0\n",
      "('liquidator_company', 0) 0\n",
      "('abetting_company', 0) 0\n",
      "('company_liquidation', 0) 0\n",
      "('company_into_liquidation', 0) 0\n",
      "('paying_company', 0) 0\n",
      "('liquidated_company', 0) 0\n",
      "('running_company', 0) 0\n",
      "('having_company', 0) 0\n",
      "('placing_company', 0) 0\n",
      "('being_company', 0) 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted)):\n",
    "    print(scores['1'][i], predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
