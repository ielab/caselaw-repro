{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides visualisations for index document lengths - pre stopword removal - as well as post stopword removal.\n",
    "\n",
    "Also provides for visualisation of word distribution in collections and for stopword list overlaps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything as needed\n",
    "%matplotlib inline\n",
    "\n",
    "from typing import List \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#Set general plot properties\n",
    "sns.set()\n",
    "sns.set_color_codes(\"pastel\")\n",
    "\n",
    "sns.set_context({\"figure.figsize\": (16, 10)})\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc_len_file(path: str):\n",
    "    lens = []\n",
    "    with open(path) as f: \n",
    "        for line in f:\n",
    "            lens.append(int(line.strip()))\n",
    "            \n",
    "    return lens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These doc lens are generated from pre-stopped indices\n",
    "dirs = ['aus', 'aus', 'sigir']\n",
    "\n",
    "index_display_names = ('AUS', 'FILTERED', 'SIGIR')\n",
    "index_names = ['flattened', 'filtered', 'sigir']\n",
    "doc_lens = []\n",
    "stopped_lens = []\n",
    "stop_prefixes = ['prestop-']\n",
    "\n",
    "for i in range(len(stop_prefixes)): \n",
    "    for in_name in index_names: \n",
    "        if i % 2 == 0:\n",
    "            stopped_lens.append(read_doc_len_file(\"../features/{0}{1}-doc_lens.txt\".format(stop_prefixes[i], in_name)))\n",
    "        else:\n",
    "            doc_lens.append(read_doc_len_file(\"../features/{0}{1}-doc_lens.txt\".format(stop_prefixes[i], in_name)))\n",
    "\n",
    "        \n",
    "def plot_lens(lens, names):\n",
    "    fig, axs = plt.subplots(1, len(lens))\n",
    "    fig.set_size_inches(16, 8)\n",
    "    for i in range(len(lens)):\n",
    "        sns.distplot(lens[i], kde=False, ax=axs[i])\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_xlabel(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lens(stopped_lens, index_display_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_whisker_lens(lens, names):\n",
    "    fig, axs = plt.subplots(1, len(lens))\n",
    "    fig.set_size_inches(16, 8)\n",
    "    axs[0].set_ylabel('Doc Len', fontsize='20')\n",
    "    for i in range(len(lens)):\n",
    "        axs[i].boxplot(lens[i])\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_xlabel(names[i], fontsize='20')\n",
    "        \n",
    "    return fig \n",
    "        \n",
    "# plot_bar_whisker_lens(stopped_lens, index_display_names).savefig('doclens.png', bbox_inches = 'tight', pad_inches = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute averages\n",
    "def get_mean_len(lens):\n",
    "    df = pd.DataFrame.from_dict({x: lens[i] for i, x in enumerate(index_names)}, orient='index')\n",
    "    df = df.transpose()\n",
    "    df.mean()\n",
    "    return df.mean().to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_mean_len(stopped_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_countfile(path: str) -> pd.DataFrame: \n",
    "    words = []\n",
    "    counts = []\n",
    "    with open(path) as f: \n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            parts = line.split()\n",
    "            words.append(parts[0])\n",
    "            counts.append(int(parts[1]))\n",
    "            \n",
    "    return pd.DataFrame({'words': words, 'counts': counts})\n",
    "    \n",
    "top_tokens = []\n",
    "for i in index_names: \n",
    "    top_tokens.append(read_countfile(\"../features/{0}-top-tokens.txt\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_tokens(tokens: List[pd.DataFrame], names, n: int): \n",
    "    fig, axs = plt.subplots(1, len(top_tokens))\n",
    "    fig.set_size_inches(16, 8)\n",
    "    axs[0].set_ylabel('Frequency', fontsize=20)\n",
    "    for i in range(len(top_tokens)):\n",
    "        axs[i].plot(top_tokens[i]['counts'][:n])\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].tick_params(labelsize=15)\n",
    "        axs[i].set_xlabel(names[i], fontsize=20)\n",
    "        \n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_tokens(top_tokens, index_display_names, 100).savefig('top-tokens.png', bbox_inches = 'tight', pad_inches = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens[2][:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
