{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "\n",
    "from phdconf import config \n",
    "from phdconf.config import * \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_names = ['AUS']\n",
    "index_names = ['flattened'] #, 'sigir']\n",
    "qrel_paths = [config.AUS_QREL_PATH]\n",
    "rel_levels = [AUS_REL_LEVEL]\n",
    "\n",
    "start = 300\n",
    "end = 3000\n",
    "increment = 50\n",
    "\n",
    "topics = 'case-topics'\n",
    "\n",
    "def load(index_names, qrel_paths, results_path, run_format, rel_levels, _1s, _1e, _1i, _2s, _2e, _2i, per_query=False, filtered=None):\n",
    "    dfs = []\n",
    "    iterator = np.arange(_1s, _1e+_1i, _1i)\n",
    "    # deal with shitty float overflow on np.arange \n",
    "    if iterator[-1] > end: \n",
    "        iterator = iterator[:-1]\n",
    "    for i, ind in enumerate(index_names):\n",
    "        temp = []\n",
    "        for j in np.arange(_2s, _2e+_2s, _2i):\n",
    "            tmp = []\n",
    "            for l in iterator:\n",
    "                tmp.append(to_trec_df(qrel_paths[i], os.path.join(results_path, run_format.format(ind, j, l)), rel_levels[i], per_query, filtered))\n",
    "            temp.append(tmp)\n",
    "        dfs.append(temp)\n",
    "    \n",
    "    return dfs \n",
    "\n",
    "# weight_dfs = load_1d_dfs(index_names, qrel_paths, os.path.join(BASE_DIR, PARA_DIR, 'dirichlet_prior'), base_run+'top-{0}-paras-unigram_dir_mu_{1:.2f}-{2:.2f}-rerank.run', rel_levels, start, end, increment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dfs = load(['case-topics'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'dirichlet_prior') , '{0}-top-{1}-paras-rerank-dir-mu-{2:.2f}.run', rel_levels, start, end, increment, 1, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_res = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, 1050, 1050, 1)[0][0]\n",
    "base_qry = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, 1050, 1050, 1, per_query=True)[0][0]\n",
    "\n",
    "tt_folds = read_folds(AUS_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rerank_sum_para(dfs, base_res, metric_names,  _1s, _1e, _1i, _2s, _2e, _2i):\n",
    "    # r = int((len(metric_names))/2)\n",
    "    # c = r\n",
    "    # print(r, c)    \n",
    "    r = 1\n",
    "    c = 1\n",
    "    fig, axs = plt.subplots(r, c, subplot_kw=dict(projection='3d'))\n",
    "    fig.set_size_inches(16, 8)\n",
    "\n",
    "    num_x = len(dfs[0])\n",
    "    num_y = len(dfs)\n",
    "    print(num_x, num_y)\n",
    "    x = np.array([[i]*num_x for i in np.arange(_2s, _2i+_2e, _2i)])\n",
    "    y = np.array([list(np.arange(_1s, _1i+_1e, _1i))] * num_y)\n",
    "\n",
    "    cnt = 0 \n",
    "    row = 0\n",
    "    for j in metric_names:\n",
    "        axs.zaxis.set_rotate_label(False)\n",
    "        axs.set_zlabel(metric_names[j], fontsize=30, rotation=90,labelpad=33)\n",
    "        axs.set_xlabel('Passages', fontsize=30, rotation=90,labelpad=20)\n",
    "        axs.set_ylabel('$\\mu$', fontsize=30, rotation=90,labelpad=20)\n",
    "        axs.tick_params(labelsize=20)\n",
    "        axs.tick_params(axis='z', pad=15)\n",
    "        \n",
    "        if j == 'unjudged@20':\n",
    "            z = np.array([[k[j] for i, k in enumerate(d)] for d in dfs])\n",
    "        else:\n",
    "            z = np.array([[k[j]-base_res[j] for i, k in enumerate(d)] for d in dfs])\n",
    "        print(len(x), len(x[0]), len(y), len(y[0]), len(z), len(z[0]))\n",
    "\n",
    "        axs.plot_surface(x, y, z, cmap=cm.gray)\n",
    "\n",
    "        cnt += 1 \n",
    "        \n",
    "    # if len(metric_names) % 2 != 0: \n",
    "    #     fig.delaxes(axs[row, -1])\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig1 = plot_rerank_sum_para(weight_dfs[0], base_res, {'rbp@0.80': 'RBP'}, start, end, increment, 1, 10, 1)\n",
    "# fig1.savefig('figures/para-sum-3d.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_1d_max_stat_sig(display_names, dfs, start, increment, name, base_qry, base_df, base_val, path, metrics=None):\n",
    "    measure_max = {}\n",
    "    for i in range(len(display_names)):\n",
    "        for j in range(len(dfs[i])):\n",
    "            for m in dfs[i][j].index:\n",
    "                if m not in metrics: \n",
    "                    continue \n",
    "                val = dfs[i][j][m]\n",
    "                if (display_names[i], metrics[m]) not in measure_max: \n",
    "                    measure_max[(display_names[i], metrics[m])] = {'-': val, name: '{0:.2f}'.format(j*increment+start)}\n",
    "                else: \n",
    "                    if measure_max[(display_names[i], metrics[m])]['-'] < val:\n",
    "                        measure_max[(display_names[i], metrics[m])] = {'-': val, name: '{0:.2f}'.format(j*increment+start)}\n",
    "    \n",
    "    back_metric = {v: k for k, v in metrics.items()}\n",
    "    for k, v in measure_max.items():\n",
    "        if k[1] == 'Unjudged@20':\n",
    "            continue\n",
    "        _l = float(v[name])\n",
    "        if _l == 0.00:\n",
    "            v['-'] = '{0:.4f}'.format(v['-'])\n",
    "        else:\n",
    "            comp = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', [path.format(k[0], float(v[name]))], per_query=True)[0]\n",
    "            p = stats.ttest_rel(base_qry[back_metric[k[1]]], comp[back_metric[k[1]]]).pvalue\n",
    "            if p < 0.01:\n",
    "                v['-'] = '{0:.4f}'.format(v['-'])+'$^{**}$'\n",
    "            elif p < 0.05:\n",
    "                v['-'] = '{0:.4f}'.format(v['-'])+'$^{*}$'\n",
    "            else:\n",
    "                v['-'] = '{0:.4f}'.format(v['-'])\n",
    "                \n",
    "    \n",
    "    for x in base_df.items():\n",
    "        if x[0] not in metrics: \n",
    "            continue\n",
    "        measure_max[('base', metrics[x[0]])] = {'-': '{0:.4f}'.format(x[1]), name: '{0:.2f}'.format(base_val)}\n",
    "        \n",
    "    max_df = pd.DataFrame.from_dict(measure_max).stack().unstack(level=0)\n",
    "    return max_df.reindex(list(metrics.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_max = select_1d_max_stat_sig([str(i) for i in range(1, 11)], weight_dfs[0], 300.0, 50.0, '$\\mu$', base_qry, base_res, 1050, os.path.join(BASE_DIR, 'dirichlet_prior', 'case-topics-top-3-paras-rerank-dir-mu-{1:.2f}.run'), RERANK_METRICS).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_df = pd.DataFrame(base_res)\n",
    "# base_df = base_df[base_df.index.isin(rerank_metrics.keys())].T\n",
    "# base_df.rename(columns=rerank_metrics, inplace=True)\n",
    "# base_df\n",
    "\n",
    "# def create_multi_index_from_base(base_res: pd.Series, metrics, name: str, v: float):\n",
    "#     out = {}\n",
    "#     for x in base_res.items():\n",
    "#         if x[0] not in metrics: \n",
    "#             continue\n",
    "#         out[('base', metrics[x[0]])] = {'-': '{0:.4f}'.format(x[1]), name: '{0:.2f}'.format(v)}\n",
    "#     return out\n",
    "    \n",
    "    \n",
    "# pd.DataFrame(create_multi_index_from_base(base_res, rerank_metrics, '$\\mu$', 1050.00))\n",
    "# base_df\n",
    "print(para_max.drop(['Unjudged@20'], axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dfs = load(['case-topics'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'dirichlet_prior') , '{0}-top-{1}-paras-rerank-dir-mu-{2:.2f}.run', rel_levels, start, end, increment, 1, 10, 1, per_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlm_df = pd.DataFrame(columns=RERANK_METRICS)\n",
    "\n",
    "for ab, runs in zip([str(i) for i in range(1, 11)], weight_dfs[0]):\n",
    "    cross = cross_validation(runs, tt_folds, RERANK_METRICS, base_qry)\n",
    "    ntlm_df.loc[ab] = cross[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlm_df.loc['$R$'] = base_res.round(4)\n",
    "ntlm_df = ntlm_df.reindex(['$R$'] + [str(i) for i in range(1, 11)])\n",
    "\n",
    "# write_table('tables/ausnl-para-top10', bold_max(ntlm_df).rename(columns=RERANK_METRICS).drop('Unjudged@20',axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_comp_df = weight_dfs[0][1][2]-base_qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_comp_fig = qry_comp_df[RERANK_METRICS.keys()].rename(RERANK_METRICS, axis='columns').plot.box(fontsize=15, boxprops=dict(linestyle='-', linewidth=2), medianprops=dict(linestyle='-', linewidth=2), color=dict(boxes='black', whiskers='black', medians='b', caps='r'), figsize=(16, 4)).axhline(y=0, xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qry_comp_fig.get_figure().savefig('figures/ausnl-para-sum-qry-diff.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_res = cross_validation(weight_dfs[0][0], tt_folds, RERANK_METRICS, base_qry)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_comp_res = [x-base_res[i] for i, x in zip(list(RERANK_METRICS.keys()), top_res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries from top para score that have the biggest decrease compared to baseline ... \n",
    "print(list(top_comp_res[-2].sort_values().index[:-14]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start looking at BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interped_dfs = []\n",
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'))\n",
    "for _lambda in np.arange(0, 1.01, 0.01):\n",
    "    inter.interpolate(os.path.join(BASE_DIR, 'bert-rerank', 'case-topics-tinybert-nrm-sum-5.run'), _lambda, 'tmp.run')\n",
    "    interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_top_res = cross_validation(interped_dfs, tt_folds, RERANK_METRICS, base_qry)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_comp = [x-top_res[i] for i, x in enumerate(bert_top_res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame()\n",
    "\n",
    "for m, x in zip(RERANK_METRICS, bert_comp):\n",
    "    a[m] = x\n",
    "\n",
    "om = copy.copy(RERANK_METRICS)\n",
    "del om['unjudged@20']\n",
    "qry_comp_fig = a[om.keys()].rename(RERANK_METRICS, axis='columns').plot.box(fontsize=15, boxprops=dict(linestyle='-', linewidth=2), medianprops=dict(linestyle='-', linewidth=2), color=dict(boxes='black', whiskers='black', medians='b', caps='r'),figsize=(16, 4)).axhline(y=0, xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='grey')\n",
    "# qry_comp_fig.get_figure().savefig('figures/ausnl-bert-toppara-comp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['rbp@0.80'][a['rbp@0.80'] < 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## window df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_dfs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, os.path.join(BASE_DIR, 'dirichlet_prior') , [topics+'-para-rerank-{0}-{1}-context-dir-mu-{2:.2f}.run'.format(x, y, 300) for x in  ['gauss', 'inv', 'exp', 'window'] for y in  [2, 5, 10, 20, 50, 100, 200, 300, 400]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tune_1d_with_ticks(names, metric_names, dfs, ticks, ylims=[], styles=[]): \n",
    "\n",
    "    r = int(len(metric_names)/2)\n",
    "    c = r \n",
    "    fig, axs = plt.subplots(r-1, c)\n",
    "    fig.set_size_inches(16, 6)\n",
    "    cnt = 0 \n",
    "    row = 0\n",
    "    x = [i for i in range(len(ticks))]\n",
    "    for m in metric_names:\n",
    "#         if m in metric_names: \n",
    "        for i, df in enumerate(dfs): \n",
    "            s = None \n",
    "            if i < len(styles): \n",
    "                s = styles[i]\n",
    "            axs[row, cnt].plot(x, [y[m] for y in df], linestyle=s)\n",
    "            \n",
    "            if m.startswith('rbp@'):\n",
    "                es = 'rbp-res@'+m[4:]\n",
    "                axs[row, cnt].fill_between(x, [y[m] for y in df], [y[es]+y[m] for y in df], alpha=0.3)\n",
    "\n",
    "        axs[row, cnt].set_ylabel(metric_names[m],fontsize=18)\n",
    "\n",
    "        axs[row, cnt].tick_params(labelsize=12)\n",
    "        axs[row, cnt].yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        axs[row, cnt].set_xticks(x)\n",
    "        axs[row, cnt].set_xticklabels(ticks)\n",
    "        cnt += 1 \n",
    "        if cnt >= c: \n",
    "            cnt = 0 \n",
    "            row += 1 \n",
    "    \n",
    "    for i in range(len(ylims)):\n",
    "        plt.gcf().get_axes()[i].set_ylim(ymax=ylims[i])\n",
    "    \n",
    "    if len(metric_names) % 2 != 0: \n",
    "        fig.delaxes(axs[row, -1])\n",
    "\n",
    "    fig.legend(names, bbox_to_anchor=[0.96, 0.28], frameon=True, ncol=2, prop={\"size\": 15}).get_frame().set_edgecolor('black')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plot_tune_1d_with_ticks(['base', 'gauss', 'inv', 'exp', 'window'], RERANK_METRICS, [[base_res for x in range(9)]]+[window_dfs[i:i+9] for i in range(0, len(window_dfs), 9)], [2, 5, 10, 20, 50, 75, 100, 150, 200], styles=['--'], ylims=RERANK_YLIMS)\n",
    "# plot_tune_1d_comp(['base', 'gauss', 'inv', 'exp', 'window'], rerank_metrics, [[base_res for x in range(9)]]+[window_dfs[i:i+9] for i in range(0, len(window_dfs), 9)], [2, 5, 10, 20, 50, 75, 100, 150, 200], styles=['--'], ylims=ylims)\n",
    "# plot_tune_1d_comp(['base', 'phrase', 'phrase-exp', 'phrase-qry', 'phrase-exp-qry'], metrics, [[base_df for x in range(to+1)]] + [x[:to+1] for x in dfs], 0.00, (to)/100, 0.01, legend_x=0.991, styles=['--'], ylims=ylims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig2.savefig('figures/ausnl-para-window.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sum_interp = []\n",
    "wind2_interp = []\n",
    "wind_interp = []\n",
    "sum1_interp = []\n",
    "\n",
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'))\n",
    "for _lambda in np.arange(0, 1.01, 0.01):\n",
    "    inter.interpolate(os.path.join(BASE_DIR, 'dirichlet_prior', 'case-topics-top-1-paras-rerank-dir-mu-300.00.run'), _lambda, 'tmp.run')\n",
    "    sum1_interp.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    inter.interpolate(os.path.join(BASE_DIR, 'dirichlet_prior', 'case-topics-top-2-paras-rerank-dir-mu-300.00.run'), _lambda, 'tmp.run')\n",
    "    sum_interp.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    inter.interpolate(os.path.join(BASE_DIR, 'dirichlet_prior', 'case-topics-para-rerank-window-50-context-dir-mu-300.00.run'), _lambda, 'tmp.run')\n",
    "    wind_interp.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    inter.interpolate(os.path.join(BASE_DIR, 'dirichlet_prior', 'case-topics-para-rerank-window-2-context-dir-mu-300.00.run'), _lambda, 'tmp.run')\n",
    "    wind2_interp.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(columns=config.METRIC_NAMES)\n",
    "\n",
    "for ab, runs in zip(['sum-2', 'sum-1', 'wind-2', 'wind-50'], [sum_interp, sum1_interp, wind_interp, wind2_interp]):\n",
    "    cross = cross_validation(runs, tt_folds, config.METRIC_NAMES, base_qry)\n",
    "    cv_df.loc[ab] = cross[0]\n",
    "    \n",
    "cv_df.loc['$R$'] = ['{:.4f}'.format(base_res[m]) for m in config.METRIC_NAMES]\n",
    "cv_df = cv_df.reindex(['$R$', 'sum-1', 'sum-2', 'wind-2', 'wind-50'])\n",
    "# write_table('tables/ausnl-para-comb', bold_max(cv_df).drop(['unjudged@20', 'recall_100'],axis='columns').rename(config.METRIC_NAMES, axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = 15\n",
    "fig3 = plot_tune_1d_comp(['DP', 'sum-2', 'wind-2', 'wind-50'], RERANK_METRICS, \n",
    "                         [[base_res for x in range(len(sum_interp[:to+1]))], \n",
    "                          [x.mean() for x in sum_interp[:to+1]], \n",
    "                          [x.mean() for x in wind2_interp[:to+1]], \n",
    "                          [x.mean() for x in wind_interp[:to+1]]], 0.0, to/100, 0.01, styles=['--'], legend_y=0.4, legend_x=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig3.savefig('figures/para-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_max = select_1d_max_stat_sig(['top-2-paras-rerank', 'para-rerank-window-50-context', 'para-rerank-window-2-context'], [sum_interp, wind_interp, wind2_interp], 0.0, 0.01, '$\\mu$', base_qry, base_res, 1050, os.path.join(BASE_DIR, 'dirichlet_prior', 'case-topics-{0}-dir-mu-300.00.run'), RERANK_METRICS).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interp_max.drop(['Unjudged@20'], axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def upperbound_runs(runs: List[pd.DataFrame]): \n",
    "\n",
    "    n = len(runs)\n",
    "\n",
    "    cols = runs[0].columns\n",
    "    query_maxes = []\n",
    "    for c in cols:\n",
    "        query_maxes.append({})\n",
    "\n",
    "    for i in range(n):\n",
    "        for row in runs[i].iterrows():\n",
    "            for v, (metric, score) in enumerate(row[1].iteritems()):\n",
    "                s = query_maxes[v].get(row[0], None)\n",
    "                if s is None or s[1] < score:\n",
    "                    query_maxes[v][row[0]] = (i, score, row[1]['unjudged@20'])\n",
    "        \n",
    "    return query_maxes\n",
    "\n",
    "\n",
    "def make_upperbound(base_qry: pd.DataFrame, path: str):\n",
    "    names = [x for x in ['gauss', 'inv', 'exp', 'wind']]\n",
    "    names += ['sum', 'base']\n",
    "\n",
    "    configs = ['case-topics-para-rerank-{0}-'.format(x)+str(y)+'-context-dir-mu-300.00.run' for x in ['gauss', 'inv', 'exp', 'window'] for y in [2, 5, 10, 20, 50, 100, 200, 300, 400]]   \n",
    "    configs = [configs[i:i+9] for i in range(0, len(configs), 9)]\n",
    "    configs += [['case-topics-top-{0}-paras-rerank-dir-mu-300.00.run'.format(x) for x in range(1, 11, 1)]]\n",
    "    configs += [['case-topics-filtered-phrasestop-unigram_dir_mu_{0:.2f}.run'.format(x) for x in range(300, 3050, 50)]]\n",
    "#     print(configs)\n",
    "    \n",
    "#     paths = []\n",
    "    paths = [path]*(len(names)-1)\n",
    "    paths.append(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'))\n",
    "\n",
    "    ind = pd.MultiIndex.from_product([base_qry.columns, ['score', 'unjudged']])\n",
    "    \n",
    "    out_df_list = []\n",
    "\n",
    "    for i, name in enumerate(names): \n",
    "\n",
    "        runs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, paths[i], configs[i], per_query=True)\n",
    "        maxes = upperbound_runs(runs)\n",
    "\n",
    "        all_m_dfs = []\n",
    "        for j, x in enumerate(maxes):\n",
    "            tmp = pd.DataFrame.from_dict(x).T\n",
    "            sig = stats.ttest_rel(base_qry[base_qry.columns[j]].fillna(0).values, tmp[1].fillna(0).values).pvalue\n",
    "            m = tmp.mean()\n",
    "            if sig < 0.01:\n",
    "                m.loc[1] = \"{:.4f}\".format(m.loc[1]) + \"$^{**}$\"\n",
    "            elif sig < 0.05:\n",
    "                m.loc[1] = \"{:.4f}\".format(m.loc[1]) + \"$^{*}$\"\n",
    "            else: \n",
    "                m.loc[1] = '{0:.4f}'.format(m.loc[1])\n",
    "\n",
    "            m.index=['lambda', 'score', 'unjudged']\n",
    "\n",
    "            all_m_dfs.append((name, 'score', base_qry.columns[j], m['score']))\n",
    "            all_m_dfs.append((name, 'unjudged', base_qry.columns[j], m['unjudged']))\n",
    "\n",
    "        df = pd.DataFrame(all_m_dfs, index=ind)\n",
    "        df.columns=['run', '', 'metric', name]\n",
    "        out_df_list.append(df[name])\n",
    "        \n",
    "    return out_df_list\n",
    "\n",
    "base_qry = load_1d_dfs(['filtered-phrasestop'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, 2400, 2400, 1, per_query=True)[0][0]\n",
    "ub_no_interp = make_upperbound(base_qry, os.path.join(BASE_DIR, 'dirichlet_prior'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_metrics = copy.deepcopy(config.METRIC_NAMES)\n",
    "del ub_metrics['recall_100']\n",
    "\n",
    "df = pd.DataFrame(ub_no_interp)\n",
    "# df.index = names\n",
    "df = df.round(4)\n",
    "df = df.T.loc[list(ub_metrics.keys())]\n",
    "df = pd.DataFrame(df, index=pd.MultiIndex.from_product([['recip_rank', 'err@20', 'recall_20', 'ndcg', 'rbp@0.80'], ['score', 'unjudged']]))\n",
    "df.index.set_levels(['-', 'unjudged'], level=1, inplace=True)\n",
    "# df.index.set_levels(list(ub_metrics.values()), level=0, inplace=True)\n",
    "# df \n",
    "print(df.T.to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plot_tune_1d_comp(['window-50-context', 'base'], rerank_metrics, [wind_interp, [base_res for x in range(len(wind_interp))]], 0.0, 1.0, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_para_dfs(qrel_path, results_path, run_format, rel_level, start, end, increment, per_query=False):\n",
    "    dfs = []\n",
    "    iterator =  np.arange(start, end, increment)\n",
    "\n",
    "    for j in range(1, 11, 1):\n",
    "        top_k_temp = []\n",
    "        for l in iterator:\n",
    "            top_k_temp.append(to_trec_df(qrel_path, os.path.join(results_path, run_format.format(l, j)), rel_level, per_query))\n",
    "        dfs.append(top_k_temp)\n",
    "    \n",
    "    return dfs \n",
    "\n",
    "para_dfs = load_para_dfs(qrel_paths[0], os.path.join(BASE_DIR, 'dirichlet_prior'), 'case-topics-top-{1}-paras-rerank-dir-mu-{0:.2f}.run', rel_levels[0], 300, 3050, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_para(para_dfs, start, end, increment, metric_names):\n",
    "    num_x = len(para_dfs[0])\n",
    "    num_y = len(para_dfs)\n",
    "\n",
    "    x = np.array([[i]*num_x for i in range(1, 11)])\n",
    "    y = np.array([list(np.arange(start, end+increment, increment))] * num_y)\n",
    "\n",
    "    fig, axs = plt.subplots(2, int(len(metric_names)/2)+1, subplot_kw=dict(projection='3d'))\n",
    "    fig.set_size_inches(16, 10)\n",
    "\n",
    "    row = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for j in metric_names:\n",
    "        z = np.array([[l[j] for l in w] for w in para_dfs]).mean(axis=2)\n",
    "        axs[row, cnt].set_zlabel(metric_names[j], fontsize=20)\n",
    "\n",
    "        axs[row, cnt].tick_params(labelsize=15)\n",
    "        axs[row, cnt].yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        axs[row, cnt].plot_surface(x, y, z, cmap=cm.gray) \n",
    "\n",
    "        cnt+=1\n",
    "        if cnt > 2: \n",
    "            cnt = 0 \n",
    "            row += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "            \n",
    "plot_3d_para(weight_dfs[0], 300, end, increment, RERANK_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tune_1d(metric_names, df, start, end, increment): \n",
    "    fig, axs = plt.subplots(1, len(metric_names))\n",
    "    fig.set_size_inches(16, 10)\n",
    "    for j in range(len(metric_names)):\n",
    "        y = [y[j] for y in df]\n",
    "        axs[j].plot(np.arange(start, end, increment), y)\n",
    "        axs[j].set_ylabel(metric_names[j],fontsize=20)\n",
    "\n",
    "        if j == 1:\n",
    "            axs[j].set_xlabel('$\\mu$', fontsize=20)\n",
    "\n",
    "        axs[j].tick_params(labelsize=15)\n",
    "        axs[j].yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tune_1d(['RR', 'NDCG', 'RBP@0.2'], para_dfs[-1], 300, 3050, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = load_1d_dfs(['case-topics'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), '{0}-filtered-phrasestop-unigram_dir_mu_{1:.2f}.run', rel_levels, 300, end, increment)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subtracted from baseline dirichlet prior run score \n",
    "def plot_tune_1d_subtract(metric_names, df, baseline, start, end, increment): \n",
    "    fig, axs = plt.subplots(2, int(len(metric_names)/2)+1)\n",
    "    fig.set_size_inches(16, 10)\n",
    "    cnt = 0\n",
    "    x_val = np.arange(start, end, increment)\n",
    "    row = 0 \n",
    "    for j in metric_names:\n",
    "        ys = [[y[j]-baseline for y in x] for x in df]\n",
    "        for y in ys: \n",
    "            axs[row, cnt].plot(x_val, y)\n",
    "        axs[row, cnt].set_ylabel(metric_names[j],fontsize=20)\n",
    "#         axs[row, cnt].legend(range(1, 11, 1))\n",
    "\n",
    "        axs[row, cnt].tick_params(labelsize=15)\n",
    "        axs[row, cnt].yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        cnt+=1\n",
    "        if cnt > 2: \n",
    "            cnt = 0 \n",
    "            row+= 1\n",
    "\n",
    "    fig.delaxes(axs[1, 2])\n",
    "    fig.legend(range(1, 11, 1), bbox_to_anchor=[0.85, 0.46], frameon=True, ncol=2, prop={\"size\": 15}).get_frame().set_edgecolor('black')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tune_1d_subtract(RERANK_METRICS, weight_dfs[0], res[0], 300, 3050, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further comparison between window and sum \n",
    "\n",
    "I coulnd't be bothered making another table so just did stat sig and created table file manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_2_res = load_1d_dfs(['top'], qrel_paths, os.path.join(BASE_DIR, 'dirichlet_prior'), 'case-topics-top-2-paras-rerank-dir-mu-{1:.2f}.run', rel_levels, 300, 300, 1, per_query=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_2_res = load_1d_dfs(['top'], qrel_paths, os.path.join(BASE_DIR, 'dirichlet_prior'), 'case-topics-para-rerank-window-2-context-dir-mu-{1:.2f}.run', rel_levels, 300, 300, 1, per_query=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_2_res[config.METRIC_NAMES].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_2_res[config.METRIC_NAMES].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in config.METRIC_NAMES:\n",
    "    print(metric, stats.ttest_rel(top_2_res[metric], wind_2_res[metric]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
