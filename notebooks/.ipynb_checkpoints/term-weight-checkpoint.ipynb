{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys \n",
    "import os \n",
    "\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "\n",
    "from phdconf import stop\n",
    "from phdconf import config \n",
    "\n",
    "from typing import List, Dict\n",
    "import math \n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(config.AUS_TOPIC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(path: str):\n",
    "    embeddings = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            values = line.rstrip().rsplit(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "embeddings = load_vectors('/home/danlocke/fastText/filtered-100d.vec')\n",
    "\n",
    "class EmbMethod:\n",
    "    SUM = 0\n",
    "    MEAN = 1 \n",
    "    CF_SUM = 2 \n",
    "    CF_MEAN = 3\n",
    "\n",
    "def embed(tokens: List[str], embeddings, dim: int=100, method: EmbMethod = EmbMethod.SUM, coll_stats = None) -> np.array:\n",
    "    e = []\n",
    "    if method > EmbMethod.MEAN: \n",
    "        for x in tokens: \n",
    "            if x in embeddings:\n",
    "                mul = coll_stats[x] if x in coll_stats else 1.0\n",
    "                e.append(mul * embeddings[x])\n",
    "    else: \n",
    "        e = [embeddings[x] for x in tokens if x in embeddings]\n",
    "    if len(e) == 0:\n",
    "        return np.zeros((dim,), dtype='float32')\n",
    "    \n",
    "    e = np.sum(e, axis=0)\n",
    "    if method == EmbMethod.MEAN or method == EmbMethod.CF_MEAN:\n",
    "        e /= len(tokens)\n",
    "            \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_vectors('/home/danlocke/fastText/filtered-100d.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_embeddings = load_vectors('/home/danlocke/fastText/para-phrase-100d.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = {\n",
    "    'first', \n",
    "    'second', \n",
    "    'third',\n",
    "    'fourth',\n",
    "    'fifth',\n",
    "    'sixth',\n",
    "    'seventh',\n",
    "    'eighth',\n",
    "    'ninth',\n",
    "    'tenth',\n",
    "    'eleventh',\n",
    "    'twelfth',\n",
    "    'thirteenth',\n",
    "    'fourteenth',\n",
    "    'fifteenth',\n",
    "    'sixteenth',\n",
    "    'seventeenth',\n",
    "    'eighteenth',\n",
    "    'nineteenth',\n",
    "    'twenty',\n",
    "    'thirty',\n",
    "    'fourty',\n",
    "}\n",
    "\n",
    "num_exclusion = {\n",
    "    'amendment',\n",
    "    'degree',\n",
    "    'refusal'\n",
    "}\n",
    "\n",
    "find2 = {\n",
    "    'north',\n",
    "    'south',\n",
    "    'east',\n",
    "    'west'\n",
    "}\n",
    "\n",
    "find3 = {\n",
    "    'set',\n",
    "    'hold',\n",
    "    'exemplary',\n",
    "    'intending',\n",
    "    'include',\n",
    "    'including',\n",
    "    'relies',\n",
    "    'relied',\n",
    "    'pursuant',\n",
    "    'thereto',\n",
    "    'behalf',\n",
    "    'giving',\n",
    "    'give',\n",
    "    'apparently',\n",
    "    'subsequently',\n",
    "    'jurisdictional',\n",
    "    'included',\n",
    "    'includes',\n",
    "    'appellant',\n",
    "    'respondent',\n",
    "    'resulting',\n",
    "    'such',\n",
    "    's',\n",
    "    'x',\n",
    "    't',\n",
    "    'th',\n",
    "    'thing',\n",
    "    're',\n",
    "    'subject'\n",
    "}\n",
    "\n",
    "find4 = {\n",
    "    'nonetheless',\n",
    "    'follows',\n",
    "    'referred',\n",
    "    'thereto',\n",
    "    'behalf',\n",
    "    'hastily',\n",
    "    'instance',\n",
    "    'instances',\n",
    "    'such',\n",
    "    's',\n",
    "    'applicant',\n",
    "    'applicants',\n",
    "    'respondent',\n",
    "    'respondents',\n",
    "    'th',\n",
    "    'x',\n",
    "    'such',\n",
    "    'll',\n",
    "    'only',\n",
    "    'way',\n",
    "    're',\n",
    "    'much',\n",
    "    'st',\n",
    "    'consideration',\n",
    "    'organisation'\n",
    "}\n",
    "\n",
    "#     consider 'made' and 'make' as exclusions\n",
    "\n",
    "def filter_phrases(phrases, splitter=' '):\n",
    "    d = isinstance(phrases, dict)\n",
    "    if d:\n",
    "        ret = {}\n",
    "    else:\n",
    "        ret = []\n",
    "    for phrase in phrases:\n",
    "        toks = phrase.split(splitter)\n",
    "        if len(toks) < 2:\n",
    "            continue \n",
    "        \n",
    "        cont = False \n",
    "        cnt = 0\n",
    "\n",
    "        if toks[-1] in find3 or len(toks[-1]) == 1:\n",
    "            continue\n",
    "        \n",
    "        if len(toks) == 2 and toks[0].startswith('claim'):\n",
    "            continue\n",
    "            \n",
    "        if len(toks) == 3 and toks[0] == 'intention' and toks[1] != 'to':\n",
    "            continue\n",
    "            \n",
    "        if toks[0] == 'intention' and len(toks) == 2:\n",
    "            continue\n",
    "            \n",
    "        if toks[0] in find4 or len(toks[0]) == 1:\n",
    "            continue\n",
    "            \n",
    "        unique = set()\n",
    "            \n",
    "        num = False \n",
    "        num_ex = False\n",
    "        for t, tok in enumerate(toks):\n",
    "            unique.add(tok)\n",
    "            \n",
    "            if tok in find: \n",
    "                num = True \n",
    "            if tok in num_exclusion:\n",
    "                num_ex = True\n",
    "            if tok in find2:\n",
    "                cnt += 1 \n",
    "            if tok == 'nunc' and t != 0:\n",
    "                cont = True \n",
    "                break\n",
    "                \n",
    "        if num and not num_ex: \n",
    "            continue\n",
    "        \n",
    "        if len(toks) > len(unique): \n",
    "            continue\n",
    "    \n",
    "        if cont or cnt > 1:\n",
    "            continue \n",
    "            \n",
    "        if d: \n",
    "            ret[phrase] = phrases[phrase]\n",
    "        else:\n",
    "            ret.append(phrase)\n",
    "        \n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coll_stats(path: str, total=None) -> Dict[str, float]:\n",
    "    stats = {}\n",
    "    \n",
    "    idf = total is None\n",
    "    if idf:\n",
    "        total = 0.0\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            if idf: \n",
    "                v = float(parts[-1])\n",
    "                total += v\n",
    "                stats[' '.join(parts[:-1])] = v\n",
    "            else:\n",
    "                stats[' '.join(parts[:-1])] = math.log(total / float(parts[-1])+1.0) + 1.0\n",
    "    \n",
    "    if idf: \n",
    "        for k, v in stats.items():\n",
    "            stats[k] = math.log(total / v+1.0) + 1.0\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_stats = load_coll_stats('/home/danlocke/phd-generated/filtered-stop-top-tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_embeddings = filter_phrases(phrase_embeddings, '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in phrase_embeddings if x.endswith('_date')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(tokens: List[str], n: int): \n",
    "    ret = []\n",
    "    for i in range(0, len(tokens)-(n-1)):\n",
    "           ret.append('_'.join(tokens[i:i+n]))\n",
    "           \n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the effect of reinstating a company that was in liquidation as regards money that may be recovered?\n",
      "[('company', 0.7679199), ('liquidation', 0.73408693), ('money', 0.69507045), ('recovered', 0.6855011), ('reinstating', 0.61489415), ('may', 0.55273366), ('what', 0.5356588), ('effect', 0.52630407), ('regards', 0.5105081)]\n",
      "[('company', 0.76757026), ('liquidation', 0.74729365), ('recovered', 0.6891548), ('money', 0.6759849), ('reinstating', 0.65781003), ('may', 0.53240055), ('effect', 0.5117331), ('regards', 0.50749296), ('what', 0.49963984)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('company', 0.76757026), ('liquidation', 0.74729365), ('recovered', 0.6891548), ('money', 0.6759849), ('reinstating', 0.65781003), ('may', 0.53240055), ('effect', 0.5117331), ('regards', 0.50749296), ('what', 0.49963984)]\n",
      "['what', 'effect', 'reinstating', 'company', 'liquidation', 'regards', 'money', 'may', 'recovered']\n",
      "OrderedDict([('reinstating_company', (2, 2)), ('company_liquidation', (3, 2))])\n",
      "----------------------------------------\n",
      "Is the variation of the date for settlement required to be in writing?\n",
      "[('variation', 0.78699005), ('writing', 0.76102126), ('settlement', 0.7436728), ('date', 0.72736233), ('required', 0.62334573)]\n",
      "[('variation', 0.8056491), ('writing', 0.7596391), ('settlement', 0.7583593), ('date', 0.70832604), ('required', 0.60311615)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('variation', 0.8056491), ('writing', 0.7596391), ('settlement', 0.7583593), ('date', 0.70832604), ('required', 0.60311615)]\n",
      "['variation', 'date', 'settlement', 'required', 'writing']\n",
      "OrderedDict([('variation_date', (0, 2)), ('date_settlement', (1, 2))])\n",
      "----------------------------------------\n",
      "Maintenance and champerty and the requisite degree of control\n",
      "[('maintenance', 0.7192178), ('control', 0.699619), ('requisite', 0.6955093), ('champerty', 0.6604107), ('degree', 0.65938234)]\n",
      "[('champerty', 0.7522079), ('maintenance', 0.7195898), ('control', 0.65209115), ('requisite', 0.64794755), ('degree', 0.60217756)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('champerty', 0.7522079), ('maintenance', 0.7195898), ('control', 0.65209115), ('requisite', 0.6479475), ('degree', 0.6021775)]\n",
      "['maintenance', 'champerty', 'requisite', 'degree', 'control']\n",
      "OrderedDict([('maintenance_champerty', (0, 2)), ('requisite_degree_control', (2, 3)), ('requisite_degree', (2, 2)), ('degree_control', (3, 2))])\n",
      "----------------------------------------\n",
      "agency fees and effective cause of sale of a boat\n",
      "[('sale', 0.7037167), ('agency', 0.6741427), ('fees', 0.63262063), ('boat', 0.61630666), ('effective', 0.5852676), ('cause', 0.49422655)]\n",
      "[('sale', 0.7013313), ('agency', 0.6830042), ('boat', 0.6445059), ('fees', 0.6337164), ('effective', 0.56915843), ('cause', 0.46515664)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('sale', 0.70133126), ('agency', 0.68300414), ('boat', 0.6445059), ('fees', 0.63371634), ('effective', 0.56915843), ('cause', 0.4651566)]\n",
      "['agency', 'fees', 'effective', 'cause', 'sale', 'boat']\n",
      "OrderedDict([('agency_fees', (0, 2)), ('effective_cause_sale', (2, 3)), ('effective_cause', (2, 2)), ('cause_sale', (3, 2))])\n",
      "----------------------------------------\n",
      "Should damages be reduced according to a sum that represents betterment\n",
      "[('sum', 0.7577501), ('damages', 0.7160471), ('reduced', 0.691999), ('represents', 0.65258837), ('betterment', 0.6305993), ('should', 0.6061266), ('according', 0.5690426)]\n",
      "[('sum', 0.7322294), ('damages', 0.70182997), ('betterment', 0.6977618), ('reduced', 0.6856158), ('represents', 0.65334797), ('should', 0.57414013), ('according', 0.5526336)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('sum', 0.7322295), ('damages', 0.70182997), ('betterment', 0.6977619), ('reduced', 0.6856159), ('represents', 0.653348), ('should', 0.57414013), ('according', 0.55263364)]\n",
      "['should', 'damages', 'reduced', 'according', 'sum', 'represents', 'betterment']\n",
      "OrderedDict()\n",
      "----------------------------------------\n",
      "Consideration of a clause that provides that the contract is subject to the buyer being satisfied, in its absolute discretion, with the due diligence by a date\n",
      "[('buyer', 0.6547602), ('contract', 0.65431327), ('subject', 0.6445586), ('diligence', 0.6259593), ('due', 0.62471694), ('consideration', 0.61441404), ('date', 0.61348575), ('clause', 0.6078902), ('discretion', 0.5842923), ('absolute', 0.5622331), ('satisfied', 0.54778343), ('provides', 0.5257542), ('being', 0.50987375)]\n",
      "[('buyer', 0.68469036), ('contract', 0.67212623), ('diligence', 0.64553255), ('subject', 0.6258679), ('due', 0.6144844), ('clause', 0.6142974), ('consideration', 0.5989943), ('date', 0.5980722), ('discretion', 0.57400113), ('absolute', 0.57284784), ('satisfied', 0.5252827), ('provides', 0.51246583), ('being', 0.48923454)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('buyer', 0.68469036), ('contract', 0.67212623), ('diligence', 0.64553255), ('subject', 0.6258679), ('due', 0.61448437), ('clause', 0.6142974), ('consideration', 0.5989943), ('date', 0.5980722), ('discretion', 0.57400113), ('absolute', 0.57284784), ('satisfied', 0.5252826), ('provides', 0.5124658), ('being', 0.4892345)]\n",
      "['consideration', 'clause', 'provides', 'contract', 'subject', 'buyer', 'being', 'satisfied', 'absolute', 'discretion', 'due', 'diligence', 'date']\n",
      "OrderedDict([('absolute_discretion', (8, 2)), ('due_diligence', (10, 2)), ('diligence_date', (11, 2))])\n",
      "----------------------------------------\n",
      "Maintenance and champerty\n",
      "[('champerty', 0.8880645), ('maintenance', 0.81635755)]\n",
      "[('champerty', 0.931509), ('maintenance', 0.7510519)]\n",
      "here\n",
      "here\n",
      "here\n",
      "[('champerty', 0.931509), ('maintenance', 0.7510519)]\n",
      "['maintenance', 'champerty']\n",
      "OrderedDict([('maintenance_champerty', (0, 2))])\n",
      "----------------------------------------\n",
      "proportionality as a basis for striking out a defamation claim\n",
      "[('claim', 0.7355147), ('striking', 0.71465445), ('defamation', 0.6903335), ('out', 0.62900215), ('basis', 0.60654944), ('proportionality', 0.5251848)]\n",
      "[('striking', 0.7275598), ('out', 0.71768403), ('claim', 0.67576575), ('defamation', 0.66079485), ('basis', 0.54887503), ('proportionality', 0.5254767)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('striking', 0.7275598), ('out', 0.71768403), ('claim', 0.67576575), ('defamation', 0.66079485), ('basis', 0.54887503), ('proportionality', 0.5254767)]\n",
      "['proportionality', 'basis', 'striking', 'out', 'defamation', 'claim']\n",
      "OrderedDict([('striking_out', (2, 2)), ('defamation_claim', (4, 2))])\n",
      "----------------------------------------\n",
      "In trade or commerce\n",
      "[('commerce', 0.94189405), ('trade', 0.91851616)]\n",
      "[('commerce', 0.94917154), ('trade', 0.90944284)]\n",
      "here\n",
      "here\n",
      "here\n",
      "[('commerce', 0.94917154), ('trade', 0.90944284)]\n",
      "['trade', 'commerce']\n",
      "OrderedDict([('trade_commerce', (0, 2))])\n",
      "----------------------------------------\n",
      "Whether membership of an organisation is in trade or commerce\n",
      "[('trade', 0.7867799), ('commerce', 0.7711893), ('organisation', 0.70854974), ('membership', 0.6713328), ('whether', 0.54086834)]\n",
      "[('trade', 0.79245096), ('commerce', 0.7888846), ('organisation', 0.7077155), ('membership', 0.6653277), ('whether', 0.50579727)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('trade', 0.79245096), ('commerce', 0.7888846), ('organisation', 0.7077155), ('membership', 0.6653277), ('whether', 0.50579727)]\n",
      "['whether', 'membership', 'organisation', 'trade', 'commerce']\n",
      "OrderedDict([('membership_organisation', (1, 2)), ('trade_commerce', (3, 2))])\n",
      "----------------------------------------\n",
      "Organisations owing members a duty of care\n",
      "[('duty', 0.72501075), ('care', 0.7036011), ('members', 0.68381035), ('organisations', 0.6055408), ('owing', 0.59947324)]\n",
      "[('duty', 0.70817304), ('care', 0.6873237), ('members', 0.68381315), ('organisations', 0.62738156), ('owing', 0.6089785)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('duty', 0.70817304), ('care', 0.68732375), ('members', 0.6838132), ('organisations', 0.62738156), ('owing', 0.6089785)]\n",
      "['organisations', 'owing', 'members', 'duty', 'care']\n",
      "OrderedDict([('duty_care', (3, 2))])\n",
      "----------------------------------------\n",
      "That proprietary relief is only available after rescission \n",
      "[('rescission', 0.7518514), ('only', 0.72400475), ('proprietary', 0.70040137), ('relief', 0.695506), ('available', 0.6438787), ('after', 0.5403242)]\n",
      "[('rescission', 0.7950756), ('proprietary', 0.73000205), ('relief', 0.6976313), ('only', 0.67940676), ('available', 0.60402167), ('after', 0.4925675)]\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "[('rescission', 0.7950756), ('proprietary', 0.73000205), ('relief', 0.6976314), ('only', 0.6794068), ('available', 0.60402167), ('after', 0.49256754)]\n",
      "['proprietary', 'relief', 'only', 'available', 'after', 'rescission']\n",
      "OrderedDict([('proprietary_relief', (0, 2))])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "\n",
    "for topic in queries.values(): \n",
    "    print(topic['topic'])\n",
    "    tokens = topic['topic'].lower().replace(',', '').replace('?', '').replace('\\'', '').replace('/', '').replace('’', '').split()\n",
    "    tokens = [x for x in tokens if x not in stop.stop]\n",
    "    diff_tokens = copy.copy(tokens)\n",
    "    keep = {}\n",
    "    for grams in [n_gram(tokens, 2), n_gram(tokens, 3)]:\n",
    "        for i, gram in enumerate(grams):\n",
    "            if gram in phrase_embeddings:\n",
    "                keep[gram] = (i, len(gram.split('_')))\n",
    "    for meth in [EmbMethod.SUM, EmbMethod.CF_SUM, EmbMethod.CF_MEAN]:\n",
    "        qry_vec = embed(tokens, embeddings, method=meth, coll_stats=coll_stats).reshape(1, -1)\n",
    "        tok_vecs = [embed([tok], embeddings, method=meth, coll_stats=coll_stats).reshape(1, -1) for tok in tokens]\n",
    "        sims = [(tokens[i], cosine_similarity(tok_vecs[i], qry_vec)[0][0]) for i in range(len(tokens))]\n",
    "        print(sorted(sims, key= lambda x: x[1], reverse=True))\n",
    "    \n",
    "    print(tokens)\n",
    "    keep = OrderedDict(sorted(keep.items(), key=lambda t: (t[1][0], -t[1][1])))\n",
    "    print(keep)\n",
    "    print('-'*40)\n",
    "    if cnt > 10:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
