{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys \n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "\n",
    "from phdconf import config \n",
    "from phdconf.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(config.AUS_TOPIC_PATH)\n",
    "tt_folds = read_folds(AUS_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['case-topics']\n",
    "qrel_paths = [config.AUS_QREL_PATH] * len(index_names)\n",
    "rel_levels = [config.AUS_REL_LEVEL] * len(index_names)\n",
    "display_names = ['base', 'sec-count', 'leg-count', 'date', 'hierarchy']\n",
    "\n",
    "topics = 'case-topics'\n",
    "\n",
    "to = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1050\n",
    "base_df = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, mu, mu, 1)[0][0]\n",
    "sdm_base_df = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'sdm_rerank'), 'case-topics-{0}-sdm_rerank-dir-mu-{1:.2f}-weights-0.85-0.00-0.15-window-2.run', rel_levels, mu, mu, 1)[0][0]\n",
    "base_qry = load_1d_dfs(['filtered-phrasestop'], qrel_paths, os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', rel_levels, mu, mu, 1, per_query=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Linker:\n",
    "#     def __init__(self, path: str, id_path: str):\n",
    "#         self._lookup = {}\n",
    "#         with open(id_path) as f:\n",
    "#             for line in f:\n",
    "#                 parts = line.split()\n",
    "#                 self._lookup[parts[0].upper()] = int(parts[1])\n",
    "\n",
    "#         self._lookup_ind = ['']*len(self._lookup)\n",
    "#         for k, v in self._lookup.items():\n",
    "#             self._lookup_ind[v] = k\n",
    "        \n",
    "#         self._inlinks = [None]*len(self._lookup)\n",
    "#         self._outlinks = [None]*len(self._lookup)\n",
    "\n",
    "#         with open(path) as f:\n",
    "#             for line in f:\n",
    "#                 parts = list(map(int, line.split()))\n",
    "                \n",
    "#                 if self._inlinks[parts[1]] == None:\n",
    "#                     self._inlinks[parts[1]] = []\n",
    "#                 self._inlinks[parts[1]].append((parts[0], parts[2]))\n",
    "\n",
    "#                 if self._outlinks[parts[0]] == None:\n",
    "#                     self._outlinks[parts[0]] = []\n",
    "#                 self._outlinks[parts[0]].append((parts[1], parts[2]))\n",
    "                \n",
    "#     def ids(self):\n",
    "#         return self._lookup_ind\n",
    "    \n",
    "#     def out_links(self): \n",
    "#         return self._outlinks\n",
    "    \n",
    "#     def in_links(self): \n",
    "#         return self._inlinks\n",
    "                \n",
    "#     def get_links_for_id(_id: str, vals, count:bool = False):\n",
    "#         ind = self._lookup.get(_id.toupper(), None)\n",
    "#         if ind != None:\n",
    "#             if count:\n",
    "#                 _sum = 0\n",
    "#                 for i in vals[ind]:\n",
    "#                     _sum += i[1]\n",
    "#                 return _sum\n",
    "#             return len(vals[ind])\n",
    "#         return 0\n",
    "\n",
    "# linker = Linker(os.path.join(os.environ[\"HOME\"], \"go/src/cit-extract/links.txt\"), os.path.join(os.environ[\"HOME\"], \"go/src/cit-extract/id-lookup.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get list of documents and relevance list \n",
    "# def get_qrel_rel_docs(path: str): \n",
    "#     out = set()\n",
    "#     with open(path) as f:\n",
    "#         for line in f:\n",
    "#             parts = line.strip().split()\n",
    "#             if int(parts[3]) > 0:\n",
    "#                 out.add(parts[2])\n",
    "                \n",
    "#     return out\n",
    "\n",
    "# def get_bin(v, bins): \n",
    "#     for i in range(1, len(bins)): \n",
    "# #         print(v, bins)\n",
    "#         if v < bins[i]: \n",
    "#             return i-1\n",
    "#     return 0 \n",
    "\n",
    "# def get_rel_vals(qrels, lookup, bins):\n",
    "#     vals = [0.0] * len(qrels)\n",
    "#     for i, q in enumerate(qrels):\n",
    "#         vals[i] = lookup.get(q, True)\n",
    "    \n",
    "#     bin_cnt = [0] * (len(bins)-1)\n",
    "#     for i, v in enumerate(vals): \n",
    "#         bin_cnt[get_bin(v, bins)] +=1\n",
    "    \n",
    "#     return bin_cnt\n",
    "    \n",
    "# def get_buckets(data):\n",
    "#     print(data[:10])\n",
    "#     df = pd.DataFrame(data)\n",
    "#     bucketed, bins = pd.cut(df[0], 100, retbins=True)\n",
    "#     return bucketed, bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets = 54\n",
    "\n",
    "# rel_docs = get_qrel_rel_docs(config.AUS_QREL_PATH)\n",
    "\n",
    "# in_links = linker.in_links()\n",
    "# out_links = linker.out_links()\n",
    "\n",
    "# inlink = [len(x) if x is not None else 0 for x in in_links]\n",
    "# outlink = [len(x) if x is not None else 0 for x in out_links]\n",
    "\n",
    "# sum_in = []\n",
    "# for x in in_links: \n",
    "#     if x is not None:\n",
    "#         sum_in.append(sum([y[1] for y in x]))\n",
    "#     else:\n",
    "#         sum_in.append(0)\n",
    "# sum_out = []\n",
    "# for x in out_links:\n",
    "#     if x is not None:\n",
    "#         sum_out.append(sum([y[1] for y in x]))\n",
    "#     else:\n",
    "#         sum_out.append(0)\n",
    "\n",
    "# rel = [True if x in rel_docs else False for x in linker.ids()]\n",
    "\n",
    "# labels = [x for x in range(1, buckets+1)]\n",
    "\n",
    "# len_df = pd.DataFrame({'id': [x.upper() for x in doc_lens.keys()], 'lens': list(doc_lens.values())}).set_index(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "dfs = []\n",
    "for d in display_names[1:]: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'case-topics-{0}.run'.format(d)), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'])[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = 15\n",
    "link_text_fig = plot_tune_1d_comp(['base', 'sections', 'legislation'], RERANK_METRICS, \n",
    "                    [[base_df for x in range(to+1)]] + [x[:to+1] for x in dfs[:2]], 0.00, (to)/100, 0.01, legend_x=0.965, ylims=RERANK_YLIMS, styles=['--'])\n",
    "# link_text_fig.savefig('figures/ausnl-legref-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = 99\n",
    "link_text_fig = plot_tune_1d_comp(['base', 'date'], RERANK_METRICS, \n",
    "                    [[base_df for x in range(to+1)]] + [x[:to+1] for x in dfs[2:3]], 0.00, (to)/100, 0.01, legend_x=0.965, ylims=RERANK_YLIMS, styles=['--'])\n",
    "# link_text_fig.savefig('figures/ausnl-date-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = 40\n",
    "link_text_fig = plot_tune_1d_comp(['base', 'hierarchy'], RERANK_METRICS, \n",
    "                    [[base_df for x in range(to+1)]] + [x[:to+1] for x in dfs[3:4]], 0.00, (to)/100, 0.01, legend_x=0.965, ylims=RERANK_YLIMS, styles=['--'])\n",
    "# link_text_fig.savefig('figures/ausnl-hierarchy-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "q_dfs = []\n",
    "for d in display_names[1:]: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'case-topics-{0}.run'.format(d)), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    q_dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=RERANK_METRICS)\n",
    "\n",
    "for ab, runs in zip(['sec', 'leg', 'date', 'hierarchy'], q_dfs):\n",
    "    cross = cross_validation(runs, tt_folds, RERANK_METRICS, base_qry)\n",
    "    df.loc[ab] = cross[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['$R$'] = base_df.round(4)\n",
    "\n",
    "date_df = df.reindex(['$R$', 'date'])\n",
    "# write_table('tables/ausnl-date', bold_max(date_df).rename(columns=RERANK_METRICS).drop('Unjudged@20',axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_df = df.reindex(['$R$', 'sec', 'leg'])\n",
    "# write_table('tables/ausnl-leg', bold_max(leg_df).rename(columns=RERANK_METRICS).drop('Unjudged@20',axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_df = df.reindex(['$R$', 'hierarchy'])\n",
    "# write_table('tables/ausnl-hierarchy', bold_max(h_df).rename(columns=RERANK_METRICS).drop('Unjudged@20',axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_max = select_1d_max_with_interp(display_names[1:], dfs, 0.0, 0.01, '$\\lambda$', inter, base_qry, base_df, 1050, os.path.join(BASE_DIR, 'case-topics-{0}.run'), config.AUS_QREL_PATH, config.AUS_REL_LEVEL, metrics=RERANK_METRICS).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(link_max.drop(['Unjudged@20'], axis='columns').to_latex(escape=False))\n",
    "link_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max for err@20\n",
    "om = copy.copy(config.METRIC_NAMES)\n",
    "del om['recall_100']\n",
    "del om['unjudged@20']\n",
    "\n",
    "for r in display_names[1:]:\n",
    "    interps = link_max.loc[r, '$\\lambda$'].values\n",
    "    cols = om.keys()\n",
    "    a = pd.DataFrame()\n",
    "    for i, c in zip(interps, cols):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'case-topics-{0}.run'.format(r)), float(i), 'tmp.run')\n",
    "        a[c] = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0][c]\n",
    "\n",
    "    qry_comp_df = a-base_qry\n",
    "    qry_comp_fig = qry_comp_df[om.keys()].rename(RERANK_METRICS, axis='columns').plot.box(fontsize=15, boxprops=dict(linestyle='-', linewidth=2), medianprops=dict(linestyle='-', linewidth=2), color=dict(boxes='black', whiskers='black', medians='b', caps='r'), figsize=(16, 4)).axhline(y=0, xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='grey')\n",
    "    # qry_comp_fig.get_figure().savefig('figures/ausnl-{0}-qry-comp.pdf'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_runs = [os.path.join(BASE_DIR, 'grid-search', '{0}-combine-max.run'.format(x)) for x in ['RR', 'ERR', 'R@20', 'NDCG', 'RBP']]\n",
    "print(max_runs)\n",
    "max_run_res = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', max_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(max_run_res, columns=om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_runs = [os.path.join(BASE_DIR, 'grid-search', '4feat-{0}-combine-max.run'.format(x)) for x in ['RR', 'ERR', 'R@20', 'NDCG', 'RBP']]\n",
    "print(max_runs)\n",
    "max_run_res = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', max_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(max_run_res, columns=om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_folds(queries, k: int):\n",
    "#     l = len(queries)\n",
    "#     q_set = set(queries)\n",
    "#     inds = [x for x in range(l)]\n",
    "#     np.random.shuffle(inds)\n",
    "#     queries = np.array(queries)\n",
    "#     queries = queries[inds]\n",
    "    \n",
    "#     avg = l / float(k)\n",
    "#     parts = []\n",
    "#     last = 0.0\n",
    "    \n",
    "#     test = []\n",
    "\n",
    "#     while last < l:\n",
    "#         test.append(list(queries[int(last):int(last + avg)]))\n",
    "#         last += avg\n",
    "     \n",
    "#     for i in range(len(parts)):\n",
    "#         train.append()\n",
    "    \n",
    "#     train = []\n",
    "#     for i in range(len(test)):\n",
    "#         train.append(list(q_set.difference(test[i])))\n",
    "    \n",
    "#     return train, test\n",
    "    \n",
    "# train, test = create_folds(list(queries.keys()), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write folds to file \n",
    "# with open('ausnl-folds.txt', 'w') as f:\n",
    "#     for tr, te in zip(train, test):\n",
    "#         f.write('{0} {1}\\n'.format(tr, te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_folds = read_folds(AUS_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = 'bert-{0}-fold-{1}-combine-max.run'\n",
    "cros_val_name = 'bert'\n",
    "#grid_name = 'dpbtsoph-{0}-fold-{1}-combine-max.run'\n",
    "\n",
    "runs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', [os.path.join(BASE_DIR, 'grid-search', grid_name.format(y, x)) for x in range(0, 5) for y in ['RR', 'ERR', 'R@20', 'NDCG', 'RBP']], per_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [os.path.join(grid_dir, grid_name.format(y, x)) for x in range(0, 5) for y in ['RR', 'ERR', 'R@20', 'NDCG', 'RBP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [names[x:x+5] for x in range(0, len(names), 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results for test dataset for runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for r in range(5):\n",
    "    test_res.append([])\n",
    "run_folds = [runs[x:x+5] for x in range(0, len(runs), 5)]\n",
    "for filters, f in zip(tt_folds, run_folds):\n",
    "    for i, measure in enumerate(f):\n",
    "        test_res[i].append(measure[measure.index.isin(filters[1])].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = copy.copy(config.METRIC_NAMES)\n",
    "del metrics['unjudged@20']\n",
    "del metrics['recall_100']\n",
    "\n",
    "test_res_avg = pd.DataFrame()\n",
    "for m, r in zip(metrics, test_res):\n",
    "    test_res_avg[m] = pd.DataFrame(r)[m]\n",
    "    print('-'*20)\n",
    "    \n",
    "test_res_avg = test_res_avg.rename(metrics, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5)\n",
    "fig.set_size_inches(16, 10)\n",
    "for i, m in enumerate(RERANK_METRICS.items()):\n",
    "    print(m)\n",
    "    p = test_res_avg[m[1]].plot.box(ax=axs[i], fontsize=15, boxprops=dict(linestyle='-', linewidth=2), medianprops=dict(linestyle='-', linewidth=2), color=dict(boxes='black', whiskers='black', medians='b', caps='r'), figsize=(16, 4))\n",
    "    p.axhline(y=base_df[m[0]], xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='blue')\n",
    "    p.axhline(y=sdm_base_df[m[0]], xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='green')\n",
    "    axs[i].set_ylim(top=RERANK_YLIMS[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig('figures/ausnl-{0}-cross-val.pdf'.format(cros_val_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "model_names = ['BERT', '4ft', '5ft']\n",
    "metric_names = ['RR', 'ERR', 'R@20', 'NDCG', 'RBP']\n",
    "metric_ll = ['recip_rank', 'err@20', 'recall_20', 'ndcg', 'rbp@0.80']\n",
    "for m in metric_names:\n",
    "    dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', \n",
    "                        [os.path.join(BASE_DIR, 'grid-search', '{0}-{1}-combine-max.run'.format(r, m)) for r in ['bert', '4feat', '5feat']], per_query=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs[0]))\n",
    "dfs[0][2].mean()[RERANK_METRICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(columns=metric_names)\n",
    "for d, m, l in zip(dfs, metric_names, metric_ll):\n",
    "    out_df[m] = [x[l].mean() for x in d]\n",
    "    \n",
    "    print([stats.ttest_rel(d[0][l], x[l]).pvalue for x in d[1:]])\n",
    "    \n",
    "out_df.index = model_names\n",
    "print(out_df.round(4).to_latex())\n",
    "\n",
    "# write_table('tables/ausnl-multi', bold_max(out_df.round(4)).rename(columns=metrics).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(columns=RERANK_METRICS)\n",
    "for n, d in zip(model_names, dfs):\n",
    "    cross = cross_validation(d, tt_folds, RERANK_METRICS, base_qry)\n",
    "    tmp_df.loc[n] = cross[0]\n",
    "    \n",
    "# write_table('tables/ausnl-multi', bold_max(tmp_df).rename(columns=metrics).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', [os.path.join(BASE_DIR, 'grid-search', '{0}-RBP-combine-max.run'.format(r)) for r in ['bert', '4feat', '5feat']], per_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grid_res(path: str, folds: int):\n",
    "    with open(path) as f:\n",
    "        measures = f.readline().split()\n",
    "        fold_res = [[] for x in measures]\n",
    "        weights = [[] for x in measures]\n",
    "        # read the fold score\n",
    "        for i in range(folds):\n",
    "            parts = f.readline().split()\n",
    "            for j in range(len(parts)):\n",
    "                fold_res[j].append(float(parts[j]))\n",
    "            \n",
    "        #read the weights\n",
    "        for i in range(folds):\n",
    "            parts = f.readline().split('] [')\n",
    "            parts = [x.strip(' []\\n') for x in parts]\n",
    "            for j in range(len(parts)):\n",
    "                weights[j].append([float(x) for x in parts[j].split()])\n",
    "                \n",
    "        return measures, fold_res, weights\n",
    "             \n",
    "_4res = read_grid_res(os.path.join(BASE_DIR, 'grid-search', '4feat-results.txt'), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_5res = read_grid_res(os.path.join(BASE_DIR, 'grid-search', '5feat-results.txt'), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertres = read_grid_res(os.path.join(BASE_DIR, 'grid-search', 'bert-results.txt'), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_metrics = {v:k for k,v in RERANK_METRICS.items()}\n",
    "rev_metrics['ERR'] = rev_metrics['ERR@20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5)\n",
    "fig.set_size_inches(16, 10)\n",
    "cnt = 0\n",
    "for i in [2, 3, 4, 1, 0]:\n",
    "    a = pd.DataFrame()\n",
    "    a['x'] = [0 for x in range(5)]\n",
    "    a['x1'] = [1 for x in range(5)]\n",
    "    a['x2'] = [2 for x in range(5)]\n",
    "    a['bert'] = bertres[1][i]\n",
    "    a['4ft'] = _4res[1][i]\n",
    "    a['5ft'] = _5res[1][i]\n",
    "    p = a.plot.scatter(y='bert', x='x', ax=axs[cnt], fontsize=15, figsize=(16, 4))\n",
    "    a.plot.scatter(y='4ft', x='x1', ax=axs[cnt], fontsize=15, figsize=(16, 4))\n",
    "    a.plot.scatter(y='5ft', x='x2', ax=axs[cnt], fontsize=15, figsize=(16, 4))\n",
    "    p.axhline(y=base_df[rev_metrics[_4res[0][i]]], xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='b')\n",
    "    p.set(xlabel=None)\n",
    "    p.set(xticks=[0, 1, 2])\n",
    "    p.set_ylabel(_4res[0][i], fontsize=15)\n",
    "    p.set_xticklabels(['bert', '4ft', '5ft'], rotation='vertical', fontsize=18)\n",
    "    cnt += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig('figures/ausnl-comb-train-res.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5)\n",
    "fig.set_size_inches(16, 10)\n",
    "for i, m in enumerate(_4res[0]):\n",
    "    a = pd.DataFrame()\n",
    "#     a['x'] = [0 for x in range(5)]\n",
    "# #     a['x1'] = [1 for x in range(5)]\n",
    "# #     a['x2'] = [2 for x in range(5)]\n",
    "# #     a['bert'] = bertres[2][i]\n",
    "# #     a['4ft'] = _4res[2][i]\n",
    "#     a['5ft'] = _5res[2][i]\n",
    "#     print(a)\n",
    "#     break\n",
    "#     p = a.plot.scatter(y='bert', x='x', ax=axs[i], fontsize=15, figsize=(16, 4))\n",
    "#     a.plot.scatter(y='4ft', x='x1', ax=axs[i], fontsize=15, figsize=(16, 4))\n",
    "#     a.plot.scatter(y='5ft', x='x2', ax=axs[i], fontsize=15, figsize=(16, 4))\n",
    "#     p.axhline(y=base_df[rev_metrics[m]], xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='b')\n",
    "#     p.set(xlabel=None)\n",
    "#     p.set(xticks=[0, 1, 2])\n",
    "#     p.set_ylabel(m, fontsize=15)\n",
    "#     p.set_xticklabels(['bert', '4ft', '5ft'], rotation='vertical', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weight_df = pd.DataFrame()\n",
    "\n",
    "for i in range(5):\n",
    "    tmp = pd.DataFrame(_4res[2][i])\n",
    "    tmp['measure'] = _4res[0][i]\n",
    "    tmp['x'] = 0\n",
    "    all_weight_df = all_weight_df.append(tmp)\n",
    "    \n",
    "# all_weight_df.plot.scatter(x='measure', y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['0cnt'] = all_weight_df.groupby('measure')[0].value_counts()\n",
    "tmp['1cnt'] = all_weight_df.groupby('measure')[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(res, feature_names, folds=5):\n",
    "    xs = [[x]*5 for x in range(len(feature_names))]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in range(5):\n",
    "        tmp = pd.DataFrame(res[2][i])\n",
    "        tmp['measure'] = res[0][i]\n",
    "        tmp['x'] = 0\n",
    "        df = df.append(tmp)\n",
    "\n",
    "    df2 = pd.DataFrame()\n",
    "    for i in range(len(feature_names)):\n",
    "        df2[i] = df.groupby('measure')[i].value_counts()\n",
    "\n",
    "    vals = {}\n",
    "\n",
    "    for iter in df2.iterrows():\n",
    "        v = vals.get(iter[0][0], [])\n",
    "        start = len(v) == 0\n",
    "        for i in range(int(iter[1][0])):\n",
    "            v.append(iter[0][1])\n",
    "        # v.append((iter[0][1], ))\n",
    "        if start:\n",
    "            vals[iter[0][0]] = v\n",
    "    \n",
    "    df2 = pd.DataFrame(vals)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 5)\n",
    "    fig.set_size_inches(16, 6)\n",
    "    inds = [2, 3, 4, 1, 0]\n",
    "    for i, ind in enumerate(inds):\n",
    "        # for j in range(len(feature_names)):\n",
    "            # legend = False\n",
    "        sns.scatterplot(xs[0], df2[res[0][i]], alpha=0.8, ax=axs[i], markers=['X'], style=0, legend=False, s=40)\n",
    "        axs[i].set_xticks([0])\n",
    "        axs[i].set_ylabel(res[0][ind], size=20)\n",
    "        axs[i].set_ylim(0, 1)\n",
    "        axs[i].set_xticks([])\n",
    "        fig.legend(feature_names, frameon=True, ncol=1, bbox_to_anchor=[0.99, 0.97], prop={\"size\": 12}, markerfirst=False).get_frame().set_edgecolor('black')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "fig = create(_4res, ['DP', 'BERT', 'court', 'oprob'])\n",
    "# fig.savefig('figures/ausnl-4ft-weights.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create(_5res, ['DP', 'BERT', 'court', 'oprob', 'fact'])\n",
    "# fig.savefig('figures/ausnl-5ft-weights.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create(bertres, ['DP', 'BERT'])\n",
    "# fig.savefig('figures/ausnl-bert-weights.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
