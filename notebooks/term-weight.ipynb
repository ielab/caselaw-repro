{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys \n",
    "import os \n",
    "\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "\n",
    "from phdconf import stop\n",
    "from phdconf import config \n",
    "\n",
    "from typing import List, Dict\n",
    "import math \n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(config.AUS_TOPIC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(path: str):\n",
    "    embeddings = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            values = line.rstrip().rsplit(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = coefs\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "embeddings = load_vectors('/home/danlocke/fastText/filtered-100d.vec')\n",
    "\n",
    "class EmbMethod:\n",
    "    SUM = 0\n",
    "    MEAN = 1 \n",
    "    CF_SUM = 2 \n",
    "    CF_MEAN = 3\n",
    "\n",
    "def embed(tokens: List[str], embeddings, dim: int=100, method: EmbMethod = EmbMethod.SUM, coll_stats = None) -> np.array:\n",
    "    e = []\n",
    "    if method > EmbMethod.MEAN: \n",
    "        for x in tokens: \n",
    "            if x in embeddings:\n",
    "                mul = coll_stats[x] if x in coll_stats else 1.0\n",
    "                e.append(mul * embeddings[x])\n",
    "    else: \n",
    "        e = [embeddings[x] for x in tokens if x in embeddings]\n",
    "    if len(e) == 0:\n",
    "        return np.zeros((dim,), dtype='float32')\n",
    "    \n",
    "    e = np.sum(e, axis=0)\n",
    "    if method == EmbMethod.MEAN or method == EmbMethod.CF_MEAN:\n",
    "        e /= float(len(tokens))\n",
    "            \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_vectors('/home/danlocke/fastText/filtered-100d.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_embeddings = load_vectors('/home/danlocke/fastText/para-phrase-100d.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = {\n",
    "    'first', \n",
    "    'second', \n",
    "    'third',\n",
    "    'fourth',\n",
    "    'fifth',\n",
    "    'sixth',\n",
    "    'seventh',\n",
    "    'eighth',\n",
    "    'ninth',\n",
    "    'tenth',\n",
    "    'eleventh',\n",
    "    'twelfth',\n",
    "    'thirteenth',\n",
    "    'fourteenth',\n",
    "    'fifteenth',\n",
    "    'sixteenth',\n",
    "    'seventeenth',\n",
    "    'eighteenth',\n",
    "    'nineteenth',\n",
    "    'twenty',\n",
    "    'thirty',\n",
    "    'fourty',\n",
    "}\n",
    "\n",
    "num_exclusion = {\n",
    "    'amendment',\n",
    "    'degree',\n",
    "    'refusal'\n",
    "}\n",
    "\n",
    "find2 = {\n",
    "    'north',\n",
    "    'south',\n",
    "    'east',\n",
    "    'west'\n",
    "}\n",
    "\n",
    "find3 = {\n",
    "    'set',\n",
    "    'hold',\n",
    "    'exemplary',\n",
    "    'intending',\n",
    "    'include',\n",
    "    'including',\n",
    "    'relies',\n",
    "    'relied',\n",
    "    'pursuant',\n",
    "    'thereto',\n",
    "    'behalf',\n",
    "    'giving',\n",
    "    'give',\n",
    "    'apparently',\n",
    "    'subsequently',\n",
    "    'jurisdictional',\n",
    "    'included',\n",
    "    'includes',\n",
    "    'appellant',\n",
    "    'respondent',\n",
    "    'resulting',\n",
    "    'such',\n",
    "    's',\n",
    "    'x',\n",
    "    't',\n",
    "    'th',\n",
    "    'thing',\n",
    "    're',\n",
    "    'subject'\n",
    "}\n",
    "\n",
    "find4 = {\n",
    "    'nonetheless',\n",
    "    'follows',\n",
    "    'referred',\n",
    "    'thereto',\n",
    "    'behalf',\n",
    "    'hastily',\n",
    "    'instance',\n",
    "    'instances',\n",
    "    'such',\n",
    "    's',\n",
    "    'applicant',\n",
    "    'applicants',\n",
    "    'respondent',\n",
    "    'respondents',\n",
    "    'th',\n",
    "    'x',\n",
    "    'such',\n",
    "    'll',\n",
    "    'only',\n",
    "    'way',\n",
    "    're',\n",
    "    'much',\n",
    "    'st',\n",
    "    'consideration',\n",
    "    'organisation'\n",
    "}\n",
    "\n",
    "#     consider 'made' and 'make' as exclusions\n",
    "\n",
    "def filter_phrases(phrases, splitter=' '):\n",
    "    d = isinstance(phrases, dict)\n",
    "    if d:\n",
    "        ret = {}\n",
    "    else:\n",
    "        ret = []\n",
    "    for phrase in phrases:\n",
    "        toks = phrase.split(splitter)\n",
    "        if len(toks) < 2:\n",
    "            continue \n",
    "        \n",
    "        cont = False \n",
    "        cnt = 0\n",
    "\n",
    "        if toks[-1] in find3 or len(toks[-1]) == 1:\n",
    "            continue\n",
    "        \n",
    "        if len(toks) == 2 and toks[0].startswith('claim'):\n",
    "            continue\n",
    "            \n",
    "        if len(toks) == 3 and toks[0] == 'intention' and toks[1] != 'to':\n",
    "            continue\n",
    "            \n",
    "        if toks[0] == 'intention' and len(toks) == 2:\n",
    "            continue\n",
    "            \n",
    "        if toks[0] in find4 or len(toks[0]) == 1:\n",
    "            continue\n",
    "            \n",
    "        unique = set()\n",
    "            \n",
    "        num = False \n",
    "        num_ex = False\n",
    "        for t, tok in enumerate(toks):\n",
    "            unique.add(tok)\n",
    "            \n",
    "            if tok in find: \n",
    "                num = True \n",
    "            if tok in num_exclusion:\n",
    "                num_ex = True\n",
    "            if tok in find2:\n",
    "                cnt += 1 \n",
    "            if tok == 'nunc' and t != 0:\n",
    "                cont = True \n",
    "                break\n",
    "                \n",
    "        if num and not num_ex: \n",
    "            continue\n",
    "        \n",
    "        if len(toks) > len(unique): \n",
    "            continue\n",
    "    \n",
    "        if cont or cnt > 1:\n",
    "            continue \n",
    "            \n",
    "        if d: \n",
    "            ret[phrase] = phrases[phrase]\n",
    "        else:\n",
    "            ret.append(phrase)\n",
    "        \n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coll_stats(path: str, total=None) -> Dict[str, float]:\n",
    "    stats = {}\n",
    "    \n",
    "    idf = total is None\n",
    "    if idf:\n",
    "        total = 0.0\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            if idf: \n",
    "                v = float(parts[-1])\n",
    "                total += v\n",
    "                stats[' '.join(parts[:-1])] = v\n",
    "            else:\n",
    "                stats[' '.join(parts[:-1])] = math.log(total / float(parts[-1])+1.0) + 1.0\n",
    "    \n",
    "    if idf: \n",
    "        for k, v in stats.items():\n",
    "            stats[k] = math.log(total / v+1.0) + 1.0\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_stats = load_coll_stats('/home/danlocke/phd-generated/filtered-stop-top-tokens.txt')\n",
    "idf_stats = load_coll_stats('/home/danlocke/phd-generated/filtered-stop-idf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_embeddings = filter_phrases(phrase_embeddings, '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in phrase_embeddings if x.endswith('_date')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(tokens: List[str], n: int): \n",
    "    ret = []\n",
    "    for i in range(0, len(tokens)-(n-1)):\n",
    "           ret.append('_'.join(tokens[i:i+n]))\n",
    "           \n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg(terms, ictf_lookup, idf_lookup):\n",
    "    ictfs = sum([ictf_lookup[x] for x in terms])\n",
    "    idfs = sum([idf_lookup[x] for x in terms])\n",
    "    \n",
    "    return ictfs / float(len(terms)), idfs / float(len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the effect of reinstating a company that was in liquidation as regards money that may be recovered?\n",
      "[('company', 0.7679199, 7.724056568691374), ('liquidation', 0.73408693, 10.406756400178168), ('money', 0.69507045, 8.637663013219438), ('recovered', 0.6855011, 10.852364557070903), ('reinstating', 0.61489415, 13.785734744976217), ('may', 0.55273366, 6.669301082836351), ('what', 0.5356588, 7.042855936164868), ('effect', 0.52630407, 7.496878414759574), ('regards', 0.5105081, 11.168738422565589)]\n",
      "[('company', 0.7585988, 7.724056568691374), ('liquidation', 0.7440747, 10.406756400178168), ('recovered', 0.6958305, 10.852364557070903), ('reinstating', 0.6707446, 13.785734744976217), ('money', 0.66999644, 8.637663013219438), ('may', 0.52263916, 6.669301082836351), ('regards', 0.5137955, 11.168738422565589), ('effect', 0.5091775, 7.496878414759574), ('what', 0.48877293, 7.042855936164868)]\n",
      "['what', 'effect', 'reinstating', 'company', 'liquidation', 'regards', 'money', 'may', 'recovered']\n",
      "OrderedDict([('reinstating_company', (2, 2, 10.770669158602146, 10.754895656833796)), ('company_liquidation', (3, 2, 9.561626377487006, 9.06540648443477))])\n",
      "----------------------------------------\n",
      "Is the variation of the date for settlement required to be in writing?\n",
      "[('variation', 0.78699005, 10.288872607293285), ('writing', 0.76102126, 9.468219315052007), ('settlement', 0.7436728, 9.0485420436867), ('date', 0.72736233, 7.780767671047673), ('required', 0.62334573, 7.600244875782614)]\n",
      "[('variation', 0.80879486, 10.288872607293285), ('writing', 0.7696643, 9.468219315052007), ('settlement', 0.75052714, 9.0485420436867), ('date', 0.70318496, 7.780767671047673), ('required', 0.60174125, 7.600244875782614)]\n",
      "['variation', 'date', 'settlement', 'required', 'writing']\n",
      "OrderedDict([('variation_date', (0, 2, 9.135528883795176, 9.03482013917048)), ('date_settlement', (1, 2, 8.848540809991983, 8.414654857367186))])\n",
      "----------------------------------------\n",
      "Maintenance and champerty and the requisite degree of control\n",
      "[('maintenance', 0.7192178, 10.102182792210906), ('control', 0.699619, 8.9980144731833), ('requisite', 0.6955093, 10.519956369781816), ('champerty', 0.6604107, 13.751149263875568), ('degree', 0.65938234, 9.309875000445835)]\n",
      "[('champerty', 0.73371524, 13.751149263875568), ('maintenance', 0.7172745, 10.102182792210906), ('requisite', 0.6665877, 10.519956369781816), ('control', 0.6563322, 8.9980144731833), ('degree', 0.61741906, 9.309875000445835)]\n",
      "['maintenance', 'champerty', 'requisite', 'degree', 'control']\n",
      "OrderedDict([('maintenance_champerty', (0, 2, 12.285916118210068, 11.926666028043236)), ('requisite_degree_control', (2, 3, 9.28461970811219, 9.60928194780365)), ('requisite_degree', (2, 2, 9.396036723125638, 9.914915685113826)), ('degree_control', (3, 2, 9.019842954093164, 9.153944736814568))])\n",
      "----------------------------------------\n",
      "agency fees and effective cause of sale of a boat\n",
      "[('sale', 0.7037167, 8.464898432020702), ('agency', 0.6741427, 10.328366914810559), ('fees', 0.63262063, 9.359207339076175), ('boat', 0.61630666, 10.892807404082154), ('effective', 0.5852676, 9.555735629358692), ('cause', 0.49422655, 8.495314028615997)]\n",
      "[('sale', 0.69067067, 8.464898432020702), ('agency', 0.68561536, 10.328366914810559), ('boat', 0.6416283, 10.892807404082154), ('fees', 0.62924266, 9.359207339076175), ('effective', 0.5809464, 9.555735629358692), ('cause', 0.4712637, 8.495314028615997)]\n",
      "['agency', 'fees', 'effective', 'cause', 'sale', 'boat']\n",
      "OrderedDict([('agency_fees', (0, 2, 10.074338579897724, 9.843787126943367)), ('effective_cause_sale', (2, 3, 9.011947447483422, 8.838649363331797)), ('effective_cause', (2, 2, 8.8860273378714, 9.025524828987344)), ('cause_sale', (3, 2, 8.902816455431791, 8.480106230318349))])\n",
      "----------------------------------------\n",
      "Should damages be reduced according to a sum that represents betterment\n",
      "[('sum', 0.7577501, 8.689116801771709), ('damages', 0.7160471, 8.444263316672048), ('reduced', 0.691999, 9.887369169123383), ('represents', 0.65258837, 10.990716190869039), ('betterment', 0.6305993, 14.567759695709865), ('should', 0.6061266, 6.782626908568341), ('according', 0.5690426, 8.822263266051579)]\n",
      "[('sum', 0.7239392, 8.689116801771709), ('betterment', 0.7027635, 14.567759695709865), ('reduced', 0.69406664, 9.887369169123383), ('damages', 0.6862023, 8.444263316672048), ('represents', 0.66701066, 10.990716190869039), ('should', 0.56130767, 6.782626908568341), ('according', 0.5571167, 8.822263266051579)]\n",
      "['should', 'damages', 'reduced', 'according', 'sum', 'represents', 'betterment']\n",
      "OrderedDict()\n",
      "----------------------------------------\n",
      "Consideration of a clause that provides that the contract is subject to the buyer being satisfied, in its absolute discretion, with the due diligence by a date\n",
      "[('buyer', 0.6547602, 10.857684271633136), ('contract', 0.65431327, 7.802803528543043), ('subject', 0.6445586, 7.655194521062779), ('diligence', 0.6259593, 10.854238873321021), ('due', 0.62471694, 8.60329473794101), ('consideration', 0.61441404, 8.003114033480237), ('date', 0.61348575, 7.780767671047673), ('clause', 0.6078902, 9.456717090567544), ('discretion', 0.5842923, 8.372034465215393), ('absolute', 0.5622331, 10.945518813543353), ('satisfied', 0.54778343, 7.738443257786893), ('provides', 0.5257542, 8.081403304280538), ('being', 0.50987375, 7.0530196876044515)]\n",
      "[('buyer', 0.67759615, 10.857684271633136), ('contract', 0.6599186, 7.802803528543043), ('diligence', 0.65039146, 10.854238873321021), ('subject', 0.6270409, 7.655194521062779), ('due', 0.6163232, 8.60329473794101), ('clause', 0.6097907, 9.456717090567544), ('consideration', 0.5983508, 8.003114033480237), ('date', 0.59625727, 7.780767671047673), ('absolute', 0.5827323, 10.945518813543353), ('discretion', 0.5801446, 8.372034465215393), ('satisfied', 0.5261423, 7.738443257786893), ('provides', 0.5145372, 8.081403304280538), ('being', 0.48640576, 7.0530196876044515)]\n",
      "['consideration', 'clause', 'provides', 'contract', 'subject', 'buyer', 'being', 'satisfied', 'absolute', 'discretion', 'due', 'diligence', 'date']\n",
      "OrderedDict([('absolute_discretion', (8, 2, 9.42449371295379, 9.658776639379372)), ('due_diligence', (10, 2, 9.580451341728956, 9.728766805631015)), ('diligence_date', (11, 2, 9.40569486030616, 9.317503272184346))])\n",
      "----------------------------------------\n",
      "Maintenance and champerty\n",
      "[('champerty', 0.8880645, 13.751149263875568), ('maintenance', 0.81635755, 10.102182792210906)]\n",
      "[('champerty', 0.92545015, 13.751149263875568), ('maintenance', 0.76172525, 10.102182792210906)]\n",
      "['maintenance', 'champerty']\n",
      "OrderedDict([('maintenance_champerty', (0, 2, 12.285916118210068, 11.926666028043236))])\n",
      "----------------------------------------\n",
      "proportionality as a basis for striking out a defamation claim\n",
      "[('claim', 0.7355147, 6.835590098642504), ('striking', 0.71465445, 11.151543037224409), ('defamation', 0.6903335, 11.286543963067812), ('out', 0.62900215, 19.617614430030322), ('basis', 0.60654944, 7.371377203494757), ('proportionality', 0.5251848, 12.599221796014342)]\n",
      "[('striking', 0.7385505, 11.151543037224409), ('out', 0.7338344, 19.617614430030322), ('claim', 0.65348274, 6.835590098642504), ('defamation', 0.6433306, 11.286543963067812), ('basis', 0.53608984, 7.371377203494757), ('proportionality', 0.5287588, 12.599221796014342)]\n",
      "['proportionality', 'basis', 'striking', 'out', 'defamation', 'claim']\n",
      "OrderedDict([('striking_out', (2, 2, 14.431966500092622, 15.384578733627364)), ('defamation_claim', (4, 2, 9.828180257034223, 9.061067030855158))])\n",
      "----------------------------------------\n",
      "In trade or commerce\n",
      "[('commerce', 0.94189405, 10.752219763162817), ('trade', 0.91851616, 8.72165171146234)]\n",
      "[('commerce', 0.9546504, 10.752219763162817), ('trade', 0.90185857, 8.72165171146234)]\n",
      "['trade', 'commerce']\n",
      "OrderedDict([('trade_commerce', (0, 2, 10.238808250982945, 9.736935737312578))])\n",
      "----------------------------------------\n",
      "Whether membership of an organisation is in trade or commerce\n",
      "[('trade', 0.7867799, 8.72165171146234), ('commerce', 0.7711893, 10.752219763162817), ('organisation', 0.70854974, 9.945306948117237), ('membership', 0.6713328, 9.870394998946919), ('whether', 0.54086834, 6.727351787135791)]\n",
      "[('commerce', 0.7871957, 10.752219763162817), ('trade', 0.7832646, 8.72165171146234), ('organisation', 0.7169644, 9.945306948117237), ('membership', 0.6738068, 9.870394998946919), ('whether', 0.49342564, 6.727351787135791)]\n",
      "['whether', 'membership', 'organisation', 'trade', 'commerce']\n",
      "OrderedDict([('membership_organisation', (1, 2, 9.911060294126507, 9.907850973532078)), ('trade_commerce', (3, 2, 10.238808250982945, 9.736935737312578))])\n",
      "----------------------------------------\n",
      "Organisations owing members a duty of care\n",
      "[('duty', 0.72501075, 8.549333139302766), ('care', 0.7036011, 8.923738796633467), ('members', 0.68381035, 8.161939924256487), ('organisations', 0.6055408, 11.154916301397053), ('owing', 0.59947324, 10.16875517930992)]\n",
      "[('duty', 0.69740707, 8.549333139302766), ('members', 0.68178105, 8.161939924256487), ('care', 0.6757244, 8.923738796633467), ('organisations', 0.63548356, 11.154916301397053), ('owing', 0.62057054, 10.16875517930992)]\n",
      "['organisations', 'owing', 'members', 'duty', 'care']\n",
      "OrderedDict([('duty_care', (3, 2, 9.083447792514452, 8.736535967968116))])\n",
      "----------------------------------------\n",
      "That proprietary relief is only available after rescission \n",
      "[('rescission', 0.7518514, 12.594755550062779), ('only', 0.72400475, 7.098956871675929), ('proprietary', 0.70040137, 11.267219202768347), ('relief', 0.695506, 8.404944077338433), ('available', 0.6438787, 8.313019960021762), ('after', 0.5403242, 7.211784802537938)]\n",
      "[('rescission', 0.7992967, 12.594755550062779), ('proprietary', 0.7375281, 11.267219202768347), ('relief', 0.6986775, 8.404944077338433), ('only', 0.66889375, 7.098956871675929), ('available', 0.60080993, 8.313019960021762), ('after', 0.47821677, 7.211784802537938)]\n",
      "['proprietary', 'relief', 'only', 'available', 'after', 'rescission']\n",
      "OrderedDict([('proprietary_relief', (0, 2, 9.822854780033861, 9.83608164005339))])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for topic in queries.values(): \n",
    "    print(topic['topic'])\n",
    "    tokens = topic['topic'].lower().replace(',', '').replace('?', '').replace('\\'', '').replace('/', '').replace('â€™', '').split()\n",
    "    tokens = [x for x in tokens if x not in stop.stop]\n",
    "    diff_tokens = copy.copy(tokens)\n",
    "    keep = {}\n",
    "    for grams in [n_gram(tokens, 2), n_gram(tokens, 3)]:\n",
    "        for i, gram in enumerate(grams):\n",
    "            if gram in phrase_embeddings:\n",
    "                ts = gram.split('_')\n",
    "                vals = get_avg(ts, coll_stats, idf_stats)\n",
    "                keep[gram] = (i, len(ts), vals[0], vals[1])\n",
    "    for meth in [EmbMethod.SUM, EmbMethod.CF_SUM]:\n",
    "        qry_vec = embed(tokens, embeddings, method=meth, coll_stats=idf_stats).reshape(1, -1)\n",
    "        tok_vecs = [embed([tok], embeddings, method=meth, coll_stats=idf_stats).reshape(1, -1) for tok in tokens]\n",
    "        sims = [(tokens[i], cosine_similarity(tok_vecs[i], qry_vec)[0][0], idf_stats[tokens[i]]) for i in range(len(tokens))]\n",
    "        print(sorted(sims, key= lambda x: x[1], reverse=True))\n",
    "    \n",
    "    print(tokens)\n",
    "    keep = OrderedDict(sorted(keep.items(), key=lambda t: (t[1][0], -t[1][1])))\n",
    "    print(keep)\n",
    "    print('-'*40)\n",
    "    if cnt > 10:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
