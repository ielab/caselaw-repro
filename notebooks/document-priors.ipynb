{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys \n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "\n",
    "from phdconf import config\n",
    "from phdconf.config import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(config.AUS_TOPIC_PATH)\n",
    "broad, specific = load_query_types(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = load_1d_dfs(['filtered-phrasestop'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', ['1'], 1050, 1050, 1)[0][0]\n",
    "base_query = load_1d_dfs(['filtered-phrasestop'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', ['1'], 1050, 1050, 1, per_query=True)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prior files for run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linker:\n",
    "    def __init__(self, path: str, id_path: str):\n",
    "        self._lookup = {}\n",
    "        with open(id_path) as f:\n",
    "            for line in f:\n",
    "                parts = line.split()\n",
    "                self._lookup[parts[0].upper()] = int(parts[1])\n",
    "\n",
    "        self._lookup_ind = ['']*len(self._lookup)\n",
    "        for k, v in self._lookup.items():\n",
    "            self._lookup_ind[v] = k\n",
    "        \n",
    "        self._inlinks = [None]*len(self._lookup)\n",
    "        self._outlinks = [None]*len(self._lookup)\n",
    "\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                parts = list(map(int, line.split()))\n",
    "                \n",
    "                if self._inlinks[parts[1]] == None:\n",
    "                    self._inlinks[parts[1]] = []\n",
    "                self._inlinks[parts[1]].append((parts[0], parts[2]))\n",
    "\n",
    "                if self._outlinks[parts[0]] == None:\n",
    "                    self._outlinks[parts[0]] = []\n",
    "                self._outlinks[parts[0]].append((parts[1], parts[2]))\n",
    "                \n",
    "    def ids(self):\n",
    "        return self._lookup_ind\n",
    "    \n",
    "    def out_links(self): \n",
    "        return self._outlinks\n",
    "    \n",
    "    def in_links(self): \n",
    "        return self._inlinks\n",
    "                \n",
    "    def get_links_for_id(_id: str, vals, count:bool = False):\n",
    "        ind = self._lookup.get(_id.toupper(), None)\n",
    "        if ind != None:\n",
    "            if count:\n",
    "                _sum = 0\n",
    "                for i in vals[ind]:\n",
    "                    _sum += i[1]\n",
    "                return _sum\n",
    "            return len(vals[ind])\n",
    "        return 0\n",
    "\n",
    "linker = Linker(\"../features/links.txt\", \"../features/id-lookup.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lens = load_doclen_lookup(os.path.join(BASE_DIR, 'filtered-phrasestop-doc_lens.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of documents and relevance list \n",
    "def get_qrel_rel_docs(path: str): \n",
    "    out = set()\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if int(parts[3]) > 0:\n",
    "                out.add(parts[2])\n",
    "                \n",
    "    return out\n",
    "\n",
    "def get_bin(v, bins): \n",
    "    for i in range(1, len(bins)): \n",
    "#         print(v, bins)\n",
    "        if v < bins[i]: \n",
    "            return i-1\n",
    "    return 0 \n",
    "\n",
    "def get_rel_vals(qrels, lookup, bins):\n",
    "    vals = [0.0] * len(qrels)\n",
    "    for i, q in enumerate(qrels):\n",
    "        vals[i] = lookup.get(q, True)\n",
    "    \n",
    "    bin_cnt = [0] * (len(bins)-1)\n",
    "    for i, v in enumerate(vals): \n",
    "        bin_cnt[get_bin(v, bins)] +=1\n",
    "    \n",
    "    return bin_cnt\n",
    "    \n",
    "def get_buckets(data):\n",
    "    print(data[:10])\n",
    "    df = pd.DataFrame(data)\n",
    "    bucketed, bins = pd.cut(df[0], 100, retbins=True)\n",
    "    return bucketed, bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = 54\n",
    "\n",
    "rel_docs = get_qrel_rel_docs(config.AUS_QREL_PATH)\n",
    "\n",
    "in_links = linker.in_links()\n",
    "out_links = linker.out_links()\n",
    "\n",
    "inlink = [len(x) if x is not None else 0 for x in in_links]\n",
    "outlink = [len(x) if x is not None else 0 for x in out_links]\n",
    "\n",
    "sum_in = []\n",
    "for x in in_links: \n",
    "    if x is not None:\n",
    "        sum_in.append(sum([y[1] for y in x]))\n",
    "    else:\n",
    "        sum_in.append(0)\n",
    "sum_out = []\n",
    "for x in out_links:\n",
    "    if x is not None:\n",
    "        sum_out.append(sum([y[1] for y in x]))\n",
    "    else:\n",
    "        sum_out.append(0)\n",
    "\n",
    "rel = [True if x in rel_docs else False for x in linker.ids()]\n",
    "\n",
    "labels = [x for x in range(1, buckets+1)]\n",
    "\n",
    "len_df = pd.DataFrame({'id': [x.upper() for x in doc_lens.keys()], 'lens': list(doc_lens.values())}).set_index(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'id': linker.ids(), 'inlink': inlink, 'outlink': outlink, 'rel': rel}).set_index(['id'])\n",
    "df = pd.merge(df, len_df, how='outer', left_index=True, right_index=True)\n",
    "df.drop('CITATION', inplace=True)\n",
    "df.drop('', inplace=True)\n",
    "df['present'] = [True if x in doc_lens else False for x in df.index]\n",
    "# # normalize\n",
    "df.sort_values(inplace=True, by='inlink')\n",
    "df['ibins'], ibins = pd.qcut(df['inlink'], buckets, retbins=True, duplicates='drop')\n",
    "df.sort_values(inplace=True, by='outlink')\n",
    "df['obins'], obins = pd.qcut(df['outlink'], buckets, retbins=True, duplicates='drop')\n",
    "df.sort_values(inplace=True, by='lens')\n",
    "df['lbins'], lbins = pd.qcut(df[df['present'] == 1.0]['lens'], buckets, retbins=True)\n",
    "# df=(df-df.min())/(df.max()-df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df.lens.dropna()))\n",
    "# print(df['inlink'].sort_values().rank(method='first').head(20))\n",
    "# df[df['rel'] == True]['inlink'].sort_values().tail(20)\n",
    "# print(df['ibins'].fillna(pd.Interval(-0.001, 1.0, closed='right')).apply(bucket_df['prob']))\n",
    "# print(df['inlink'].sort_values().head(20))\n",
    "# print(df['outlink'].sort_values().head(20))\n",
    "# print(len(df.inlink.dropna()))\n",
    "# print(len(df['lbins'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len_df.loc['2015QCA244'])\n",
    "# print(df.loc['2015QCA244'])\n",
    "# print(df.loc['2010FCA1'])\n",
    "# print(df.loc['2010FCA2'])\n",
    "df[df['inlink'] > 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ibins = pd.qcut(df['inlink'].rank(method='first'), buckets, retbins=True)\n",
    "# _, obins = pd.qcut(df['outlink'].rank(method='first'), buckets, retbins=True)\n",
    "# _, lbins = pd.qcut(df[df['present'] == True]['lens'].sort_values().rank(method='first'), buckets, retbins=True)\n",
    "rel_i = get_rel_vals(rel_docs, df['inlink'].to_dict(), ibins)\n",
    "rel_o = get_rel_vals(rel_docs, df['outlink'].to_dict(), obins)\n",
    "rel_l = get_rel_vals(rel_docs, df['lens'].to_dict(), lbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ibins', 'obins', 'lbins']\n",
    "orig_cols = ['inlink', 'outlink', 'lens']\n",
    "for col, ocol, bins, rel in zip(cols, orig_cols, [ibins, obins, lbins], [rel_i, rel_o, rel_l]):\n",
    "    bucket_df = df[col].value_counts(sort=False).to_frame()\n",
    "#     bucket_df = df['lbins'].value_counts(sort=False).to_frame()\n",
    "    bucket_df['rel'] = rel\n",
    "    fig = plt.figure() \n",
    "    fig.set_size_inches(16, 6)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    bucket_df['prob'] =  bucket_df['rel']/bucket_df[col]\n",
    "    # print([int(x) for x in bucket_df.index.categories.left.tolist()])\n",
    "    \n",
    "    ### determine prob for each \n",
    "    to_val = 0.99 * bucket_df['rel'].sum()\n",
    "    s = 0\n",
    "    stop_bucket = 0\n",
    "    for v in bucket_df['rel']: \n",
    "        s += v\n",
    "        stop_bucket += 1\n",
    "        if s >= to_val:\n",
    "            break\n",
    "\n",
    "    if stop_bucket < 2: \n",
    "        stop_bucket = 2\n",
    "        \n",
    "    pre_bins = [x+bins[1]/2 for x in bins[:stop_bucket]]\n",
    "\n",
    "    poly = np.poly1d(np.polyfit(pre_bins, bucket_df['prob'][:stop_bucket].values, 2))\n",
    "    poly_vals = [poly(x) for x in pre_bins]\n",
    "    poly_vals += [poly_vals[-1]] * (len(bins) - len(poly_vals) -1)\n",
    "    bucket_df['poly'] = poly_vals\n",
    "\n",
    "    ax.plot([x for x in range(0, len(bins)-1)], poly_vals)\n",
    "\n",
    "    sns.scatterplot([x for x in range(len(bins)-1)], bucket_df['prob'], alpha=0.8, ax=ax, markers=['X'], style=0, color='black', s=40)\n",
    "    ticks = [str(int(x)) for x in bucket_df.index.categories.left.tolist()]\n",
    "    ax.set_xticks(range(len(ticks)))\n",
    "    ax.set_xticklabels(ticks, rotation=270)\n",
    "    ax.set_ylabel('P(R|B)', size=20)\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.get_legend().remove()\n",
    "    df[col[:1]+'prob'] = df[col].fillna(bucket_df.index[0]).replace(bucket_df['prob'])\n",
    "    df[col[:1]+'poly'] = df[col].fillna(bucket_df.index[0]).replace(bucket_df['poly'])\n",
    "    # fig.savefig('figures/aus-' + ocol+'-prob-rel.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_res_file(out_path: str, results):\n",
    "    with open(out_path, 'w') as f:\n",
    "        for q, q_res in sorted(results.items(), key=lambda x: x[0]):\n",
    "            q_res = sorted(zip(q_res[0], q_res[1]), key=lambda x: x[1], reverse=True)\n",
    "            cut = len(q_res)\n",
    "            if cut > CUTOFF:\n",
    "                cut = CUTOFF\n",
    "            for i, res in enumerate(q_res[:cut]):\n",
    "                f.write('{0} Q0 {1} {2} {3} t\\n'.format(q, res[0], i, res[1]))\n",
    "\n",
    "def create_res_file(path: str, df: pd.DataFrame):\n",
    "    cols = ['inlink', 'outlink', 'lens', 'iprob', 'oprob', 'lprob', 'ipoly', 'opoly', 'lpoly']\n",
    "    results = []\n",
    "    for c in cols:\n",
    "        results.append({})\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            q = int(parts[0])\n",
    "            doc = parts[2].upper()\n",
    "            row = df.loc[doc]\n",
    "            for i, c in enumerate(cols):\n",
    "                vals = results[i].get(q, [{}, []])\n",
    "                vals[0][doc] = len(vals[1])\n",
    "                vals[1].append(row[c])\n",
    "                results[i][q] = vals\n",
    "\n",
    "    for r, c in zip(results, cols):\n",
    "        save_res_file(os.path.join(BASE_DIR, 'links', '{0}-res.txt'.format(c)), r)\n",
    "    \n",
    "# create_res_file(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "names = ['inlink', 'outlink', 'lens', 'iprob', 'oprob', 'lprob', 'ipoly', 'opoly', 'lpoly']\n",
    "dfs = []\n",
    "for d in names: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'links', d+'-res.txt'), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], False)[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = 30\n",
    "# link_text_fig = plot_tune_1d_comp(['base']+names, RERANK_METRICS, \n",
    "#                     [[base_df for x in range(to)]] + [x[:to] for x in dfs], 0.00, (to-1)/100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_fig = plot_tune_1d_comp(['base', 'len', 'prob', 'poly'], RERANK_METRICS, \n",
    "                   [[base_df for x in range(to)]] + [x[:to] for x in [x for x in dfs[2::3]]], 0.00, (to-1)/100, 0.01, legend_x=0.92, styles=['--'], ylims=RERANK_YLIMS)\n",
    "\n",
    "# len_fig.savefig('figures/ausnl-len-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_fig = plot_tune_1d_comp(['base']+[x for i, x in enumerate(names[::]) if i % 3 != 2], RERANK_METRICS, \n",
    "                    [[base_df for x in range(to)]] + [x[:to] for x in [x for i, x in enumerate(dfs[::]) if i % 3 != 2]], 0.00, (to-1)/100, 0.01, legend_x = 0.92, styles=['--'], ylims=RERANK_YLIMS)\n",
    "\n",
    "# link_fig.savefig('figures/ausnl-citation-interp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_qry = load_1d_dfs(['filtered-phrasestop'], [config.AUS_QREL_PATH], os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior'), 'case-topics-{0}-unigram_dir_mu_{1:.2f}.run', ['1'], 1050, 1050, 1, per_query=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_1d_max_with_interp(display_names, metric_names, dfs, start, increment, name, interp, base_qry, base_df, path, metrics=None):\n",
    "    measure_max = {}\n",
    "    for i in range(len(display_names)):\n",
    "        for j in range(len(dfs[i])):\n",
    "            for m in dfs[i][j].index:\n",
    "                if m not in metrics: \n",
    "                    continue \n",
    "                val = dfs[i][j][m]-base_df[m]\n",
    "                if (display_names[i], metrics[m]) not in measure_max: \n",
    "                    measure_max[(display_names[i], metrics[m])] = {'-': val, name: '{0:.2f}'.format(j*increment+start)}\n",
    "                else: \n",
    "                    if measure_max[(display_names[i], metrics[m])]['-'] < val:\n",
    "                        measure_max[(display_names[i], metrics[m])] = {'-': val, name: '{0:.2f}'.format(j*increment+start)}\n",
    "\n",
    "    back_metric = {v: k for k, v in metrics.items()}\n",
    "    for k, v in measure_max.items():\n",
    "        if k[1] == 'Unjudged@20':\n",
    "            continue\n",
    "        _l = float(v[name])\n",
    "        if _l == 0.00:\n",
    "            v['-'] = '{0:.4f}'.format(v['-'])\n",
    "        else:\n",
    "            interp.interpolate(path.format(k[0]), _l, 'tmp.run')\n",
    "            comp = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0]\n",
    "            p = stats.ttest_rel(base_qry[back_metric[k[1]]], comp[back_metric[k[1]]]).pvalue\n",
    "            if p < 0.01:\n",
    "                v['-'] = '{0:.4f}'.format(v['-'])+'$^{**}$'\n",
    "            elif p < 0.05:\n",
    "                v['-'] = '{0:.4f}'.format(v['-'])+'$^{*}$'\n",
    "            else:\n",
    "                v['-'] = '{0:.4f}'.format(v['-'])\n",
    "        \n",
    "    max_df = pd.DataFrame.from_dict(measure_max).stack().unstack(level=0)\n",
    "    return max_df.reindex(list(metrics.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_max = select_1d_max_with_interp([x for x in names[2::3]], RERANK_METRICS.keys(), [x for x in dfs[2::3]], 0.0, 0.01, '$\\lambda$', inter, base_qry, base_df, os.path.join(BASE_DIR, 'links', '{0}-res.txt'), metrics=RERANK_METRICS).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len_max.drop(['Unjudged@20'], axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_max = select_1d_max_with_interp([x for i, x in enumerate(names[::]) if i % 3 != 2], RERANK_METRICS.keys(), [x for i, x in enumerate(dfs[::]) if i % 3 != 2], 0.0, 0.01, '$\\lambda$', inter, base_qry, base_df, os.path.join(BASE_DIR, 'links', '{0}-res.txt'), metrics=RERANK_METRICS).T\n",
    "print(link_max.drop(['Unjudged@20'], axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "names = ['inlink', 'outlink', 'lens', 'iprob', 'oprob', 'lprob', 'ipoly', 'opoly', 'lpoly']\n",
    "dfs = []\n",
    "for d in names: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'links', d+'-res.txt'), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_folds = read_folds(AUS_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = copy.copy(config.METRIC_NAMES)\n",
    "del metrics['recall_100']\n",
    "\n",
    "ntlm_df = pd.DataFrame(columns=metrics)\n",
    "\n",
    "for ab, runs in zip(names, dfs):\n",
    "    ntlm_cross = cross_validation(runs, tt_folds, metrics, base_qry)\n",
    "    ntlm_df.loc[ab] = ntlm_cross[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlm_df.loc['$R$'] = base_query.mean().round(4)\n",
    "link_df = ntlm_df.reindex(['$R$', 'inlink', 'iprob', 'ipoly', 'outlink', 'oprob', 'opoly'])\n",
    "# write_table('tables/ausnl-link-prior', bold_max(link_df).rename(columns=metrics).drop(['Unjudged@20'],axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = ntlm_df.reindex(['$R$', 'lens', 'lprob', 'lpoly'])\n",
    "# write_table('tables/ausnl-len-prior', bold_max(len_df).rename(columns=metrics).drop(['Unjudged@20'],axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om = copy.copy(config.METRIC_NAMES)\n",
    "del om['recall_100']\n",
    "del om['unjudged@20']\n",
    "\n",
    "for r in ['lens', 'lprob']:\n",
    "    inter.interpolate(os.path.join(BASE_DIR, 'links', r+'-res.txt'), 0.14, 'tmp.run')\n",
    "    b = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0]\n",
    "    qry_comp_df = b-base_qry\n",
    "    qry_comp_fig = qry_comp_df[om.keys()].rename(metrics, axis='columns').plot.box(fontsize=15, boxprops=dict(linestyle='-', linewidth=2), medianprops=dict(linestyle='-', linewidth=2), color=dict(boxes='black', whiskers='black', medians='b', caps='r'), figsize=(16, 4)).axhline(y=0, xmin=0.0, xmax=1.0, linestyle='--', linewidth=1.0, color='grey')\n",
    "    # qry_comp_fig.get_figure().savefig('figures/ausnl-qry-comp-{0}.pdf'.format(r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpolater(os.path.join(BASE_DIR, 'preprocessing', 'dirichlet_prior', 'case-topics-filtered-phrasestop-unigram_dir_mu_1050.00.run'), normalize=True)\n",
    "\n",
    "names = ['oprob']\n",
    "dfs = []\n",
    "for d in names: \n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'links', d+'-res.txt'), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_diff(names, metric_names, dfs, start, end, increment, broad, narrow, legend_x: float=0.96, legend_y: float=0.46, styles=[], ylims=[]): \n",
    "\n",
    "    r = int(len(metric_names)/2)\n",
    "    c = r\n",
    "    if c == r: \n",
    "        r-=1\n",
    "    if len(metric_names)%2 != 0:\n",
    "        c += 1 \n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    fig.set_size_inches(16, 6)\n",
    "    x = np.arange(start, end+increment, increment)\n",
    "    cnt = 0 \n",
    "    row = 0\n",
    "    print(len(x))\n",
    "    for m in metric_names:\n",
    "            for i, df in enumerate(dfs):\n",
    "                s = None \n",
    "                if i < len(styles): \n",
    "                    s = styles[i]\n",
    "                \n",
    "                axs[row, cnt].plot(x, [y[m].mean() for y in df], linestyle=s)\n",
    "                axs[row, cnt].plot(x, [y[y.index.isin(broad)][m].mean() for y in df])\n",
    "                axs[row, cnt].plot(x, [y[y.index.isin(narrow)][m].mean() for y in df])\n",
    "\n",
    "            axs[row, cnt].set_ylabel(metric_names[m],fontsize=18)\n",
    "\n",
    "            axs[row, cnt].tick_params(labelsize=12)\n",
    "            axs[row, cnt].yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "            cnt += 1 \n",
    "            if cnt >= c: \n",
    "                cnt = 0 \n",
    "                row += 1 \n",
    "                \n",
    "    for i in range(len(ylims)):\n",
    "        plt.gcf().get_axes()[i].set_ylim(ymax=ylims[i])\n",
    "    \n",
    "    if len(metric_names) % 2 != 0: \n",
    "        fig.delaxes(axs[row, -1])\n",
    "\n",
    "    fig.legend(names + ['broad', 'specific'], bbox_to_anchor=[legend_x, legend_y], frameon=True, ncol=2, prop={\"size\": 15}).get_frame().set_edgecolor('black')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "bs_plot = plot_diff(['all'], metrics, dfs, 0, 0.99, 0.01, broad, specific, styles=['--'])\n",
    "# bs_plot.savefig('figures/ausnl-oprob-qtype.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interped_df = dfs[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_changes(df, base, broad, specific, metrics):\n",
    "    new_df = df - base \n",
    "    totals = {}\n",
    "    b_df = new_df[new_df.index.isin(broad)]\n",
    "    s_df = new_df[new_df.index.isin(specific)]\n",
    "    for m in metrics:\n",
    "        totals[m] = {}\n",
    "        for l, d in zip(['b', 's'], [b_df, s_df]):\n",
    "            totals[m][(l, '+')] = d[d[m] > 0][m].count()/len(d)\n",
    "            totals[m][(l, '-')] = d[d[m] < 0][m].count()/len(d)\n",
    "    \n",
    "#     print(pd.DataFrame(totals))\n",
    "    print(pd.DataFrame(totals).rename(metrics, axis='columns').drop(\"Unjudged@20\", axis='columns').round(4))\n",
    "\n",
    "count_changes(interped_df, dfs[0][0], broad, specific, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_qry(df, base, broad, metric, disp):\n",
    "    cmp = df-base\n",
    "    cmp['type'] = pd.Series({k: queries[k]['type'] for k in cmp.index})\n",
    "    sort = cmp.sort_values(metric, ascending=True)\n",
    "    mask = sort['type'] == 'broad'\n",
    "    colors = np.array(['b']*len(sort))\n",
    "    colors[mask.values] = 'r'\n",
    "    \n",
    "    fig = plt.figure() \n",
    "    ax = fig.add_subplot(111)\n",
    "    fig.set_size_inches(16, 4)\n",
    "    sns.barplot(x=df.index, y=metric, data=cmp, order=sort.index, ax=ax, palette=colors)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_ylabel(disp, fontsize=15)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    return fig\n",
    "    \n",
    "\n",
    "pq_diff = plot_per_qry(interped_df, base_query, queries, 'err@20', 'ERR@20')\n",
    "# pq_diff.savefig('figures/ausnl-oprob-qtype-err.pdf')\n",
    "\n",
    "pq_diff = plot_per_qry(interped_df, base_query, queries, 'rbp@0.80', 'RBP')\n",
    "# pq_diff.savefig('figures/ausnl-oprob-qtype-ndcg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_len_correlation(queries, df, metrics):\n",
    "    lens = {k: len(queries[k]['topic'].split()) for k in queries}\n",
    "    df['lens'] = df.index.map(lens)\n",
    "    \n",
    "    fig = plt.figure() \n",
    "    ax = fig.add_subplot(111)\n",
    "    fig.set_size_inches(16, 8)\n",
    "    for m in metrics.keys():\n",
    "        sns.regplot(x=df['lens'], y=df[m], ax=ax, truncate=False)\n",
    "#         ax.scatter(x=df['lens'], y=df[m])\n",
    "#         g, b = np.polyfit(df['lens'], df[m], 1)\n",
    "#         ax.plot(df['lens'], g*df['lens']+b)\n",
    "    ax.set_xlabel('Query length', fontsize=15)\n",
    "    ax.set_ylabel('Increase above $R$', fontsize=15)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.legend(list(metrics.values()), frameon=True, fontsize=12).get_frame().set_edgecolor(\"black\")\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "len_corr_fig = plot_len_correlation(queries, interped_df, {'err@20': 'ERR@20', 'rbp@0.80': 'RBP'})\n",
    "# len_corr_fig.savefig('figures/ausnl-len-corr.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(queries, df, metrics):\n",
    "    lens = {k: len(queries[k]['topic'].split()) for k in queries}\n",
    "    df['lens'] = df.index.map(lens)\n",
    "    out_df = pd.DataFrame()\n",
    "    out_df['pearson'] = df[['lens', *list(metrics.keys())]].corr(method='pearson')['lens'].T\n",
    "    out_df['kendall'] = df[['lens', *list(metrics.keys())]].corr(method='kendall')['lens'].T\n",
    "    return out_df.drop(['lens'], axis='index').rename(config.METRIC_NAMES, axis='index').round(4).to_latex()\n",
    "    \n",
    "# write_table('tables/link-correlation', correlation(queries, interped_df, config.METRIC_NAMES))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
