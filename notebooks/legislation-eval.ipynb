{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for leg queries and ranking features as well as prf for determining whether top ranked document contains legislation that is relevant to automatically apply filtering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotlib.loaders import *\n",
    "from plotlib.plotters import *\n",
    "from phdconf import config \n",
    "from phdconf.config import *\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(AUS_LEG_TOPIC_PATH)\n",
    "broad, specific = load_query_types(queries)\n",
    "\n",
    "paths = ['leg-casename.run', 'leg-citation.run', 'leg-count.run', 'leg-date.run', 'leg-query.run', 'leg-sec-count.run', 'leg-specific-sec-count.run', 'leg-interp.run', 'leg-comb.run', 'auspdfs-unigram_dir_mu_1050.00.run', 'filtered-phrasestop-unigram_dir_mu_1050.00.run']\n",
    "paths = ['all-leg-queries-'+x for x in paths]\n",
    "names = ['casenames', 'citations', 'counts', 'date', 'query', 'section', 'specific_section', 'interp', 'comb', 'pdf', 'text']\n",
    "displays = ['Casename', 'Citation', 'Legislation', 'Date', 'Query', 'Section', 'Specific Sec', 'Interp', 'Combined', 'PDF', 'Cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_folds(queries, k: int):\n",
    "#     l = len(queries)\n",
    "#     q_set = set(queries)\n",
    "#     inds = [x for x in range(l)]\n",
    "#     np.random.shuffle(inds)\n",
    "#     queries = np.array(queries)\n",
    "#     queries = queries[inds]\n",
    "    \n",
    "#     avg = l / float(k)\n",
    "#     parts = []\n",
    "#     last = 0.0\n",
    "    \n",
    "#     test = []\n",
    "\n",
    "#     while last < l:\n",
    "#         test.append(list(queries[int(last):int(last + avg)]))\n",
    "#         last += avg\n",
    "     \n",
    "#     for i in range(len(parts)):\n",
    "#         train.append()\n",
    "    \n",
    "#     train = []\n",
    "#     for i in range(len(test)):\n",
    "#         train.append(list(q_set.difference(test[i])))\n",
    "    \n",
    "#     return train, test\n",
    "    \n",
    "# train, test = create_folds(list(queries.keys()), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write folds to file \n",
    "# with open('ausleg-folds.txt', 'w') as f:\n",
    "#     for tr, te in zip(train, test):\n",
    "#         f.write('{0} {1}\\n'.format(tr, te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, os.path.join(config.BASE_DIR, 'dirichlet_prior'), paths)\n",
    "dfs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, os.path.join(BASE_DIR, 'legislative'), paths, per_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sig(dfs, comps, names, metrics):\n",
    "    d = pd.DataFrame(columns=dfs[0].columns)\n",
    "    all_ind = set()\n",
    "    for df in dfs:\n",
    "        all_ind.update(df.index)\n",
    "        \n",
    "    for i in range(len(dfs)): \n",
    "        ind = all_ind - set(dfs[i].index)\n",
    "        ncol = len(dfs[i].columns)\n",
    "        for x in ind: \n",
    "            dfs[i].loc[x] = [0.0] * ncol\n",
    "        dfs[i].sort_index(inplace=True)\n",
    "    \n",
    "    symbols = ['*', '\\dagger', '\\cdot', '\\textdollar', '\\textyen', '\\textcent', '\\texteuro', '\\text', '\\cdot', '\\circ', '\\centerdot', '\\diamond']\n",
    "    comp_res = []\n",
    "    for c in comps: \n",
    "        res = {}\n",
    "        for m in metrics:\n",
    "            res[m] = dfs[c][m]\n",
    "        comp_res.append((c, res))\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        av = df.mean()\n",
    "        for j, res in enumerate(comp_res):\n",
    "            if i <= res[0]: \n",
    "                continue\n",
    "            for m in metrics:\n",
    "#                 print(res[m])\n",
    "#                 print(df[m])\n",
    "                p = stats.ttest_rel(res[1][m], df[m]).pvalue\n",
    "                if p < 0.05: \n",
    "                    sym = symbols[j]\n",
    "                    if p < 0.01:\n",
    "                        sym = sym*2\n",
    "                    if isinstance(av[m], str):\n",
    "                        av[m] = av[m][:-2] + sym + \"}$\"\n",
    "                    else:\n",
    "                        av[m] = \"{0:.4f}$^{{\".format(av[m]) + sym + \"}$\"\n",
    "                elif isinstance(av[m], float):\n",
    "                    av[m] = \"{0:.4f}$^{{}}$\".format(av[m])\n",
    "\n",
    "        d.loc[names[i]] = av\n",
    "    print(d.round(4).filter(metrics, axis='columns').rename(metrics, axis='columns').to_latex(escape=False))\n",
    "    return d.filter(metrics, axis='columns').rename(metrics, axis='columns')\n",
    "                    \n",
    "\n",
    "metrics = {}\n",
    "metrics['set_P'] = 'P'\n",
    "metrics['set_recall'] = 'R'\n",
    "metrics['set_F_.5'] = 'F_{0.5}'\n",
    "all_leg_df = calc_sig(dfs, [4, 9, 10], displays, metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(dfs[9]['recip_rank'], dfs[10]['recip_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = all_leg_df.reindex(['Query', 'PDF', 'Cleaned'])\n",
    "sub_df = sub_df.rename(index={'PDF': '\\texttt{PDF}', 'Cleaned': '\\texttt{cleaned}', 'Query': '\\texttt{bool}'})\n",
    "# write_table('tables/ausl-leg-bool', bold_max(sub_df).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = copy.copy(config.METRIC_NAMES)\n",
    "del metrics['unjudged@20']\n",
    "calc_sig(dfs[:-2], [4], displays[:-2], metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['leg-casename.run', 'leg-citation.run', 'leg-count.run', 'leg-date.run', 'leg-query.run', 'leg-sec-count.run', 'leg-specific-sec-count.run', 'leg-interp.run', 'leg-comb.run', 'auspdfs-unigram_dir_mu_1050.00.run', 'filtered-phrasestop-unigram_dir_mu_1050.00.run']\n",
    "paths = ['all-leg-queries-'+x for x in paths]\n",
    "names = ['casenames', 'citations', 'counts', 'date', 'query', 'section', 'specific_section', 'interp', 'comb', 'pdf', 'text']\n",
    "    \n",
    "# names[4]\n",
    "inter = Interpolater(os.path.join(BASE_DIR, 'legislative/', paths[4]), normalize=True)\n",
    "\n",
    "dfs = []\n",
    "for d in paths[:4]+paths[5:-4]: \n",
    "    print(d)\n",
    "    interped_dfs = []\n",
    "    for _lambda in np.arange(0, 1.0, 0.01):\n",
    "        inter.interpolate(os.path.join(BASE_DIR, 'legislative/', d), _lambda, 'tmp.run')\n",
    "        interped_dfs.append(load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', ['tmp.run'], per_query=True)[0])\n",
    "    dfs.append(interped_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_folds = read_folds(AUS_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, '', [os.path.join(BASE_DIR, 'legislative', paths[4])], per_query=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = copy.copy(config.METRIC_NAMES)\n",
    "\n",
    "ntlm_df = pd.DataFrame(columns=metrics)\n",
    "\n",
    "for ab, runs in zip(names[2:4]+names[5:-4], dfs[2:]):\n",
    "    print(ab)\n",
    "    ntlm_cross = cross_validation(runs, tt_folds, metrics, base_query)\n",
    "    ntlm_df.loc[ab] = ntlm_cross[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlm_df.loc['$R$'] = base_query.mean().round(4)\n",
    "ntlm_df = ntlm_df.reindex(['$R$', 'counts', 'section', 'specific_section', 'date'])\n",
    "print(ntlm_df.rename(columns=metrics).drop(['Unjudged@20', 'R@100'],axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausl_leg_df = ntlm_df.reindex(['$R$', 'counts', 'section'])\n",
    "ausl_leg_df = ausl_leg_df.rename(index={'counts': 'leg', 'section': 'sec'})\n",
    "# write_table('tables/ausl-leg-ranking', bold_max(ausl_leg_df).rename(columns=metrics).drop(['Unjudged@20', 'R@100'],axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ausl_date_df = ntlm_df.reindex(['$R$', 'date'])\n",
    "# write_table('tables/ausl-date-ranking', bold_max(ausl_date_df).rename(columns=metrics).drop(['Unjudged@20', 'R@100'],axis='columns').to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missed(run_name: str, path: str = os.path.join(BASE_DIR, 'legislative')):    \n",
    "    retrieved = {}\n",
    "    with open(f'{path}/{run_name}.run') as f:\n",
    "        for line in f: \n",
    "            parts = line.strip().split()\n",
    "            if parts[0] not in retrieved:\n",
    "                retrieved[parts[0]] = set()\n",
    "            retrieved[parts[0]].add(parts[2])\n",
    "            \n",
    "    relevant = {}\n",
    "    with open(config.AUS_QREL_PATH) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if parts[0] not in retrieved:\n",
    "                continue\n",
    "            if parts[0] not in relevant:\n",
    "                relevant[parts[0]] = set()\n",
    "            if parts[3] == \"1\":\n",
    "                relevant[parts[0]].add(parts[2])\n",
    "                \n",
    "                \n",
    "    for topic in relevant.keys():\n",
    "        items = copy.copy(relevant[topic])\n",
    "        for doc in items:\n",
    "            if doc in retrieved[topic]: \n",
    "                relevant[topic].remove(doc)\n",
    "    \n",
    "    return(relevant)\n",
    "    \n",
    "missed = get_missed('all-leg-queries-leg-query')\n",
    "\n",
    "\n",
    "# not cite - 33\n",
    "# 2 - 2006QCA155, 2003FCA50\n",
    "# 17 - 2014FCA765, \n",
    "# 35 - 2003FCAFC109, 2014QSC281\n",
    "# 47 - 2005FCA494, 2008FCAFC170\n",
    "# 55 - 2009FCA1502, 2013FCA1038, 2011FCA1159, 2013QCA104, 2015FCA741\n",
    "# 60 - 2015QSC149, 2014QCA183\n",
    "# 61 - 2013QCA161, 2016FCA243, 2002QCA225, 2012QCA100, 2009QSC417, 2016QCA215, 2010QSC122, 2008FCA0865, 2014FCA585\n",
    "# 66 - 2006QSC349\n",
    "# 77 - 2005QCA277, 2010FCA769, 2005FCA918, 2010FCA285, 2018FCA33\n",
    "# 78 - 2010FCA285, 2005FCA918, 2018FCA33\n",
    "# 86 - 2011QDC213\n",
    "\n",
    "# reason for this is might be appeal or costs decision\n",
    "\n",
    "# cite prev leg - 4\n",
    "# 36 - 2001QSC211\n",
    "# 38 - 2004FCA5\n",
    "# 92 - 2011QSC307, 2009QCA75\n",
    "\n",
    "# cite other sec from same act or another act - 15\n",
    "# 17 - 2011FCA1063\n",
    "# 55 - 2019QSC144\n",
    "# 60 - 2001QSC444, 2007QCA185, 2007QSC92, 2008QSC4, 2011QSC88, 2012QDC73, 2006QSC274, 2004QSC272, 2009QSC192, \n",
    "# 78 - 2018QCA79, 2007QSC262\n",
    "# 96 - 2018FCA657, 2018FCA1405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missed_standard = get_missed('all-leg-queries-leg-linked-rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in missed.items():\n",
    "#     print(k, v)\n",
    "dfs = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, os.path.join(BASE_DIR, 'legislative/'), paths, per_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['legislative-queries', 'case-topics']\n",
    "expansion_paths = ['leg-exp.run', 'leg-filtered-exp.run', 'leg-linked-all.run', 'leg-linked-rep.run', 'leg-linked-same.run']\n",
    "expansion_paths = ['all-leg-queries-'+x for x in expansion_paths]\n",
    "\n",
    "results = load_dfs(config.AUS_QREL_PATH, config.AUS_REL_LEVEL, os.path.join(BASE_DIR, 'legislative/'), expansion_paths, per_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['set_P'] = 'P'\n",
    "metrics['set_recall'] = 'R'\n",
    "metrics['set_F_.5'] = 'F_{0.5}'\n",
    "leg_filter_df = calc_sig(dfs[-3:]+results, [0, 1, 2], displays[-3:]+['leg-exp', 'leg-filtered-exp', 'leg-linked-all', 'leg-linked-rep', 'leg-linked-same'], metrics)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_filter_df = leg_filter_df.rename(index={'PDF': '\\texttt{PDF}', 'Cleaned': '\\texttt{cleaned}', 'Combined': '\\texttt{bool}', \n",
    "                                        'leg-linked-all': 'all-link', 'leg-linked-rep': 'rep-link', 'leg-linked-same': 'same-link'})\n",
    "leg_filter_df = leg_filter_df.applymap(lambda x: round(x, 4) \n",
    "    if isinstance(x, (int, float)) else x)\n",
    "# write_table('tables/ausl-leg-exp', bold_max(leg_filter_df.round(4)).rename(columns=metrics).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = leg_filter_df.reindex(['\\texttt{bool}', '\\texttt{cleaned}', '\\texttt{PDF}', 'leg-exp'])\n",
    "ndf = ndf.applymap(lambda x: round(x, 4) if isinstance(x, (int, float)) else x)\n",
    "# write_table('tables/ausl-leg-term-exp', bold_max(ndf).rename(columns=metrics).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = copy.copy(config.METRIC_NAMES)\n",
    "del metrics ['unjudged@20']\n",
    "calc_sig(dfs+results, [4, 9, 10], displays+['leg-exp', 'leg-filtered-exp', 'leg-linked-all', 'leg-linked-rep', 'leg-linked-same'], metrics)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[-1][(results[-1]-dfs[-3])['set_recall'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[-3].loc[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_b = get_missed('all-leg-queries-leg-linked-all') \n",
    "miss_a = get_missed('all-leg-queries-leg-exp') \n",
    "# first is missing from baseline \n",
    "# for k, v in miss_a.items():\n",
    "#     if len(v) > 0 or len(miss_b[k]) > 0:\n",
    "#         print(k, v, '|', miss_b[k])\n",
    "# print('-'*20)\n",
    "# miss_b = get_missed('legislative-queries-leg-linked-same') \n",
    "# miss_a = get_missed('legislative-queries-leg-exp') \n",
    "# for k, v in miss_a.items():\n",
    "#     if len(v) > 0 or len(miss_b[k]) > 0:\n",
    "#         print(k, v, '|', miss_b[k])\n",
    "# print('-'*20)\n",
    "# miss_b = get_missed('legislative-queries-leg-linked-rep') \n",
    "# miss_a = get_missed('legislative-queries-leg-exp') \n",
    "# for k, v in miss_a.items():\n",
    "#     if len(v) > 0 or len(miss_b[k]) > 0:\n",
    "#         print(k, v, '|', miss_b[k])\n",
    "# print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_missed('all-leg-queries-leg-exp') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_results(path: str):\n",
    "    res = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            topic = line.split()[0]\n",
    "            v = res.get(topic, 0)\n",
    "            res[topic] = v + 1\n",
    "                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_num_results(os.path.join(BASE_DIR, 'legislative/', 'case-topics-leg-exp.run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_num_results(os.path.join(BASE_DIR, 'legislative/', 'legislative-queries-flattened-unigram_dir_mu_2400.00.run'))\n",
    "\n",
    "# clear files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prf(path: str): \n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "        return data\n",
    "        \n",
    "prf_data = load_prf('../features/leg-prf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = []\n",
    "legs = []\n",
    "for i in range(0, 4):\n",
    "    secs.append([])\n",
    "    legs.append([])\n",
    "\n",
    "for section in prf_data['sections']:\n",
    "    q_leg = set()\n",
    "    q_sec = []\n",
    "    \n",
    "    if section in prf_data['Found']:\n",
    "        q_leg = set(prf_data['Found'][section][0])\n",
    "        if prf_data['Found'][section][1] is not None:\n",
    "            q_sec = set(prf_data['Found'][section][1])\n",
    "    \n",
    "    for i in range(0, 4):\n",
    "        if prf_data['legislation'][section][i] is None:\n",
    "            continue\n",
    "            \n",
    "        for l in prf_data['legislation'][section][i].items():\n",
    "            if l[0] == 'act' or l[0] == 'acts':\n",
    "                continue\n",
    "            legs[i].append((section, l[0], l[1], l[0] in q_leg))\n",
    "            \n",
    "        for s in prf_data['sections'][section][i].items():\n",
    "            secs[i].append((section, s[0], s[1], s[0] in q_sec))\n",
    "\n",
    "#         legs = sorted(prf_data['legislation'][section][i].items(), key=lambda x: x[1], reverse=True)\n",
    "#         secs = sorted(prf_data['sections'][section][i].items(), key=lambda x: x[1], reverse=True)\n",
    "                    \n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prf_data['Found'].keys())\n",
    "print(set(prf_data['sections'].keys()).difference(set(prf_data['Found'].keys())))\n",
    "print(len(prf_data['sections'].keys()))\n",
    "print(prf_data['legislation'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df = pd.DataFrame(data=secs[0], columns=['query', 'item', 'count', 'in_query'])\n",
    "f, ax = plt.subplots(1)\n",
    "sec_scatter = sns.scatterplot(x='count', y='query',\n",
    "              hue='in_query',\n",
    "              data=sec_df)\n",
    "\n",
    "f.set_size_inches(16, 4)\n",
    "ax.set_xlabel('Frequency', fontsize=15)\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "ax.axes.tick_params(labelsize=12)\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "ax.get_legend().remove()\n",
    "# f.savefig('figures/aus-sec-prf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_df = pd.DataFrame(data=legs[0], columns=['query', 'item', 'count', 'in_query'])\n",
    "f, ax = plt.subplots(1)\n",
    "leg_scatter = sns.scatterplot(x='count', y='query',\n",
    "              hue='in_query',\n",
    "              data=leg_df, ax=ax)\n",
    "\n",
    "f.set_size_inches(16, 4)\n",
    "# ax.axes.xaxis.set_visible(False)\n",
    "ax.set_xlabel('Frequency', fontsize=15)\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "ax.axes.tick_params(labelsize=12)\n",
    "ax.get_legend().remove()\n",
    "# f.savefig('figures/aus-leg-prf.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
