{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_embeddings(path: str) -> Tuple[Dict[str, int], List[str], np.ndarray]:\n",
    "    vocab = []\n",
    "    lookup = {}\n",
    "    vecs = []\n",
    "    ind = 0\n",
    "    with open(path,'r') as f:\n",
    "        f.readline()\n",
    "\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            vocab.append(split_line[0])\n",
    "            lookup[split_line[0]] = ind\n",
    "            ind += 1\n",
    "            vecs.append(np.array(split_line[1:], dtype=np.float64))\n",
    "        \n",
    "    return lookup, vocab, np.asarray(vecs, dtype=np.float64) \n",
    "\n",
    "lookup, vocab, embs = load_embeddings('/home/danlocke/fastText/filtered-100d.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"damages defamation compensate amongst other things emotional distress\".split()\n",
    "# query = \"maintenance champerty requisite degree control\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(term: str, lookup: Dict[str, int], embs: np.ndarray) -> np.ndarray:\n",
    "    if term not in lookup:\n",
    "        raise Exception(term)\n",
    "\n",
    "    return embs[lookup[term]]\n",
    "\n",
    "centroid = np.sum(np.asarray([get_embedding(q, lookup, embs) for q in query]), axis=0)\n",
    "centroid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top(vec: np.ndarray, embs: np.ndarray, vocab: List[str], k: int = 20, sim: int = None) -> None:\n",
    "    similarities = cosine_similarity(vec.reshape(1, -1), embs)\n",
    "    if sim != None:\n",
    "        print(similarities[0][sim])\n",
    "    inds = np.argsort(similarities)\n",
    "    for ind in inds[0][-k:]:\n",
    "        print(ind, vocab[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 damage\n",
      "32775 overcompensation\n",
      "3692 defamation\n",
      "46452 humiliations\n",
      "3237 emotional\n",
      "27856 defamations\n",
      "57591 distresses\n",
      "59536 insolation\n",
      "27618 defaming\n",
      "4460 compensate\n",
      "14927 anguish\n",
      "11564 reputational\n",
      "34148 indignities\n",
      "7704 humiliation\n",
      "5053 feelings\n",
      "415 damages\n",
      "37343 compensatable\n",
      "38347 compensations\n",
      "21439 consolation\n",
      "4018 distress\n"
     ]
    }
   ],
   "source": [
    "print_top(centroid, embs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "3647 recoverable\n",
      "3692 defamation\n",
      "2210 quantum\n",
      "32659 Compensatory\n",
      "10486 meruit\n",
      "50111 overcompensatory\n",
      "10116 restitutionary\n",
      "38347 compensations\n",
      "4909 liquidated\n",
      "22103 Exemplary\n",
      "10095 unliquidated\n",
      "37343 compensatable\n",
      "727 compensation\n",
      "1974 awarded\n",
      "57671 compensator\n",
      "5309 exemplary\n",
      "5875 compensatory\n",
      "8426 Damages\n",
      "43867 amages\n",
      "415 damages\n"
     ]
    }
   ],
   "source": [
    "print_top(get_embedding('damages', lookup, embs), embs, vocab, sim=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automate'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[35202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
