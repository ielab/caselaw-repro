{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple eval of features for each para and manual classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.artist import setp\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib.collections import PolyCollection\n",
    "sns.set()\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "\n",
    "sns.set_context({\"figure.figsize\": (16, 10)})\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_classification_file(path: str): \n",
    "    lookup = {}\n",
    "    categories = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            id_parts = parts[0].split('-')\n",
    "            if len(id_parts) == 4:\n",
    "                _id = ''.join(id_parts[:3])+'-'+id_parts[3]\n",
    "            else:\n",
    "                _id = parts[0]\n",
    "            if len(parts) != 2:\n",
    "                print(line)\n",
    "            else:    \n",
    "                if parts[1] not in categories:\n",
    "                    categories[parts[1]] = set()\n",
    "                    \n",
    "                categories[parts[1]].add(_id)\n",
    "                lookup[_id] = parts[1]\n",
    "                \n",
    "    return lookup, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features_file(path: str, classified):\n",
    "    out = {}\n",
    "    seen = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            features = []\n",
    "            id_parts = parts[0].split('-')\n",
    "            doc = ''\n",
    "            if len(id_parts) == 4:\n",
    "                doc = ''.join(id_parts[:3])\n",
    "                _id = ''.join(id_parts[:3])+'-'+id_parts[3]\n",
    "            else:\n",
    "                _id = parts[0]\n",
    "                \n",
    "            features.append(int(id_parts[-1]))\n",
    "                \n",
    "            for p in parts[1:]:\n",
    "                features.append(float(p))\n",
    "                \n",
    "            if doc in seen and _id in classified: \n",
    "                    features.append(seen[doc])\n",
    "            else: \n",
    "                features.append(0)\n",
    "                if doc not in seen or seen[doc] == 0: \n",
    "                    if _id in classified and classified[_id] == 'law':\n",
    "                        seen[doc] = 1\n",
    "                else:\n",
    "                    seen[doc] = 0\n",
    "                \n",
    "            out[_id] = features\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_path = '../features/para-classification.txt'\n",
    "features_path = '../features/out.txt'\n",
    "\n",
    "classified_lookup, categories = read_classification_file(classified_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lookup = read_features_file(features_path, classified_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lookup(features, classified): \n",
    "    prev_doc = '' \n",
    "    prev = ''\n",
    "    out = {}\n",
    "    for _id in features:\n",
    "        doc = _id.split('-')[0]\n",
    "        if doc == prev_doc: \n",
    "            if features[_id][2] == 1: \n",
    "                for i in range(1, len(features[prev])):\n",
    "                    features[prev][i] += features[_id][i]\n",
    "            else: \n",
    "                prev = _id \n",
    "                out[_id] = features[_id]\n",
    "        \n",
    "        prev_doc = doc             \n",
    "        \n",
    "    return out \n",
    "\n",
    "combined_lookup = combine_lookup(features_lookup, classified_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {x: features_lookup[x] + [classified_lookup[x]] for x in features_lookup if x in classified_lookup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = {x: combined_lookup[x] + [classified_lookup[x]] for x in combined_lookup if x in classified_lookup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame.from_dict(features, orient='index', columns=['pos', 'para_num', 'quote', 'num_tokens', 'num_day', 'num_date', 'num_time', 'num_month', 'num_cit', 'num_case', 'num_cl', 'num_sec', 'num_leg', 'num_pin', 'num_ref', 'num_para', 'num_enum', 'num_judg', 'num_court', 'num_person', 'num_party', 'num_coy', 'num_acn', 'num_abn', 'num_ent', 'num_money', 'num_percent', 'num_ground', 'num_ex', 'num_pld', 'num_tscpt', 'num_ab', 'num_decno', 'num_fileno', 'num_report', 'num_order', 'num_secondary', 'seen_law', 'type'])\n",
    "combined_features_df = pd.DataFrame.from_dict(combined_features, orient='index', columns=['pos', 'para_num', 'quote', 'num_tokens', 'num_day', 'num_date', 'num_time', 'num_month', 'num_cit', 'num_case', 'num_cl', 'num_sec', 'num_leg', 'num_pin', 'num_ref', 'num_para', 'num_enum', 'num_judg', 'num_court', 'num_person', 'num_party', 'num_coy', 'num_acn', 'num_abn', 'num_ent', 'num_money', 'num_percent', 'num_ground', 'num_ex', 'num_pld', 'num_tscpt', 'num_ab', 'num_decno', 'num_fileno', 'num_report', 'num_order', 'num_secondary', 'seen_law', 'type'])\n",
    "\n",
    "# features_df = pd.DataFrame.from_dict(features, orient='index', columns=['pos', 'para_num', 'quote', 'num_tokens', 'num_person', 'num_entity', 'num_case', 'num_cit', 'num_sec', 'num_leg', 'num_ref', 'num_para', 'num_clause', 'num_money', 'num_pinpoint', 'num_judge', 'num_date', 'num_acn', 'num_abn', 'num_percent', 'num_time', 'num_order', 'seen_law', 'type'])\n",
    "# combined_features_df = pd.DataFrame.from_dict(combined_features, orient='index', columns=['pos', 'para_num', 'quote', 'num_tokens', 'num_person', 'num_entity', 'num_case', 'num_cit', 'num_sec', 'num_leg', 'num_ref', 'num_para', 'num_clause', 'num_money', 'num_pinpoint', 'num_judge', 'num_date', 'num_acn', 'num_abn', 'num_percent', 'num_time', 'num_order', 'seen_law', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_para(df):\n",
    "    out = {}\n",
    "    for i in df.index:\n",
    "        parts = i.split('-')\n",
    "        if parts[0] not in out: \n",
    "            out[parts[0]] = int(parts[1])\n",
    "        else:\n",
    "            v = int(parts[1]) \n",
    "            if v > out[parts[0]]:\n",
    "                out[parts[0]] = v\n",
    "        \n",
    "    return out \n",
    "doc_paras = num_para(features_df)\n",
    "comb_doc_paras = num_para(combined_features_df)\n",
    "\n",
    "\n",
    "def add_rel_pos(df, lookup):\n",
    "    new = []\n",
    "    for i in df.index: \n",
    "        parts = i.split('-')\n",
    "        doc = lookup[parts[0]]\n",
    "        new.append(float(parts[1])/float(doc))\n",
    "    df['rel_pos'] = new\n",
    "    \n",
    "add_rel_pos(features_df, doc_paras)\n",
    "add_rel_pos(combined_features_df, comb_doc_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(df):\n",
    "    overall = df['type'].value_counts().to_dict()\n",
    "\n",
    "    comp = {}\n",
    "    for x in df.columns:\n",
    "        if not (x == 'heading' or x == 'pos' or x == 'type' or x  == 'para_num' or x == 'num_tokens'):\n",
    "            comp[x] = df[df[x] > 0]['type'].value_counts().to_dict()\n",
    "    \n",
    "    return comp, overall \n",
    "\n",
    "comp, overall = calc(features_df)\n",
    "comp_comb, overall_comb = calc(combined_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame.from_dict(comp).T / pd.Series(overall)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame.from_dict(comp_comb).T / pd.Series(overall_comb)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rule_var1(df, overall):\n",
    "    return pd.Series(df[(df.num_case > 0) | (df.num_cit > 0) | (df.num_sec > 0) | (df.num_leg > 0)]['type'].value_counts().to_dict()) / pd.Series(overall)\n",
    "    \n",
    "def calc_rule_var2(df, overall):\n",
    "    return pd.Series(df[(df.num_case > 0) | (df.num_cit > 0) | (df.num_sec > 0) | (df.num_leg > 0) | (df.num_judge > 0)]['type'].value_counts().to_dict()) / pd.Series(overall)\n",
    "\n",
    "def calc_rule_var3(df, overall):\n",
    "    return pd.Series(df[(df.num_case > 0) | (df.num_cit > 0) | (df.num_sec > 0) | (df.num_leg > 0) | (df.seen_law > 0)]['type'].value_counts().to_dict()) / pd.Series(overall)\n",
    "\n",
    "\n",
    "\n",
    "print(calc_rule_var1(features_df, overall))\n",
    "print('-'*30)\n",
    "print(calc_rule_var1(combined_features_df, overall_comb))\n",
    "print('-'*30)\n",
    "print(calc_rule_var2(features_df, overall))\n",
    "print('-'*30)\n",
    "print(calc_rule_var2(combined_features_df, overall_comb))\n",
    "print('-'*30)\n",
    "print(calc_rule_var3(features_df, overall))\n",
    "print('-'*30)\n",
    "print(calc_rule_var3(combined_features_df, overall_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['seen_law'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.groupby('type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cat_box(df, feature: str):\n",
    "    groups = df.groupby('type')\n",
    "    types = df['type'].unique()\n",
    "    fig, axs = plt.subplots(1, len(types))\n",
    "    fig.set_size_inches(16, 8)\n",
    "    for i in range(len(types)):\n",
    "        axs[i].boxplot(df.loc[groups.groups[types[i]]][feature])\n",
    "        axs[i].set_xlabel(types[i], fontsize='20', rotation=90)\n",
    "\n",
    "plot_cat_box(features_df, 'num_tokens')\n",
    "plot_cat_box(features_df, 'rel_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cat_box(combined_features_df, 'num_tokens')\n",
    "plot_cat_box(combined_features_df, 'rel_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['quote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.subplot()\n",
    "# fig.set_size_inches(16, 8)\n",
    "# fig.scatter(features_df['num_tokens'], features_df['rel_pos'])\n",
    "groups = features_df.groupby('type')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(group.num_tokens, group.rel_pos, marker='o', linestyle='', label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[(features_df.index.str.contains('2000QCA011')) & ((features_df.num_case > 0) | (features_df.num_cit > 0) | (features_df.num_sec > 0) | (features_df.num_leg > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[features_df.index.str.contains('2000QCA011')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
