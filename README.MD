# Caselaw repro

This repository serves as an appendix to our SIGIR submission. Notebooks used to generate results for the paper can be found in `notebooks`. TREC result files can be found in `run-files`.

## Extended results 
Results that we refer to in our paper can be found in the `extended-results` folder. This contains a range of other tables, with other evaluation measures (RR, ERR@20, R@20, R@100 (where not a reranking), NDCG, RBP@0.8 and the number of unjudged documents@20). We also have figures showing parameter searches for interpolations, as well as a range of other evaluations: BERT and multi feature train and test effectiveness and weights; SDM tuning; bucket counts for probabilities of relevance (length, indegree, outdegree); correlations between changes in effectiveness and query reductions or citation priors; per-query distributions of effectiveness. All of these results can be generated by the notebooks contained in this repository.

## Retrieval and ranking code
The underlying retrieval code is contained in [language-model-retrieval repository](www.github.com/dan-locke/langauge-model-retrieval). For more golang scripts that rely on this retrieval code and generate trec style run files, see [this repository](www.github.com/dan-locke/phd).

For BERT based rankers, we used Huggingface, and [KourosAI - NBoost TinyBert model](https://github.com/koursaros-ai/nboost). 

## Using python notebooks
To begin with, you will need to specify 4 environment variables that point to query and qrel paths for collections. 
- `AUS_TOPIC_PATH`
- `AUS_LEG_TOPIC_PATH`
- `AUS_QREL_PATH`
- `SIGIR_QREL_PATH`

You will also need [trec_eval](https://github.com/usnistgov/trec_eval) and [rbp_eval](https://github.com/jsc/rbp_eval) installed and on path. I've put a copy of [gd-eval](https://github.com/trec-web/trec-web-2014/blob/master/src/eval/gdeval.pl) in the `notebooks/plotlib` directory as this is used for ERR results.


## Collection
Please contact me (daniel.locke@uq.edu.au) if you would like a copy of the underlying collection. 

## Embeddings
TODO -- need to upload these somewhere but they are big.